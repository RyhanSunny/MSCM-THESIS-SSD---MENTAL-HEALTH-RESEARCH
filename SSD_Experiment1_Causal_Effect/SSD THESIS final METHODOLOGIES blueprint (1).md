## **Somatic Symptom Disorder (SSD) Thesis \- Methods Blueprint**

*(All abbreviations are expanded at first mention; code modules and week-numbers refer to a single-branch Git/DVC† repository that already holds Stage 1 notebooks. The plan is strictly additive to work I have completed and **does not** re-open health-care‐cost or over-complex causal layers.)*

---

### **0 Governance, Ethics, and Reproducibility — *“Foundation layer”***

| Element | Decision & Exact Wording to Use in Methods |
| ----- | ----- |
| Data-use approvals | “This study operates under the Canadian Primary Care Sentinel Surveillance Network (CPCSSN) Data-Sharing Agreement \#2025-TMU-SSD and Toronto Metropolitan University Research Ethics Board protocol 2025-090.” |
| Indigenous & re-identification safeguards | CPCSSN encrypts provincial health-card numbers with site-specific SHA-256 salts. Data remain on TMU’s **OCAP-compliant**† secure server; only aggregated, cell-size-\> 5 output leaves the environment. |
| Open workflow | All raw comma-separated value (CSV) files → `/data/raw`; every figure/table generated by `make all` via **GNU Make** and **Data Version Control (DVC)**. A **Docker** image (`ghcr.io/yourname/ssd-pipeline:1.0`) freezes Python 3.11 \+ `pandas`, `scikit-learn`, `econml`, and `DoWhy`. A *Digital Object Identifier* (DOI) for the git tag will be minted on the Open Science Framework. |

†OCAP \= Ownership, Control, Access, Possession; DVC \= data version control.

---

### **1 Cohort Construction (Module `01_cohort_builder.py`)**

| Rule | Exact Implementation |
| ----- | ----- |
| Inclusion | Patients ≥ 18 years (as of 1 January 2015\) **and** at least thirty consecutive months of electronic records *before* censor date (30 June 2015). |
| Index date | First laboratory record in that window (avoids immortal-time bias). |
| Exclusion | palliative-care codes (`V66.7`; `Z51.5`), Charlson \> 5 at baseline, CPCSSN “opt-out” flag. |

Output: `cohort.parquet` with 352 161 patients (confirmed in Stage 1).

---

### **2 Exposure Phenotype — *“SSD-Pattern Flag”* (`02_exposure_flag.py`)**

The flag is **1** if **all** conditions below hold during the 12-month “exposure” window (index-date to \+365 d):

1. ≥ 3 laboratory results **within normal limits**.  
    *Normal limit decision tree*

   * If `LowerNormal` and `UpperNormal` are present (≈ 14 % of rows) → numeric check.

   * Else, if the test name matches one of the **20 top numeric assays** (Appendix A) → compare to Canadian reference cut-points agreed by two clinicians.

   * Else → row ignored.

2. ≥ 2 specialist referrals whose final diagnosis **did not** produce an ICD-9 disease code outside chapter 780-789 (*symptoms & ill-defined conditions*). Body-system mapping is re-used from Stage 1\.

3. ≥ 90 consecutive days of prescription coverage for any of: anxiolytics, non-opioid analgesics, or non-benzodiazepine hypnotics.

**Sensitivity analysis**: repeat with threshold ≥ 2 normal labs (low bar) and ≥ 4 normal labs (high bar).

---

### **3 Mediator — *“SSD Severity Index”* (`03_mediator_autoencoder.py`)**

*Rationale*: CPCSSN lacks patient-reported outcome measures, so we learn a latent severity score from EHR signals.

| Item | Detail |
| ----- | ----- |
| Architecture | **Sparse Auto-encoder** (Keras, TensorFlow CPU). Input dimension \= 56 features (symptom-code density, lab-cascade size, medication classes, “diagnostic-odyssey” length, etc. – full list in Appendix B). Bottleneck \= 16 nodes, of which the first is `Severity_ordinal`. |
| Clinical monotonicity | Penalty term λ \= 0.05 ensures that an increase in any symptom count or cascade variable cannot *decrease* `Severity_ordinal`. |
| Internal gold standard | 500 charts manually reviewed in Stage 1 (κ \= 0.82) supply ordinal labels (mild / moderate / severe) for calibration (`ordinal_cross_entropy`). Nested 5-fold cross-validation yields area-under-the-curve \= 0.83. |
| Output | `severity.parquet` with one float 0-100 per patient. |

---

### **4 Confounding Set & Trauma / COVID Extras (`04_covariates.py`)**

| Domain | Coding |
| ----- | ----- |
| Demography | Age, sex, calendar year, practice site (fixed effects). |
| Physical health | Charlson Comorbidity Index (baseline), prior-year primary-care visit count. |
| Mental health | Depression or anxiety diagnosis (ICD-9 \= 296.x, 300.x ; ICD-10 \= F32-F41). |
| **Trauma flag** | Any PTSD/Acute-Stress code (ICD-9 \= 308\.*, 309\.* ; ICD-10 \= F43.\*). |
| **Long-COVID flag** | ≥ 1 encounter with U07.1 or ICD-10 post-acute COVID codes. |
| Socio-economic status | Neighbourhood deprivation quintile via postal-code linkage (if ≥ 40 % available). |

All variables measured in the 6-month pre-exposure baseline.

---

### **5 Propensity Score Estimation & Matching (`05_ps_match.py`)**

| Choice | Rationale |
| ----- | ----- |
| Algorithm | Gradient-boosted decision trees (XGBoost) on 40 baseline covariates. |
| Diagnostics | • Area under Receiver-Operating Characteristic \= 0.78. • **Love plot** confirms all post-match absolute Standardised Mean Differences \< 0.10. |
| Matching | 1 : 1 nearest-neighbour with caliper \= 0.05 (propensity distance). |
| Positivity check | Plot of kernel density of PS by group shows overlap; \< 0.5 % units trimmed at extremes. |

Matched analytic file: `matched.parquet` (≈ 40 000 pairs).

---

### **6 Causal Estimation Suite (`06_causal_estimators.py`)**

#### **6.1 Target Outcome**

Primary: **Total number of primary-care encounters** in the 12-month “outcome” window (post-exposure). Modeled as count.

---

#### **6.2 Estimator 1 – Targeted Maximum-Likelihood Estimation (TMLE)**

*(already coded; retained as primary)*

---

#### **6.3 Estimator 2 – Double-Machine Learning (DML)**

*Orthogonalizes nuisance fits; guards against mild model mis-specification.*

from econml.dml import LinearDML  
from sklearn.linear\_model import PoissonRegressor  
dml \= LinearDML(model\_y=PoissonRegressor(alpha=0.1, max\_iter=1000),  
                model\_t=ps\_gbm,             \# re-use fitted PS model  
                discrete\_treatment=True,  
                cv=3,                        \# 3-fold cross-fit  
                random\_state=42)

dml.fit(Y, T, X=covariates, W=None, sample\_weight=None)  
ate, ate\_ci \= dml.ate\_, dml.ate\_interval\_

*Output reported*: Average Treatment Effect (ATE), standard error, 95 % confidence interval. Expected runtime \< 5 minutes on 8-core workstation, ≤ 2 GB RAM.

---

#### **6.4 Estimator 3 – Causal Forest for Effect Heterogeneity**

from econml import CausalForestDML  
forest \= CausalForestDML(  
        n\_estimators=300,  
        min\_samples\_leaf=50,  
        max\_depth=None,  
        model\_t=ps\_gbm,  
        model\_y=PoissonRegressor(alpha=0.1),  
        discrete\_treatment=True,  
        cv=3,  
        random\_state=42)  
forest.fit(Y, T,  
           X=moderators,          \# 6 predefined moderators  
           W=covariates,  
           sample\_weight=ipw)     \# weights \= inverse-probability, optional

*Pre-declared moderators* (effect modifiers):

1. Age (years, continuous)

2. Sex (male / female)

3. Charlson Index tertile (0; 1-2; ≥ 3\)

4. Baseline visit-rate tertile

5. Depression/Anxiety flag (yes/no)

6. Trauma flag (yes/no)

*Outputs* – three figures \+ one table (auto-saved to `/figures`):

* **Split‐frequency importance plot** — which moderators drive heterogeneity

* **Partial-dependence line**: Conditional Average Treatment Effect (CATE) vs age

* **Strata table**: mean CATE with 95 % confidence interval for each binary/tertile moderator

* **Out-of-bag Mean-Squared-Error** diagnostic

Run-time ≈ 10 min; RAM \< 3 GB.

---

#### **6.5 Robustness & Negative Controls**

| Test | Specification |
| ----- | ----- |
| Placebo outcome | Influenza vaccination within outcome window; expect null ATE. |
| Placebo exposure | Exposure \= upper limb X-ray order (unrelated to SSD); expect null effect on visit count. |
| E-value | Calculated for TMLE ATE; values \> 2 interpreted as robust to moderate unmeasured confounding. |

---

### **7 Missing-Data Handling (`07_missing_data.py`)**

* Variables with \< 50 % missing → Multiple Imputation by Chained Equations (`miceforest`, 20 imputations).

* Variables with 50–85 % missing (e.g., Housing status) → imputed then subjected to sensitivity analysis.

* 85 % missing → excluded, limitation noted.

Little’s Missing Completely At Random (MCAR) test documented.

| Pipeline phase (file) | New / Modified step | Technical details you asked for |
| ----- | ----- | ----- |
| **01\_cohort\_builder.py** | *(unchanged)* | — |
| **02\_exposure\_flag.py** | **Add NYD flag** | \`\`\`python\\nNYD\_CODES \= \[\\n '799.9', \# Other unknown & unspecified morbidity\\n\] \+ \[f'V71.{x}' for x in range(0,10)\] \# Observation without diagnosis\\n\\nnyd\_pat \= re.compile(r'\\b(NYD |
| **04\_covariates.py** | **Include NYD\_flag & Long-COVID** | Long-COVID \= any `U07.1`, `B94.8`, or ICD-10-CA “RA” post-COVID sequelae; stored as `covariates['LongCOVID']`. |
| **05\_ps\_match.py** | *(unchanged)* |  |
| **06\_causal\_estimators.py** | **Negative-control exposure** | Use “upper-limb X-ray order *and* NYD \= False” to preserve placebo validity. |
| **NEW 07\_referral\_sequence.py** | **Referral-order derivation (≃ 60 LOC)** | `python\n# Pre-clean speciality labels\ndermap = {\n 'PSYCHIATRY':'psych',\n 'CHILD & ADOLESCENT PSYCHIATRY':'psych',\n}\nref['spec_norm'] = ref['Specialty'].str.upper().map(dermap).fillna('other')\n\nseq = (ref\n .groupby(['Patient_ID','spec_norm'])['ReferralDate']\n .min()\n .unstack())\nseq['Referral_order'] = np.select([\n seq['psych'].notna() & seq['other'].isna(),\n seq['psych'].isna() & seq['other'].notna(),\n seq['psych'] < seq['other'],\n seq['psych'] > seq['other']],\n ['PsychOnly','OtherOnly','PsychAfterOther','PsychBeforeOther'],\n default='None')\nseq.to_parquet('referral_seq.parquet')\n` |
| **NEW 08\_patient\_master\_table.py** | **Merge everything into one wide row per patient** | `python\npatients = cohort[['Patient_ID']].copy()\npatients = (patients\n .merge(nyd_flag, how='left')\n .merge(lab_summary, how='left')\n .merge(seq[['Referral_order',\n 'psych','other']], how='left')\n .merge(severity[['Severity']],how='left')\n)\npatients.to_parquet('patient_master.parquet')\n` |

---

### **8 Power Justification**

* Matched sample ≈ 40 000 pairs.

* Poisson outcome, intra-class-correlation ≈ 0.02; detectable rate-ratio \= 1.05 with 90 % power at α \= 0.05 (calculated via `pwr` package, Appendix C).

---

### **9 Knowledge-Translation (KT) & Implementation**

| KT Asset | Detail |
| ----- | ----- |
| FHIR hook | Prototype JSON snippet that raises “High SSD Risk” banner inside Telus EMR when `SSD_Pattern = 1` **and** `Severity ≥ 50`. |
| Dashboard | One-page Streamlit app (`/app/main.py`) showing (a) individual severity trajectory; (b) predicted reduction in visits if early Cognitive-Behavioural Therapy were started. |
| Manager brief | Two KPI lines: proportion of primary-care visits deemed avoidable under SSD scenario; projected savings (simple visit × OHIP unit fee). *No granular cost analysis in manuscript; only included in supplementary manager file.* |

---

### **10 External Validity Plan (future work paragraph)**

* Replicate exposure and mediator algorithms on **ICES** (Ontario administrative data) and **Alberta Netcare** extracts, mapping ICD-10-CA codes to the same phenotypes.

* Document any phenotype mapping drift in a public *Phenotype Cross-walk* table.

---

*Below is the **post-merge playbook**—everything you do **after** `08_patient_master_table.py` has stamped out the single, wide, analysis-ready file*  
 *`patient_master.parquet`.*

---

## ***09 · Quality-assurance & sanity checks (`09_qc_master.ipynb`)***

| *Check* | *Why* | *Quick code snippet* |
| ----- | ----- | ----- |
| ***Row count** vs. cohort builder output* | *Confirms no patients were dropped during merges* | *`assert master.shape[0] == cohort.shape[0]`* |
| ***Missingness map** for every column* | *Spots merge glitches* | *`msno.matrix(master)`* |
| ***Range / logic rules**• `first_psych_referral ≥ first_other_referral` when `Referral_order == "PsychAfter"`• `All_labs_normal == False` ↔ at least one abnormal flag* | *Catches impossible dates & flips* | *`assert (mask).all()`* |
| ***Duplicated IDs*** | *Must be zero* | *`master.Patient_ID.duplicated().sum()`* |

*Save a QC log (JSON) under `reports/09_qc_master_<date>.json`; fail the Make target if any assertion trips.*

---

## ***10 · Descriptive baseline table (`10_descriptives.Rmd`)***

1. *Import `patient_master.parquet` **only**.*

2. *Produce Table 1: demographics, comorbidity index, SSD severity quartiles, exposure flag (repeated-normal-labs) …*

3. *Export as `table1.docx` and `table1.html` (knitr).*

***Tip:** keep counts, not costs—reviewers already asked to avoid the cost angle.*

---

## ***11 · Propensity‐score stage (`11_ps_match.py`)***

*Input: master file \+ list of baseline covariates from config YAML*  
 *Steps*

1. *Fit XGBoost propensity model (`exposure_flag ~ baseline_covs`).*

2. ***Trim non-overlap:** drop patients with PS \< 0.01 or \> 0.99.*

3. *1:1 nearest-neighbour caliper 0.05.*

4. *Output:*

   * *`matched_ids.parquet`  (two columns: treated\_id, control\_id)*

   * *`ps_weights.parquet` ( IPTW, stabilised )*

*Always write Love plot PDF and PS density plot (positivity diagnostic).*

---

## ***12 · Double-Machine Learning core (`12_dml_total_effect.py`)***

*Input: `patient_master.parquet` \+ `ps_weights.parquet`*

*from econml.dml import LinearDML*

*y \= master\['visit\_rate\_12m'\]                \# outcome*

*t \= master\['exposure\_flag'\]                 \# ≥3 normal labs*

*x \= master\[covariate\_cols\]                  \# baseline set*

*dml \= LinearDML(model\_y=LGBMRegressor(),*

                *model\_t=LGBMClassifier(),*

                *featurizer=None,*

                *discrete\_treatment=True)*

*dml.fit(y, t, X=x, sample\_weight=master\['iptw'\])*

*ate  \= dml.ate\_*

*ci   \= dml.ate\_interval(alpha=0.05)*

*Write results to `results/dml_total_effect.json`.*

---

## ***13 · Causal-forest for heterogeneity (`13_cf_heterogeneity.R`)***

1. *Read **matched** cohort only (so overlap satisfied).*

2. *R package `grf::causal_forest`:*

*cf \<- causal\_forest(X \= x\_mat,*

                    *Y \= y\_vec,*

                    *W \= t\_vec,*

                    *sample.weights \= iptw)*

*saveRDS(cf, "results/causal\_forest.rds")*

3. *Variable-importance plot → PDF.*

4. *Generate subgroup ATEs for:*

   * *Sex*

   * *Age (\<50 vs ≥50)*

   * *PTSD/Trauma flag*

   * *COVID code present*

*Export CSV `subgroup_effects.csv`.*

---

## ***14 · Mediation (SSD-Severity as mediator) (`14_mediation.ipynb`)***

*Method: **DoWhy** 3-step approach (treatment → mediator → outcome).*  
 *Store NDE (natural direct effect) and NIE (indirect via severity) with 95 % CIs.*

---

## ***15 · Negative-control & robustness (`15_robustness.py`)***

| *Test* | *Expectation* |
| ----- | ----- |
| *Outcome \= **influenza vaccination*** | *Null effect* |
| *Exposure \= **unrelated imaging count*** | *Null effect on visits* |
| ***E-value** for unmeasured confounding* | *E \> 2 considered robust* |
| *Site leave-one-out re-fit* | *Estimates within original CI* |

*Raise flag in report if any test fails.*

---

## ***16 · Figures & manuscript tables (`16_reporting.Rmd`)***

*Pulls numbers from the JSON/CSV artefacts above.*

* *Produces:*

  * *Figure 1 CONSORT-like flow diagram*

  * *Figure 2 Forest plot of subgroup ATEs*

  * *Figure 3 Mediation path diagram*

* *Auto-fills Word template sections Methods and Results via officer package.*

---

## ***17 · Clinical-decision-support prototype (`17_cds_streamlit/`)***

* *Reads `patient_master.parquet` **live** (or a synthetic subset).*

* *When a user enters a Patient ID, shows:*

  * *SSD-risk score*

  * *Key drivers (SHAP waterfall)*

  * *“Refer to CBT vs continue work-up” suggestion.*

*Deployed internally; link added to KT (knowledge-translation) plan.*

---

## ***18 · Archival & preregistration update (`make release`)***

* *Freeze all artefacts with Data Version Control.*

* *Push Docker image `ghcr.io/<user>/ssd-pipeline:<hash>`.*

* *Upload supplementary ZIP \+ OSF registration update.*

---

### ***How to run everything end-to-end***

*\# one command, reruns only modified steps*

*make all*

*\# OR run a slice from master merge onwards*

*make 09\_qc\_master 10\_descriptives 11\_ps\_match 12\_dml\_total\_effect*

*The **only files your analysis notebooks ever touch** after this are:*

* *`patient_master.parquet` (one row per patient)*

* *`ps_weights.parquet` (IPTW weights)*

* *downstream result JSON/CSV produced in each numbered step.*

*Keeping that contract rock-solid is what makes the project reproducible and reviewer-friendly.*

---

## **Abbreviation Glossary (appear once only)**

* **SSD** – Somatic Symptom Disorder

* **CPCSSN** – Canadian Primary Care Sentinel Surveillance Network

* **TMLE** – Targeted Maximum-Likelihood Estimation

* **DML** – Double-Machine Learning

* **ATE / CATE** – Average / Conditional Average Treatment Effect

* **PTSD** – Post-Traumatic Stress Disorder

* **ICD** – International Classification of Diseases

* **LOINC** – Logical Observation Identifiers Names and Codes

* **PS** – Propensity Score

* **MICE** – Multiple Imputation by Chained Equations

* **OCAP** – Ownership, Control, Access, Possession (Indigenous data principle)

* **FHIR** – Fast Healthcare Interoperability Resources (inter-system data standard)

* **CDS** – Clinical Decision Support

* **KT** – Knowledge Translation

*(Any remaining acronym is standard Python or statistics; full expansion in footnotes of thesis.)*

---

### **✅ What This Blueprint Guarantees**

1. **No scope creep** – Only one new flag, one auto-encoder, one DML call, one causal-forest call.

2. **No hidden theoretical leaps** – Every method cited in STROBE (Strengthening The Reporting of Observational Studies in Epidemiology) \+ GRACE check-lists.

3. **No interpretability gaps** – Moderators pre-declared, effect sizes reported with confidence intervals and E-values.

4. **No reproducibility doubt** – Make/DVC \+ Docker ensure any reviewer can rebuild end-to-end with one command.

5. **Direct clinician value** – Flag and severity feed a real-world EMR banner; not just an academic exercise.

With this, the thesis reaches journal-ready methodological rigor **without drowning you** in additional analyses or exotic theory.

