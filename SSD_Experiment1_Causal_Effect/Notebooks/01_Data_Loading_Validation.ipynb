{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Data loading \n",
    "- Comprehensive quality checks\n",
    "- Dataset relationship validation\n",
    "- Data completeness reporting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: missingno in c:\\users\\projectc4m\\anaconda3\\lib\\site-packages (0.5.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\projectc4m\\anaconda3\\lib\\site-packages (from missingno) (1.26.4)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\projectc4m\\anaconda3\\lib\\site-packages (from missingno) (3.9.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\projectc4m\\anaconda3\\lib\\site-packages (from missingno) (1.13.1)\n",
      "Requirement already satisfied: seaborn in c:\\users\\projectc4m\\anaconda3\\lib\\site-packages (from missingno) (0.13.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\projectc4m\\anaconda3\\lib\\site-packages (from matplotlib->missingno) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\projectc4m\\anaconda3\\lib\\site-packages (from matplotlib->missingno) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\projectc4m\\anaconda3\\lib\\site-packages (from matplotlib->missingno) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\projectc4m\\anaconda3\\lib\\site-packages (from matplotlib->missingno) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\projectc4m\\anaconda3\\lib\\site-packages (from matplotlib->missingno) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\projectc4m\\anaconda3\\lib\\site-packages (from matplotlib->missingno) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\projectc4m\\anaconda3\\lib\\site-packages (from matplotlib->missingno) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\projectc4m\\anaconda3\\lib\\site-packages (from matplotlib->missingno) (2.9.0.post0)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\projectc4m\\anaconda3\\lib\\site-packages (from seaborn->missingno) (2.2.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\projectc4m\\anaconda3\\lib\\site-packages (from pandas>=1.2->seaborn->missingno) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\projectc4m\\anaconda3\\lib\\site-packages (from pandas>=1.2->seaborn->missingno) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\projectc4m\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->missingno) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~etuptools (C:\\Users\\ProjectC4M\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~etuptools (C:\\Users\\ProjectC4M\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~etuptools (C:\\Users\\ProjectC4M\\anaconda3\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install missingno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------- #\n",
    "# 01_Data_Loading_Validation.ipynb                                             #\n",
    "# ---------------------------------------------------------------------------- #\n",
    "# Purpose: Load CPCSSN datasets for Somatic Symptom Disorder (SSD) causal      #\n",
    "# pathway analysis, validate data quality and relationships, and establish      #\n",
    "# base statistics for downstream analysis.                                     #\n",
    "# ---------------------------------------------------------------------------- #\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import json\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import re\n",
    "import missingno as msno\n",
    "from scipy import stats\n",
    "from IPython.display import display, Markdown, HTML\n",
    "\n",
    "# Configure visualization settings for publication quality\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_context(\"paper\", font_scale=1.5)\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['savefig.dpi'] = 300\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['font.sans-serif'] = ['Arial']\n",
    "\n",
    "# Suppress specific warnings while maintaining important ones\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=pd.errors.PerformanceWarning)\n",
    "pd.options.mode.chained_assignment = None  # Suppress SettingWithCopyWarning\n",
    "\n",
    "# Display options for better readability\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 60)\n",
    "pd.set_option('display.width', 200)\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ------------------------------- Configuration ------------------------------- #\n",
    "\n",
    "# Define paths configuration\n",
    "class Config:\n",
    "    # Base paths\n",
    "    DATA_PATH = Path(r\"C:\\Users\\ProjectC4M\\Documents\\CPCSSN Datasets Care4Mind\\New Extraction Feb 2025\\prepared_data\")\n",
    "    OUTPUT_PATH = Path(\"output\")\n",
    "    INTERIM_PATH = Path(\"data/interim\")\n",
    "    \n",
    "    # Create directories if they don't exist\n",
    "    for path in [OUTPUT_PATH, INTERIM_PATH]:\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "    \n",
    "    # Dataset filenames\n",
    "    DATASETS = {\n",
    "        'patient': 'Patient_prepared.csv',\n",
    "        'patient_demographic': 'PatientDemographic_merged_prepared.csv', \n",
    "        'encounter': 'Encounter_prepared.csv',\n",
    "        'encounter_diagnosis': 'EncounterDiagnosis_prepared.csv',\n",
    "        'health_condition': 'HealthCondition_prepared.csv',\n",
    "        'lab': 'Lab_prepared.csv',\n",
    "        'medication': 'Medication_prepared.csv',\n",
    "        'referral': 'Referral_prepared.csv',\n",
    "        'family_history': 'FamilyHistory_prepared.csv',\n",
    "        'medical_procedure': 'MedicalProcedure_prepared.csv',\n",
    "        'risk_factor': 'RiskFactor_prepared.csv'\n",
    "    }\n",
    "    \n",
    "    # Required columns by table (based on provided configuration)\n",
    "    REQUIRED_COLUMNS = {\n",
    "        'patient': ['Patient_ID', 'Sex', 'BirthYear', 'BirthMonth'],\n",
    "        'patient_demographic': ['Patient_ID', 'PatientDemographic_ID', 'Network_ID', 'Site_ID'],\n",
    "        'encounter': ['Encounter_ID', 'Patient_ID', 'Provider_ID', 'EncounterDate', 'EncounterType'],\n",
    "        'encounter_diagnosis': ['EncounterDiagnosis_ID', 'Encounter_ID', 'Patient_ID', 'DiagnosisCode_calc', 'DiagnosisText_calc'],\n",
    "        'health_condition': ['HealthCondition_ID', 'Patient_ID', 'DiagnosisCode_calc', 'DateOfOnset'],\n",
    "        'lab': ['Lab_ID', 'Patient_ID', 'PerformedDate', 'Name_calc', 'TestResult_calc', 'UpperNormal', 'LowerNormal'],\n",
    "        'medication': ['Medication_ID', 'Patient_ID', 'StartDate', 'StopDate', 'Name_calc'],\n",
    "        'referral': ['Referral_ID', 'Patient_ID', 'CompletedDate', 'Name_calc']\n",
    "    }\n",
    "    \n",
    "    # Date columns that need conversion\n",
    "    DATE_COLUMNS = {\n",
    "        'encounter': ['EncounterDate', 'DateCreated'],\n",
    "        'encounter_diagnosis': ['DateCreated'],\n",
    "        'health_condition': ['DateOfOnset', 'DateCreated'],\n",
    "        'lab': ['PerformedDate', 'DateCreated'],\n",
    "        'medication': ['StartDate', 'StopDate', 'DateCreated'],\n",
    "        'referral': ['CompletedDate', 'DateCreated'],\n",
    "        'medical_procedure': ['PerformedDate', 'DateCreated'],\n",
    "        'risk_factor': ['StartDate', 'EndDate', 'DateCreated']\n",
    "    }\n",
    "    \n",
    "    # Study parameters\n",
    "    CURRENT_YEAR = 2025  # Reference year for age calculations\n",
    "    MIN_AGE = 18  # Inclusion criterion: minimum age\n",
    "    MIN_ENCOUNTERS = 2  # Minimum encounters for inclusion\n",
    "\n",
    "config = Config()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ----------------------------- Helper Functions ----------------------------- #\n",
    "\n",
    "def print_section_header(title):\n",
    "    \"\"\"Print formatted section header for better notebook organization.\"\"\"\n",
    "    display(Markdown(f\"## {title}\"))\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "def print_subsection_header(title):\n",
    "    \"\"\"Print formatted subsection header for better notebook organization.\"\"\"\n",
    "    display(Markdown(f\"### {title}\"))\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "def format_percentage(value):\n",
    "    \"\"\"Format decimal as percentage with 2 decimal places.\"\"\"\n",
    "    return f\"{value:.2%}\"\n",
    "\n",
    "def display_dataset_info(name, df):\n",
    "    \"\"\"Display basic dataset information in a formatted way.\"\"\"\n",
    "    print(f\"Dataset: {name}\")\n",
    "    print(f\"Shape: {df.shape[0]:,} rows × {df.shape[1]} columns\")\n",
    "    print(f\"Memory usage: {df.memory_usage(deep=True).sum() / (1024**2):.2f} MB\")\n",
    "    \n",
    "    # Sample of first few rows\n",
    "    display(df.head(3))\n",
    "    \n",
    "    # Column information\n",
    "    column_info = pd.DataFrame({\n",
    "        'Column': df.columns,\n",
    "        'Type': df.dtypes,\n",
    "        'Non-Null Count': df.count(),\n",
    "        'Non-Null %': df.count() / len(df) * 100,\n",
    "        'Unique Values': [df[col].nunique() for col in df.columns]\n",
    "    })\n",
    "    \n",
    "    display(column_info)\n",
    "    print(\"\\n\")\n",
    "\n",
    "# --------------------------- Main Loading Function -------------------------- #\n",
    "\n",
    "def load_and_validate_data(required_tables=None):\n",
    "    \"\"\"\n",
    "    Load CPCSSN datasets with comprehensive validation and quality checks.\n",
    "    \n",
    "    This function implements a robust data loading pipeline with:\n",
    "    1. Standardized error handling for file access issues\n",
    "    2. Multiple encoding fallbacks (UTF-8, latin1, etc.)\n",
    "    3. Required column validation\n",
    "    4. Automatic date column conversion\n",
    "    5. Data type verification and standardization\n",
    "    6. Basic quality metrics calculation\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    required_tables : list, optional\n",
    "        Specific tables to load; if None, loads all configured tables\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary of dataframes with table names as keys\n",
    "    dict\n",
    "        Dictionary of data quality metrics for each table\n",
    "    \n",
    "    Notes:\n",
    "    ------\n",
    "    The function follows ETL best practices from clinical data research:\n",
    "    - Standardized approach across all tables (Kahn et al., 2016)\n",
    "    - Explicit validation steps (Weiskopf & Weng, 2013)\n",
    "    - Careful attention to date/time handling (Hripcsak & Albers, 2013)\n",
    "    \"\"\"\n",
    "    print_section_header(\"Data Loading and Initial Validation\")\n",
    "    \n",
    "    # If no specific tables are requested, load all\n",
    "    if required_tables is None:\n",
    "        required_tables = config.DATASETS.keys()\n",
    "    \n",
    "    data_dict = {}\n",
    "    quality_metrics = {}\n",
    "    \n",
    "    # Track overall metrics\n",
    "    total_rows = 0\n",
    "    total_files = 0\n",
    "    loading_errors = 0\n",
    "    \n",
    "    for key in required_tables:\n",
    "        if key not in config.DATASETS:\n",
    "            print(f\"WARNING: Table '{key}' not found in configuration.\")\n",
    "            continue\n",
    "            \n",
    "        filename = config.DATASETS[key]\n",
    "        file_path = config.DATA_PATH / filename\n",
    "        \n",
    "        print_subsection_header(f\"Loading {key} ({filename})\")\n",
    "        \n",
    "        # Initialize quality metrics for this table\n",
    "        quality_metrics[key] = {\n",
    "            'exists': False,\n",
    "            'loaded_successfully': False,\n",
    "            'row_count': 0,\n",
    "            'column_count': 0,\n",
    "            'missing_required_columns': [],\n",
    "            'missing_data_percentage': {},\n",
    "            'date_column_quality': {},\n",
    "            'invalid_row_percentage': 0.0,\n",
    "        }\n",
    "        \n",
    "        # Check if file exists\n",
    "        if not file_path.exists():\n",
    "            print(f\"ERROR: File {filename} does not exist at {file_path}\")\n",
    "            continue\n",
    "            \n",
    "        quality_metrics[key]['exists'] = True\n",
    "        total_files += 1\n",
    "        \n",
    "        # Attempt to load with multiple encodings\n",
    "        for encoding in ['utf-8-sig', 'utf-8', 'latin1', 'cp1252']:\n",
    "            try:\n",
    "                # Use chunks for large files (especially Lab and Encounter tables)\n",
    "                # This is crucial for working with large CPCSSN datasets efficiently\n",
    "                if key in ['lab', 'encounter', 'encounter_diagnosis']:\n",
    "                    # For large tables, use chunked reading with dask or chunks\n",
    "                    chunk_size = 500000  # Adjust based on memory constraints\n",
    "                    print(f\"Large table detected. Loading {key} in chunks of {chunk_size:,} rows...\")\n",
    "                    \n",
    "                    chunks = []\n",
    "                    for chunk in pd.read_csv(file_path, encoding=encoding, \n",
    "                                             chunksize=chunk_size, low_memory=False):\n",
    "                        chunks.append(chunk)\n",
    "                    \n",
    "                    if chunks:\n",
    "                        df = pd.concat(chunks, ignore_index=True)\n",
    "                    else:\n",
    "                        df = pd.DataFrame()  # Empty dataframe if no chunks\n",
    "                else:\n",
    "                    # Regular loading for smaller tables\n",
    "                    df = pd.read_csv(file_path, encoding=encoding, low_memory=False)\n",
    "                \n",
    "                print(f\"Successfully loaded with encoding: {encoding}\")\n",
    "                break\n",
    "                \n",
    "            except UnicodeDecodeError:\n",
    "                print(f\"Failed to load with encoding: {encoding}, trying next...\")\n",
    "                continue\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"ERROR loading {filename}: {str(e)}\")\n",
    "                loading_errors += 1\n",
    "                break\n",
    "        else:\n",
    "            # This executes if no break occurs in the for loop (all encodings failed)\n",
    "            print(f\"ERROR: Failed to load {filename} with any encoding\")\n",
    "            continue\n",
    "            \n",
    "        # Mark as successfully loaded\n",
    "        quality_metrics[key]['loaded_successfully'] = True\n",
    "        data_dict[key] = df\n",
    "        \n",
    "        # Basic metrics\n",
    "        row_count = len(df)\n",
    "        col_count = len(df.columns)\n",
    "        total_rows += row_count\n",
    "        \n",
    "        quality_metrics[key]['row_count'] = row_count\n",
    "        quality_metrics[key]['column_count'] = col_count\n",
    "        \n",
    "        print(f\"Loaded {row_count:,} rows and {col_count} columns\")\n",
    "        \n",
    "        # Check for required columns\n",
    "        if key in config.REQUIRED_COLUMNS:\n",
    "            missing_cols = [col for col in config.REQUIRED_COLUMNS[key] \n",
    "                           if col not in df.columns]\n",
    "            \n",
    "            if missing_cols:\n",
    "                print(f\"WARNING: Missing required columns in {key}: {missing_cols}\")\n",
    "                quality_metrics[key]['missing_required_columns'] = missing_cols\n",
    "                \n",
    "        # Convert date columns\n",
    "        if key in config.DATE_COLUMNS:\n",
    "            date_quality = {}\n",
    "            for date_col in config.DATE_COLUMNS[key]:\n",
    "                if date_col in df.columns:\n",
    "                    # Store original count to measure parse failures\n",
    "                    orig_non_null = df[date_col].notna().sum()\n",
    "                    \n",
    "                    # Convert to datetime\n",
    "                    df[date_col] = pd.to_datetime(df[date_col], errors='coerce')\n",
    "                    \n",
    "                    # Measure quality\n",
    "                    new_non_null = df[date_col].notna().sum()\n",
    "                    parse_failure_rate = 1.0 - (new_non_null / orig_non_null) if orig_non_null > 0 else 0\n",
    "                    \n",
    "                    date_quality[date_col] = {\n",
    "                        'coverage': new_non_null / len(df),\n",
    "                        'parse_failure_rate': parse_failure_rate,\n",
    "                        'min_date': df[date_col].min(),\n",
    "                        'max_date': df[date_col].max(),\n",
    "                        'null_count': df[date_col].isna().sum()\n",
    "                    }\n",
    "                    \n",
    "                    print(f\"Converted {date_col} to datetime. \" +\n",
    "                          f\"Parse failures: {parse_failure_rate:.2%}\")\n",
    "            \n",
    "            quality_metrics[key]['date_column_quality'] = date_quality\n",
    "                    \n",
    "        # Calculate missing data percentage per column\n",
    "        missing_pct = df.isna().mean().to_dict()\n",
    "        quality_metrics[key]['missing_data_percentage'] = missing_pct\n",
    "        \n",
    "        # Check for basic invalid data\n",
    "        # For numeric columns, check for out-of-range values\n",
    "        invalid_rows = 0\n",
    "        # Add specific validation based on column types\n",
    "        \n",
    "        # Calculate quality statistics\n",
    "        high_missing_cols = [col for col, pct in missing_pct.items() if pct > 0.2]\n",
    "        if high_missing_cols:\n",
    "            print(f\"WARNING: High missing data (>20%) in columns: {high_missing_cols}\")\n",
    "            \n",
    "    # Print overall summary\n",
    "    print_section_header(\"Data Loading Summary\")\n",
    "    print(f\"Successfully loaded {total_files} files with {total_rows:,} total rows\")\n",
    "    if loading_errors > 0:\n",
    "        print(f\"WARNING: Encountered {loading_errors} loading errors\")\n",
    "        \n",
    "    return data_dict, quality_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --------------------------- Data Validation Functions -------------------------- #\n",
    "\n",
    "def validate_data_relationships(data_dict):\n",
    "    \"\"\"\n",
    "    Validate foreign key relationships between datasets to ensure referential integrity.\n",
    "    \n",
    "    This function checks how well foreign keys in dependent tables (e.g., encounters, labs)\n",
    "    match primary keys in reference tables (e.g., patients). High integrity is crucial for\n",
    "    reliable analysis, as broken references can lead to data loss during joins.\n",
    "    \n",
    "    The function implements recommendations from:\n",
    "    - Kahn et al. (2016) \"A Harmonized Data Quality Assessment Terminology and Framework...\"\n",
    "    - Weiskopf & Weng (2013) \"Methods and dimensions of electronic health record data quality...\"\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data_dict : dict\n",
    "        Dictionary of dataframes with table names as keys\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary of relationship metrics between tables\n",
    "    \"\"\"\n",
    "    print_section_header(\"Data Relationship Validation\")\n",
    "    \n",
    "    relationships = {}\n",
    "    \n",
    "    # Define key relationships to check\n",
    "    key_relationships = [\n",
    "        # dependent_table, reference_table, foreign_key, primary_key\n",
    "        ('encounter', 'patient', 'Patient_ID', 'Patient_ID'),\n",
    "        ('encounter_diagnosis', 'encounter', 'Encounter_ID', 'Encounter_ID'),\n",
    "        ('encounter_diagnosis', 'patient', 'Patient_ID', 'Patient_ID'),\n",
    "        ('lab', 'patient', 'Patient_ID', 'Patient_ID'),\n",
    "        ('lab', 'encounter', 'Encounter_ID', 'Encounter_ID'),\n",
    "        ('medication', 'patient', 'Patient_ID', 'Patient_ID'),\n",
    "        ('referral', 'patient', 'Patient_ID', 'Patient_ID'),\n",
    "        ('health_condition', 'patient', 'Patient_ID', 'Patient_ID')\n",
    "    ]\n",
    "    \n",
    "    for dep_table, ref_table, fk, pk in key_relationships:\n",
    "        # Skip if either table is missing\n",
    "        if dep_table not in data_dict or ref_table not in data_dict:\n",
    "            print(f\"Skipping relationship check: {dep_table}.{fk} -> {ref_table}.{pk} (table missing)\")\n",
    "            continue\n",
    "            \n",
    "        # Skip if columns don't exist\n",
    "        if fk not in data_dict[dep_table].columns or pk not in data_dict[ref_table].columns:\n",
    "            print(f\"Skipping relationship check: {dep_table}.{fk} -> {ref_table}.{pk} (column missing)\")\n",
    "            continue\n",
    "            \n",
    "        # Get unique keys from both tables\n",
    "        dep_keys = set(data_dict[dep_table][fk].dropna().unique())\n",
    "        ref_keys = set(data_dict[ref_table][pk].dropna().unique())\n",
    "        \n",
    "        # Calculate metrics\n",
    "        matching_keys = dep_keys.intersection(ref_keys)\n",
    "        orphaned_keys = dep_keys - ref_keys\n",
    "        \n",
    "        # As percentages\n",
    "        total_dep_keys = len(dep_keys)\n",
    "        match_pct = len(matching_keys) / total_dep_keys if total_dep_keys > 0 else 0\n",
    "        orphan_pct = len(orphaned_keys) / total_dep_keys if total_dep_keys > 0 else 0\n",
    "        \n",
    "        # Store metrics\n",
    "        rel_key = f\"{dep_table}.{fk} -> {ref_table}.{pk}\"\n",
    "        relationships[rel_key] = {\n",
    "            'dependent_table': dep_table,\n",
    "            'reference_table': ref_table,\n",
    "            'foreign_key': fk,\n",
    "            'primary_key': pk,\n",
    "            'total_unique_keys': total_dep_keys,\n",
    "            'matching_keys': len(matching_keys),\n",
    "            'orphaned_keys': len(orphaned_keys),\n",
    "            'match_percentage': match_pct,\n",
    "            'orphan_percentage': orphan_pct\n",
    "        }\n",
    "        \n",
    "        # Print summary\n",
    "        print(f\"Relationship: {rel_key}\")\n",
    "        print(f\"  Match rate: {match_pct:.2%} ({len(matching_keys):,}/{total_dep_keys:,} keys)\")\n",
    "        if orphan_pct > 0:\n",
    "            print(f\"  Orphaned records: {orphan_pct:.2%} ({len(orphaned_keys):,} keys)\")\n",
    "            # Show sample of orphaned keys (useful for debugging)\n",
    "            if len(orphaned_keys) <= 5:\n",
    "                print(f\"  Sample orphaned keys: {list(orphaned_keys)}\")\n",
    "            else:\n",
    "                print(f\"  Sample orphaned keys: {list(orphaned_keys)[:5]} ...\")\n",
    "        print()\n",
    "        \n",
    "    # Create summary table for visualization\n",
    "    if relationships:\n",
    "        rel_df = pd.DataFrame([\n",
    "            {\n",
    "                'Relationship': k,\n",
    "                'Match Rate': v['match_percentage'],\n",
    "                'Orphaned Rate': v['orphan_percentage'],\n",
    "                'Total Keys': v['total_unique_keys']\n",
    "            }\n",
    "            for k, v in relationships.items()\n",
    "        ])\n",
    "        \n",
    "        # Sort by match rate\n",
    "        rel_df = rel_df.sort_values('Match Rate')\n",
    "        \n",
    "        # Plot relationship metrics\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        bars = plt.barh(rel_df['Relationship'], rel_df['Match Rate'])\n",
    "        \n",
    "        # Add percentage labels\n",
    "        for i, bar in enumerate(bars):\n",
    "            width = bar.get_width()\n",
    "            label = f\"{width:.1%}\"\n",
    "            plt.text(max(0.05, width - 0.1), bar.get_y() + bar.get_height()/2, \n",
    "                    label, ha='center', va='center', color='white', fontweight='bold')\n",
    "        \n",
    "        plt.xlabel('Match Rate (% of dependent keys found in reference table)')\n",
    "        plt.title('Data Relationship Integrity')\n",
    "        plt.xlim(0, 1.0)\n",
    "        plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(config.OUTPUT_PATH / 'relationship_integrity.png')\n",
    "        plt.close()\n",
    "        \n",
    "    return relationships\n",
    "\n",
    "def validate_temporal_consistency(data_dict):\n",
    "    \"\"\"\n",
    "    Validate temporal consistency in date columns across datasets.\n",
    "    \n",
    "    This function checks for:\n",
    "    1. Chronological consistency (e.g., start dates before end dates)\n",
    "    2. Date ranges within reasonable study period\n",
    "    3. Temporal alignment between related events\n",
    "    \n",
    "    Temporal consistency is essential for accurate pathway analysis, especially for\n",
    "    establishing the correct sequence of NYD status, lab tests, referrals, and diagnoses.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data_dict : dict\n",
    "        Dictionary of dataframes with table names as keys\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary of temporal consistency metrics\n",
    "    \"\"\"\n",
    "    print_section_header(\"Temporal Consistency Validation\")\n",
    "    \n",
    "    temporal_metrics = {}\n",
    "    \n",
    "    # 1. Check date ranges in each table\n",
    "    print_subsection_header(\"Date ranges by table\")\n",
    "    \n",
    "    for table_name, df in data_dict.items():\n",
    "        date_cols = [col for col in df.columns if pd.api.types.is_datetime64_dtype(df[col])]\n",
    "        if not date_cols:\n",
    "            continue\n",
    "            \n",
    "        table_metrics = {}\n",
    "        print(f\"Table: {table_name}\")\n",
    "        \n",
    "        for col in date_cols:\n",
    "            # Skip if all null\n",
    "            if df[col].isna().all():\n",
    "                continue\n",
    "                \n",
    "            min_date = df[col].min()\n",
    "            max_date = df[col].max()\n",
    "            null_count = df[col].isna().sum()\n",
    "            null_pct = null_count / len(df)\n",
    "            \n",
    "            # Check for future dates (beyond current study year)\n",
    "            future_date_threshold = pd.Timestamp(f\"{config.CURRENT_YEAR+1}-01-01\")\n",
    "            future_dates = df[col] >= future_date_threshold\n",
    "            future_count = future_dates.sum()\n",
    "            future_pct = future_count / df[col].notna().sum() if df[col].notna().any() else 0\n",
    "            \n",
    "            # Check for implausible past dates (before 1900)\n",
    "            past_date_threshold = pd.Timestamp(\"1900-01-01\")\n",
    "            past_dates = df[col] < past_date_threshold\n",
    "            past_count = past_dates.sum()\n",
    "            past_pct = past_count / df[col].notna().sum() if df[col].notna().any() else 0\n",
    "            \n",
    "            print(f\"  {col}: {min_date} to {max_date} (Null: {null_pct:.2%})\")\n",
    "            if future_pct > 0:\n",
    "                print(f\"    WARNING: {future_pct:.2%} ({future_count:,}) future dates beyond {config.CURRENT_YEAR}\")\n",
    "            if past_pct > 0:\n",
    "                print(f\"    WARNING: {past_pct:.2%} ({past_count:,}) implausibly old dates before 1900\")\n",
    "                \n",
    "            table_metrics[col] = {\n",
    "                'min_date': min_date,\n",
    "                'max_date': max_date,\n",
    "                'null_percentage': null_pct,\n",
    "                'future_date_percentage': future_pct,\n",
    "                'past_date_percentage': past_pct\n",
    "            }\n",
    "            \n",
    "        temporal_metrics[table_name] = table_metrics\n",
    "        \n",
    "    # 2. Check for specific date sequence consistency\n",
    "    print_subsection_header(\"Date sequence validation\")\n",
    "    \n",
    "    # Medication: StartDate before StopDate\n",
    "    if 'medication' in data_dict and 'StartDate' in data_dict['medication'].columns and 'StopDate' in data_dict['medication'].columns:\n",
    "        med_df = data_dict['medication']\n",
    "        # Only check rows with both dates non-null\n",
    "        both_dates = med_df['StartDate'].notna() & med_df['StopDate'].notna()\n",
    "        total_both_dates = both_dates.sum()\n",
    "        \n",
    "        if total_both_dates > 0:\n",
    "            invalid_sequence = (med_df['StartDate'] > med_df['StopDate']) & both_dates\n",
    "            invalid_count = invalid_sequence.sum()\n",
    "            invalid_pct = invalid_count / total_both_dates\n",
    "            \n",
    "            print(f\"Medication - StartDate before StopDate: {(1-invalid_pct):.2%} valid\")\n",
    "            if invalid_pct > 0:\n",
    "                print(f\"  WARNING: {invalid_pct:.2%} ({invalid_count:,}/{total_both_dates:,}) \" +\n",
    "                      f\"medication records have StartDate after StopDate\")\n",
    "                \n",
    "            temporal_metrics['medication_sequence'] = {\n",
    "                'check': 'StartDate_before_StopDate',\n",
    "                'valid_percentage': 1 - invalid_pct,\n",
    "                'invalid_count': invalid_count,\n",
    "                'total_checked': total_both_dates\n",
    "            }\n",
    "    \n",
    "    # 3. Check referral sequences for patients (relevant for pathway analysis)\n",
    "    if 'referral' in data_dict and 'CompletedDate' in data_dict['referral'].columns:\n",
    "        ref_df = data_dict['referral']\n",
    "        # Group by patient and sort by date\n",
    "        patient_ref_counts = ref_df.groupby('Patient_ID')['CompletedDate'].count()\n",
    "        multiple_refs = (patient_ref_counts > 1).sum()\n",
    "        multiple_refs_pct = multiple_refs / len(patient_ref_counts)\n",
    "        \n",
    "        print(f\"Referral sequences: {multiple_refs_pct:.2%} ({multiple_refs:,}/{len(patient_ref_counts):,}) \" +\n",
    "              f\"patients have multiple referrals\")\n",
    "              \n",
    "        temporal_metrics['referral_sequence'] = {\n",
    "            'check': 'multiple_referrals',\n",
    "            'patients_with_multiple_refs': multiple_refs,\n",
    "            'percentage': multiple_refs_pct\n",
    "        }\n",
    "    \n",
    "    # 4. Visualize date distributions\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Collect date ranges for key tables\n",
    "    key_tables = ['encounter', 'lab', 'medication', 'referral']\n",
    "    date_ranges = []\n",
    "    \n",
    "    for table in key_tables:\n",
    "        if table not in temporal_metrics:\n",
    "            continue\n",
    "            \n",
    "        for col, metrics in temporal_metrics[table].items():\n",
    "            if 'min_date' in metrics and 'max_date' in metrics:\n",
    "                date_ranges.append({\n",
    "                    'table': table,\n",
    "                    'column': col,\n",
    "                    'min_date': metrics['min_date'],\n",
    "                    'max_date': metrics['max_date']\n",
    "                })\n",
    "    \n",
    "    # Create date range plot\n",
    "    if date_ranges:\n",
    "        df_ranges = pd.DataFrame(date_ranges)\n",
    "        df_ranges['label'] = df_ranges['table'] + '.' + df_ranges['column']\n",
    "        \n",
    "        # Sort by min_date\n",
    "        df_ranges = df_ranges.sort_values('min_date')\n",
    "        \n",
    "        # Plot\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        for i, row in df_ranges.iterrows():\n",
    "            plt.plot([row['min_date'], row['max_date']], [i, i], 'o-', linewidth=2, markersize=8)\n",
    "            plt.text(row['min_date'], i+0.1, row['min_date'].strftime('%Y-%m-%d'), fontsize=9)\n",
    "            plt.text(row['max_date'], i+0.1, row['max_date'].strftime('%Y-%m-%d'), fontsize=9)\n",
    "            \n",
    "        plt.yticks(range(len(df_ranges)), df_ranges['label'])\n",
    "        plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "        plt.title('Date Ranges by Table and Column')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(config.OUTPUT_PATH / 'date_ranges.png')\n",
    "        plt.close()\n",
    "    \n",
    "    return temporal_metrics\n",
    "\n",
    "def analyze_patient_population(data_dict):\n",
    "    \"\"\"\n",
    "    Analyze the patient population demographics and coverage.\n",
    "    \n",
    "    This function:\n",
    "    1. Analyzes core demographic distributions (age, sex)\n",
    "    2. Checks data coverage across key tables for patient cohort\n",
    "    3. Identifies potential inclusion/exclusion issues\n",
    "    \n",
    "    Understanding the patient population is essential for:\n",
    "    - Assessing potential selection bias (Haneuse & Daniels, 2016)\n",
    "    - Ensuring adequate representation across key strata (Deeny & Steventon, 2015)\n",
    "    - Establishing the generalizability of findings (Hersh et al., 2013)\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data_dict : dict\n",
    "        Dictionary of dataframes with table names as keys\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary of population metrics\n",
    "    \"\"\"\n",
    "    print_section_header(\"Patient Population Analysis\")\n",
    "    \n",
    "    population_metrics = {}\n",
    "    \n",
    "    # Exit if patient table is missing\n",
    "    if 'patient' not in data_dict:\n",
    "        print(\"ERROR: Patient table missing, cannot analyze population\")\n",
    "        return population_metrics\n",
    "        \n",
    "    patient_df = data_dict['patient']\n",
    "\n",
    "    if 'Sex' in patient_df.columns:\n",
    "        # Normalize sex values to standardized format\n",
    "        sex_mapping = {\n",
    "            'F': 'Female', 'FEMALE': 'Female', 'Female': 'Female', \n",
    "            'M': 'Male', 'MALE': 'Male', 'Male': 'Male',\n",
    "            'U': 'Unknown', 'Unknown': 'Unknown', \n",
    "            'Undifferentiated': 'Other'\n",
    "        }\n",
    "        \n",
    "        # Apply mapping (preserve original for reference)\n",
    "        patient_df['Sex_normalized'] = patient_df['Sex'].map(sex_mapping).fillna('Unknown')\n",
    "        \n",
    "        # Get normalized distribution\n",
    "        sex_counts = patient_df['Sex_normalized'].value_counts()\n",
    "        sex_pct = sex_counts / len(patient_df) * 100\n",
    "        \n",
    "        print(\"\\nNormalized sex distribution:\")\n",
    "        for sex, count in sex_counts.items():\n",
    "            print(f\"  {sex}: {count:,} ({sex_pct[sex]:.1f}%)\")\n",
    "            \n",
    "        # Store in metrics\n",
    "        population_metrics['sex_normalized'] = {\n",
    "            'counts': sex_counts.to_dict(),\n",
    "            'percentage': sex_pct.to_dict()\n",
    "        }\n",
    "        \n",
    "        # Create visualization with normalized values\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        ax = sns.barplot(x=sex_counts.index, y=sex_counts.values)\n",
    "        plt.title('Patient Sex Distribution (Normalized)', fontsize=14)\n",
    "        plt.xlabel('Sex', fontsize=12)\n",
    "        plt.ylabel('Number of Patients', fontsize=12)\n",
    "        \n",
    "        # Add count and percentage labels\n",
    "        for i, p in enumerate(ax.patches):\n",
    "            height = p.get_height()\n",
    "            percentage = sex_pct.iloc[i]\n",
    "            ax.text(p.get_x() + p.get_width()/2., height + height*0.02,\n",
    "                   f'{int(height):,}\\n({percentage:.1f}%)', \n",
    "                   ha=\"center\", va=\"bottom\", fontsize=9)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(config.OUTPUT_PATH / 'sex_distribution_normalized.png')\n",
    "        plt.close()\n",
    "        \n",
    "    \n",
    "    # 1. Basic demographic analysis\n",
    "    print_subsection_header(\"Demographic Distribution\")\n",
    "    \n",
    "    # Calculate age from birth year\n",
    "    if 'BirthYear' in patient_df.columns:\n",
    "        # Check if birth year is valid (not future, not unreasonably old)\n",
    "        current_year = config.CURRENT_YEAR\n",
    "        # Filter out clearly invalid birth years\n",
    "        invalid_birth_mask = (patient_df['BirthYear'] > current_year) | (patient_df['BirthYear'] < 1900)\n",
    "        if invalid_birth_mask.any():\n",
    "            print(f\"WARNING: Found {invalid_birth_mask.sum()} patients with invalid birth years. Setting to NaN.\")\n",
    "            patient_df.loc[invalid_birth_mask, 'BirthYear'] = np.nan\n",
    "        \n",
    "        # Check if DeceasedYear column exists in demographic data\n",
    "        has_deceased_info = ('patient_demographic' in data_dict and \n",
    "                            'DeceasedYear' in data_dict['patient_demographic'].columns)\n",
    "    \n",
    "        # Base age calculation using current year\n",
    "        patient_df['Age'] = current_year - patient_df['BirthYear']\n",
    "        \n",
    "        if has_deceased_info:\n",
    "            # Get only the necessary columns from demographic data to avoid duplicate columns in merge\n",
    "            demo_df = data_dict['patient_demographic'][['Patient_ID', 'DeceasedYear']].copy()\n",
    "            \n",
    "            # Remove duplicates if any exist in demographic data\n",
    "            if demo_df['Patient_ID'].duplicated().any():\n",
    "                print(f\"WARNING: Found {demo_df['Patient_ID'].duplicated().sum()} duplicate Patient_IDs in demographic data.\")\n",
    "                # Keep the first occurrence of each Patient_ID\n",
    "                demo_df = demo_df.drop_duplicates('Patient_ID')\n",
    "            \n",
    "            # Merge with demographic data to get deceased year\n",
    "            patient_df = patient_df.merge(demo_df, on='Patient_ID', how='left')\n",
    "            \n",
    "            # Validate DeceasedYear values\n",
    "            # - Must be not null\n",
    "            # - Must be a reasonable year (not future, not before birth year)\n",
    "            # - Must be after birth year\n",
    "            valid_deceased_mask = (\n",
    "                patient_df['DeceasedYear'].notna() & \n",
    "                (patient_df['DeceasedYear'] > 0) &\n",
    "                (patient_df['DeceasedYear'] <= current_year) &\n",
    "                (patient_df['DeceasedYear'] >= patient_df['BirthYear'])\n",
    "            )\n",
    "            \n",
    "            # Create reference year column (either death year or current year)\n",
    "            patient_df['reference_year'] = current_year  # Default to current year\n",
    "            \n",
    "            # Only update reference year for valid deceased records\n",
    "            if valid_deceased_mask.any():\n",
    "                patient_df.loc[valid_deceased_mask, 'reference_year'] = patient_df.loc[valid_deceased_mask, 'DeceasedYear']\n",
    "                \n",
    "                # Flag invalid deceased years\n",
    "                invalid_deceased = patient_df['DeceasedYear'].notna() & ~valid_deceased_mask\n",
    "                if invalid_deceased.any():\n",
    "                    print(f\"WARNING: Found {invalid_deceased.sum()} patients with invalid death years. \"\n",
    "                        f\"Using current year for age calculation instead.\")\n",
    "            \n",
    "            # Calculate corrected age using either death year or current year\n",
    "            patient_df['Age'] = patient_df['reference_year'] - patient_df['BirthYear']\n",
    "            \n",
    "            # Report on deceased patients\n",
    "            deceased_count = valid_deceased_mask.sum()\n",
    "            print(f\"Deceased patients with valid death year: {deceased_count:,} \"\n",
    "                f\"({deceased_count/len(patient_df)*100:.2f}%)\")\n",
    "        else:\n",
    "            # Standard age calculation based on current year\n",
    "            patient_df['Age'] = current_year - patient_df['BirthYear']\n",
    "        \n",
    "        # Cap implausible ages to avoid outliers affecting statistics\n",
    "        # Handle maximum age cap (e.g., 110 years)\n",
    "        max_age_cap = 110\n",
    "        too_old_mask = patient_df['Age'] > max_age_cap\n",
    "        if too_old_mask.any():\n",
    "            print(f\"WARNING: Found {too_old_mask.sum()} patients with ages > {max_age_cap}. Capping at {max_age_cap}.\")\n",
    "            patient_df.loc[too_old_mask, 'Age'] = max_age_cap\n",
    "        \n",
    "        # Handle negative ages (data error)\n",
    "        negative_age_mask = patient_df['Age'] < 0\n",
    "        if negative_age_mask.any():\n",
    "            print(f\"WARNING: Found {negative_age_mask.sum()} patients with negative ages. Setting to NaN.\")\n",
    "            patient_df.loc[negative_age_mask, 'Age'] = np.nan\n",
    "            \n",
    "        # Age statistics (ignoring NaN values)\n",
    "        age_mean = patient_df['Age'].mean()\n",
    "        age_median = patient_df['Age'].median()\n",
    "        age_min = patient_df['Age'].min()\n",
    "        age_max = patient_df['Age'].max()\n",
    "        \n",
    "        print(f\"Age statistics (as of {config.CURRENT_YEAR}):\")\n",
    "        print(f\"  Mean: {age_mean:.1f} years\")\n",
    "        print(f\"  Median: {age_median:.1f} years\")\n",
    "        print(f\"  Range: {age_min} to {age_max} years\")\n",
    "        \n",
    "        # Age distribution with standard age groups\n",
    "        # Option 1: Standard age groups (pediatric, adult, senior divisions)\n",
    "        age_bins = [0, 18, 35, 50, 65, 80, max_age_cap]\n",
    "        age_labels = ['<18', '18-34', '35-49', '50-64', '65-79', '80+']\n",
    "        \n",
    "        # For easier customization, you could use one of these alternative binning schemes:\n",
    "        # Option 2: Decades for more granular view\n",
    "        # age_bins = [0, 10, 20, 30, 40, 50, 60, 70, 80, 90, max_age_cap]\n",
    "        # age_labels = ['0-9', '10-19', '20-29', '30-39', '40-49', '50-59', '60-69', '70-79', '80-89', '90+']\n",
    "        \n",
    "        # Option 3: More detailed pediatric and geriatric groups\n",
    "        # age_bins = [0, 2, 5, 12, 18, 35, 50, 65, 75, 85, max_age_cap]\n",
    "        # age_labels = ['0-1', '2-4', '5-11', '12-17', '18-34', '35-49', '50-64', '65-74', '75-84', '85+']\n",
    "        \n",
    "        # Create age groups, handling NaN values\n",
    "        patient_df['Age_Group'] = pd.cut(patient_df['Age'], bins=age_bins, labels=age_labels)\n",
    "        \n",
    "        # Calculate distribution, excluding NaN values\n",
    "        valid_age_mask = patient_df['Age_Group'].notna()\n",
    "        if (~valid_age_mask).any():\n",
    "            print(f\"WARNING: {(~valid_age_mask).sum()} patients have missing age data and are excluded from age distribution.\")\n",
    "        \n",
    "        # Calculate distribution based on valid ages only\n",
    "        age_dist = patient_df.loc[valid_age_mask, 'Age_Group'].value_counts().sort_index()\n",
    "        age_pct = age_dist / valid_age_mask.sum() * 100\n",
    "        \n",
    "        # Display age distribution\n",
    "        age_table = pd.DataFrame({\n",
    "            'Age Group': age_dist.index,\n",
    "            'Count': age_dist.values,\n",
    "            'Percentage': age_pct.values\n",
    "        })\n",
    "        \n",
    "        print(\"\\nAge distribution:\")\n",
    "        display(age_table)\n",
    "        \n",
    "        # Store in metrics\n",
    "        population_metrics['age'] = {\n",
    "            'mean': age_mean,\n",
    "            'median': age_median,\n",
    "            'min': age_min,\n",
    "            'max': age_max,\n",
    "            'distribution': age_dist.to_dict(),\n",
    "            'percentage': age_pct.to_dict(),\n",
    "            'excluded_count': (~valid_age_mask).sum() if (~valid_age_mask).any() else 0\n",
    "        }\n",
    "        \n",
    "        # Plot age distribution\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        ax = sns.barplot(x=age_dist.index, y=age_dist.values)\n",
    "        plt.title('Patient Age Distribution', fontsize=14)\n",
    "        plt.xlabel('Age Group', fontsize=12)\n",
    "        plt.ylabel('Number of Patients', fontsize=12)\n",
    "        \n",
    "        # Add count and percentage labels\n",
    "        for i, p in enumerate(ax.patches):\n",
    "            height = p.get_height()\n",
    "            percentage = age_pct.iloc[i]\n",
    "            ax.text(p.get_x() + p.get_width()/2., height + height*0.02,\n",
    "                f'{int(height):,}\\n({percentage:.1f}%)', \n",
    "                ha=\"center\", va=\"bottom\", fontsize=9)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(config.OUTPUT_PATH / 'age_distribution.png')\n",
    "        plt.close()\n",
    "\n",
    "        # Add a note if there were data quality issues\n",
    "        quality_issues = invalid_birth_mask.sum() + (\n",
    "            negative_age_mask.sum() if 'negative_age_mask' in locals() else 0\n",
    "        )\n",
    "        if quality_issues > 0:\n",
    "            print(f\"\\nNOTE: Found {quality_issues} patients with age data quality issues.\")\n",
    "            print(\"      See warnings above for details.\")\n",
    "            \n",
    "            # Add quality metrics\n",
    "            population_metrics['age']['data_quality_issues'] = {\n",
    "                'invalid_birth_year': invalid_birth_mask.sum(),\n",
    "                'negative_age': negative_age_mask.sum() if 'negative_age_mask' in locals() else 0,\n",
    "                'too_old': too_old_mask.sum() if 'too_old_mask' in locals() else 0\n",
    "            }\n",
    "    else:\n",
    "        print(\"WARNING: 'BirthYear' column not found, age calculations skipped\")\n",
    "    \n",
    "    # Sex distribution\n",
    "    if 'Sex' in patient_df.columns:\n",
    "        sex_counts = patient_df['Sex'].value_counts()\n",
    "        sex_pct = sex_counts / len(patient_df) * 100\n",
    "        \n",
    "        print(\"\\nSex distribution:\")\n",
    "        for sex, count in sex_counts.items():\n",
    "            print(f\"  {sex}: {count:,} ({sex_pct[sex]:.1f}%)\")\n",
    "            \n",
    "        # Store in metrics\n",
    "        population_metrics['sex'] = {\n",
    "            'counts': sex_counts.to_dict(),\n",
    "            'percentage': sex_pct.to_dict()\n",
    "        }\n",
    "        \n",
    "        # Plot sex distribution\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        ax = sns.barplot(x=sex_counts.index, y=sex_counts.values)\n",
    "        plt.title('Patient Sex Distribution', fontsize=14)\n",
    "        plt.xlabel('Sex', fontsize=12)\n",
    "        plt.ylabel('Number of Patients', fontsize=12)\n",
    "        \n",
    "        # Add count and percentage labels\n",
    "        for i, p in enumerate(ax.patches):\n",
    "            height = p.get_height()\n",
    "            percentage = sex_pct.iloc[i]\n",
    "            ax.text(p.get_x() + p.get_width()/2., height + height*0.02,\n",
    "                   f'{int(height):,}\\n({percentage:.1f}%)', \n",
    "                   ha=\"center\", va=\"bottom\", fontsize=9)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(config.OUTPUT_PATH / 'sex_distribution.png')\n",
    "        plt.close()\n",
    "    \n",
    "    # 2. Data coverage across tables\n",
    "    print_subsection_header(\"Patient Data Coverage\")\n",
    "    \n",
    "    # Get patient ID sets for each table\n",
    "    coverage = {}\n",
    "    all_patients = set(patient_df['Patient_ID'])\n",
    "    total_patients = len(all_patients)\n",
    "    \n",
    "    for table, df in data_dict.items():\n",
    "        if table == 'patient':\n",
    "            continue\n",
    "            \n",
    "        if 'Patient_ID' in df.columns:\n",
    "            table_patients = set(df['Patient_ID'].unique())\n",
    "            overlap = table_patients.intersection(all_patients)\n",
    "            \n",
    "            coverage_pct = len(overlap) / total_patients\n",
    "            coverage[table] = {\n",
    "                'patients': len(overlap),\n",
    "                'percentage': coverage_pct\n",
    "            }\n",
    "            \n",
    "            print(f\"{table}: {coverage_pct:.2%} ({len(overlap):,}/{total_patients:,} patients)\")\n",
    "    \n",
    "    # Create intersection visualization\n",
    "    if coverage:\n",
    "        # Sort tables by coverage\n",
    "        sorted_tables = sorted(coverage.keys(), key=lambda x: coverage[x]['percentage'], reverse=True)\n",
    "        \n",
    "        # Create bar chart of coverage\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        coverage_vals = [coverage[t]['percentage'] for t in sorted_tables]\n",
    "        bars = plt.barh(sorted_tables, coverage_vals)\n",
    "        \n",
    "        # Add percentage labels\n",
    "        for i, bar in enumerate(bars):\n",
    "            width = bar.get_width()\n",
    "            label = f\"{width:.1%}\"\n",
    "            plt.text(max(0.05, width - 0.1), bar.get_y() + bar.get_height()/2, \n",
    "                    label, ha='center', va='center', color='white', fontweight='bold')\n",
    "        \n",
    "        plt.xlabel('Percentage of Patients with Data')\n",
    "        plt.title('Patient Coverage by Data Table')\n",
    "        plt.xlim(0, 1.0)\n",
    "        plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(config.OUTPUT_PATH / 'patient_coverage.png')\n",
    "        plt.close()\n",
    "    \n",
    "    # Store in metrics\n",
    "    population_metrics['coverage'] = coverage\n",
    "    \n",
    "    # 3. Eligibility analysis based on protocol criteria\n",
    "    print_subsection_header(\"Study Eligibility Analysis\")\n",
    "    \n",
    "    # Age eligibility (adults ≥18)\n",
    "    if 'Age' in patient_df.columns:\n",
    "        age_eligible = patient_df['Age'] >= config.MIN_AGE\n",
    "        age_eligible_count = age_eligible.sum()\n",
    "        age_eligible_pct = age_eligible_count / len(patient_df)\n",
    "        \n",
    "        print(f\"Age eligible (≥{config.MIN_AGE}): {age_eligible_pct:.2%} ({age_eligible_count:,}/{len(patient_df):,} patients)\")\n",
    "    \n",
    "    # Encounter eligibility (≥2 encounters)\n",
    "    if 'encounter' in data_dict and 'Patient_ID' in data_dict['encounter'].columns:\n",
    "        encounter_counts = data_dict['encounter']['Patient_ID'].value_counts()\n",
    "        encounter_eligible = encounter_counts[encounter_counts >= config.MIN_ENCOUNTERS]\n",
    "        encounter_eligible_count = len(encounter_eligible)\n",
    "        encounter_eligible_pct = encounter_eligible_count / len(patient_df)\n",
    "        \n",
    "        print(f\"Encounter eligible (≥{config.MIN_ENCOUNTERS} encounters): \" +\n",
    "              f\"{encounter_eligible_pct:.2%} ({encounter_eligible_count:,}/{len(patient_df):,} patients)\")\n",
    "        \n",
    "        # Encounter statistics\n",
    "        enc_mean = encounter_counts.mean()\n",
    "        enc_median = encounter_counts.median()\n",
    "        enc_p90 = encounter_counts.quantile(0.9)\n",
    "        \n",
    "        print(f\"Encounter statistics:\")\n",
    "        print(f\"  Mean: {enc_mean:.1f} encounters per patient\")\n",
    "        print(f\"  Median: {enc_median:.0f} encounters per patient\")\n",
    "        print(f\"  90th percentile: {enc_p90:.0f} encounters per patient\")\n",
    "        \n",
    "        # Store in metrics\n",
    "        population_metrics['encounters'] = {\n",
    "            'mean': enc_mean,\n",
    "            'median': enc_median,\n",
    "            'p90': enc_p90,\n",
    "            'eligible_count': encounter_eligible_count,\n",
    "            'eligible_percentage': encounter_eligible_pct\n",
    "        }\n",
    "        \n",
    "        # Create histogram of encounter counts\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        # Log transform for better visualization\n",
    "        log_counts = np.log10(encounter_counts + 1)  # +1 to handle zeros\n",
    "        plt.hist(log_counts, bins=50)\n",
    "        plt.title('Distribution of Encounters per Patient (Log Scale)', fontsize=14)\n",
    "        plt.xlabel('log10(Encounters + 1)', fontsize=12)\n",
    "        plt.ylabel('Number of Patients', fontsize=12)\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(config.OUTPUT_PATH / 'encounter_distribution.png')\n",
    "        plt.close()\n",
    "    \n",
    "    # 4. Combined eligibility criteria\n",
    "    if 'Age' in patient_df.columns and 'encounter' in data_dict:\n",
    "        # Get patient IDs with sufficient encounters\n",
    "        encounter_counts = data_dict['encounter']['Patient_ID'].value_counts()\n",
    "        encounter_eligible_ids = set(encounter_counts[encounter_counts >= config.MIN_ENCOUNTERS].index)\n",
    "        \n",
    "        # Combine with age eligibility\n",
    "        age_eligible_ids = set(patient_df.loc[patient_df['Age'] >= config.MIN_AGE, 'Patient_ID'])\n",
    "        \n",
    "        # Intersection\n",
    "        eligible_ids = age_eligible_ids.intersection(encounter_eligible_ids)\n",
    "        eligible_count = len(eligible_ids)\n",
    "        eligible_pct = eligible_count / len(patient_df)\n",
    "        \n",
    "        print(f\"\\nCombined eligibility (age ≥{config.MIN_AGE} AND ≥{config.MIN_ENCOUNTERS} encounters): \" +\n",
    "              f\"{eligible_pct:.2%} ({eligible_count:,}/{len(patient_df):,} patients)\")\n",
    "              \n",
    "        # Store in metrics\n",
    "        population_metrics['combined_eligibility'] = {\n",
    "            'eligible_count': eligible_count,\n",
    "            'eligible_percentage': eligible_pct,\n",
    "            'age_criteria': f\"≥{config.MIN_AGE}\",\n",
    "            'encounter_criteria': f\"≥{config.MIN_ENCOUNTERS}\"\n",
    "        }\n",
    "    \n",
    "    return population_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --------------------------- Data Validation Functions -------------------------- #\n",
    "\n",
    "def validate_data_relationships(data_dict):\n",
    "    \"\"\"\n",
    "    Validate foreign key relationships between datasets to ensure referential integrity.\n",
    "    \n",
    "    This function checks how well foreign keys in dependent tables (e.g., encounters, labs)\n",
    "    match primary keys in reference tables (e.g., patients). High integrity is crucial for\n",
    "    reliable analysis, as broken references can lead to data loss during joins.\n",
    "    \n",
    "    The function implements recommendations from:\n",
    "    - Kahn et al. (2016) \"A Harmonized Data Quality Assessment Terminology and Framework...\"\n",
    "    - Weiskopf & Weng (2013) \"Methods and dimensions of electronic health record data quality...\"\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data_dict : dict\n",
    "        Dictionary of dataframes with table names as keys\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary of relationship metrics between tables\n",
    "    \"\"\"\n",
    "    print_section_header(\"Data Relationship Validation\")\n",
    "    \n",
    "    relationships = {}\n",
    "    \n",
    "    # Define key relationships to check\n",
    "    key_relationships = [\n",
    "        # dependent_table, reference_table, foreign_key, primary_key\n",
    "        ('encounter', 'patient', 'Patient_ID', 'Patient_ID'),\n",
    "        ('encounter_diagnosis', 'encounter', 'Encounter_ID', 'Encounter_ID'),\n",
    "        ('encounter_diagnosis', 'patient', 'Patient_ID', 'Patient_ID'),\n",
    "        ('lab', 'patient', 'Patient_ID', 'Patient_ID'),\n",
    "        ('lab', 'encounter', 'Encounter_ID', 'Encounter_ID'),\n",
    "        ('medication', 'patient', 'Patient_ID', 'Patient_ID'),\n",
    "        ('referral', 'patient', 'Patient_ID', 'Patient_ID'),\n",
    "        ('health_condition', 'patient', 'Patient_ID', 'Patient_ID')\n",
    "    ]\n",
    "    \n",
    "    for dep_table, ref_table, fk, pk in key_relationships:\n",
    "        # Skip if either table is missing\n",
    "        if dep_table not in data_dict or ref_table not in data_dict:\n",
    "            print(f\"Skipping relationship check: {dep_table}.{fk} -> {ref_table}.{pk} (table missing)\")\n",
    "            continue\n",
    "            \n",
    "        # Skip if columns don't exist\n",
    "        if fk not in data_dict[dep_table].columns or pk not in data_dict[ref_table].columns:\n",
    "            print(f\"Skipping relationship check: {dep_table}.{fk} -> {ref_table}.{pk} (column missing)\")\n",
    "            continue\n",
    "            \n",
    "        # Get unique keys from both tables\n",
    "        dep_keys = set(data_dict[dep_table][fk].dropna().unique())\n",
    "        ref_keys = set(data_dict[ref_table][pk].dropna().unique())\n",
    "        \n",
    "        # Calculate metrics\n",
    "        matching_keys = dep_keys.intersection(ref_keys)\n",
    "        orphaned_keys = dep_keys - ref_keys\n",
    "        \n",
    "        # As percentages\n",
    "        total_dep_keys = len(dep_keys)\n",
    "        match_pct = len(matching_keys) / total_dep_keys if total_dep_keys > 0 else 0\n",
    "        orphan_pct = len(orphaned_keys) / total_dep_keys if total_dep_keys > 0 else 0\n",
    "        \n",
    "        # Store metrics\n",
    "        rel_key = f\"{dep_table}.{fk} -> {ref_table}.{pk}\"\n",
    "        relationships[rel_key] = {\n",
    "            'dependent_table': dep_table,\n",
    "            'reference_table': ref_table,\n",
    "            'foreign_key': fk,\n",
    "            'primary_key': pk,\n",
    "            'total_unique_keys': total_dep_keys,\n",
    "            'matching_keys': len(matching_keys),\n",
    "            'orphaned_keys': len(orphaned_keys),\n",
    "            'match_percentage': match_pct,\n",
    "            'orphan_percentage': orphan_pct\n",
    "        }\n",
    "        \n",
    "        # Print summary\n",
    "        print(f\"Relationship: {rel_key}\")\n",
    "        print(f\"  Match rate: {match_pct:.2%} ({len(matching_keys):,}/{total_dep_keys:,} keys)\")\n",
    "        if orphan_pct > 0:\n",
    "            print(f\"  Orphaned records: {orphan_pct:.2%} ({len(orphaned_keys):,} keys)\")\n",
    "            # Show sample of orphaned keys (useful for debugging)\n",
    "            if len(orphaned_keys) <= 5:\n",
    "                print(f\"  Sample orphaned keys: {list(orphaned_keys)}\")\n",
    "            else:\n",
    "                print(f\"  Sample orphaned keys: {list(orphaned_keys)[:5]} ...\")\n",
    "        print()\n",
    "        \n",
    "    # Create summary table for visualization\n",
    "    if relationships:\n",
    "        rel_df = pd.DataFrame([\n",
    "            {\n",
    "                'Relationship': k,\n",
    "                'Match Rate': v['match_percentage'],\n",
    "                'Orphaned Rate': v['orphan_percentage'],\n",
    "                'Total Keys': v['total_unique_keys']\n",
    "            }\n",
    "            for k, v in relationships.items()\n",
    "        ])\n",
    "        \n",
    "        # Sort by match rate\n",
    "        rel_df = rel_df.sort_values('Match Rate')\n",
    "        \n",
    "        # Plot relationship metrics\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        bars = plt.barh(rel_df['Relationship'], rel_df['Match Rate'])\n",
    "        \n",
    "        # Add percentage labels\n",
    "        for i, bar in enumerate(bars):\n",
    "            width = bar.get_width()\n",
    "            label = f\"{width:.1%}\"\n",
    "            plt.text(max(0.05, width - 0.1), bar.get_y() + bar.get_height()/2, \n",
    "                    label, ha='center', va='center', color='white', fontweight='bold')\n",
    "        \n",
    "        plt.xlabel('Match Rate (% of dependent keys found in reference table)')\n",
    "        plt.title('Data Relationship Integrity')\n",
    "        plt.xlim(0, 1.0)\n",
    "        plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(config.OUTPUT_PATH / 'relationship_integrity.png')\n",
    "        plt.close()\n",
    "        \n",
    "    return relationships\n",
    "\n",
    "def validate_temporal_consistency(data_dict):\n",
    "    \"\"\"\n",
    "    Validate temporal consistency in date columns across datasets.\n",
    "    \n",
    "    This function checks for:\n",
    "    1. Chronological consistency (e.g., start dates before end dates)\n",
    "    2. Date ranges within reasonable study period\n",
    "    3. Temporal alignment between related events\n",
    "    \n",
    "    Temporal consistency is essential for accurate pathway analysis, especially for\n",
    "    establishing the correct sequence of NYD status, lab tests, referrals, and diagnoses.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data_dict : dict\n",
    "        Dictionary of dataframes with table names as keys\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary of temporal consistency metrics\n",
    "    \"\"\"\n",
    "    print_section_header(\"Temporal Consistency Validation\")\n",
    "    \n",
    "    temporal_metrics = {}\n",
    "    \n",
    "    # 1. Check date ranges in each table\n",
    "    print_subsection_header(\"Date ranges by table\")\n",
    "    \n",
    "    for table_name, df in data_dict.items():\n",
    "        date_cols = [col for col in df.columns if pd.api.types.is_datetime64_dtype(df[col])]\n",
    "        if not date_cols:\n",
    "            continue\n",
    "            \n",
    "        table_metrics = {}\n",
    "        print(f\"Table: {table_name}\")\n",
    "        \n",
    "        for col in date_cols:\n",
    "            # Skip if all null\n",
    "            if df[col].isna().all():\n",
    "                continue\n",
    "                \n",
    "            min_date = df[col].min()\n",
    "            max_date = df[col].max()\n",
    "            null_count = df[col].isna().sum()\n",
    "            null_pct = null_count / len(df)\n",
    "            \n",
    "            # Check for future dates (beyond current study year)\n",
    "            future_date_threshold = pd.Timestamp(f\"{config.CURRENT_YEAR+1}-01-01\")\n",
    "            future_dates = df[col] >= future_date_threshold\n",
    "            future_count = future_dates.sum()\n",
    "            future_pct = future_count / df[col].notna().sum() if df[col].notna().any() else 0\n",
    "            \n",
    "            # Check for implausible past dates (before 1900)\n",
    "            past_date_threshold = pd.Timestamp(\"1900-01-01\")\n",
    "            past_dates = df[col] < past_date_threshold\n",
    "            past_count = past_dates.sum()\n",
    "            past_pct = past_count / df[col].notna().sum() if df[col].notna().any() else 0\n",
    "            \n",
    "            print(f\"  {col}: {min_date} to {max_date} (Null: {null_pct:.2%})\")\n",
    "            if future_pct > 0:\n",
    "                print(f\"    WARNING: {future_pct:.2%} ({future_count:,}) future dates beyond {config.CURRENT_YEAR}\")\n",
    "            if past_pct > 0:\n",
    "                print(f\"    WARNING: {past_pct:.2%} ({past_count:,}) implausibly old dates before 1900\")\n",
    "                \n",
    "            table_metrics[col] = {\n",
    "                'min_date': min_date,\n",
    "                'max_date': max_date,\n",
    "                'null_percentage': null_pct,\n",
    "                'future_date_percentage': future_pct,\n",
    "                'past_date_percentage': past_pct\n",
    "            }\n",
    "            \n",
    "        temporal_metrics[table_name] = table_metrics\n",
    "        \n",
    "    # 2. Check for specific date sequence consistency\n",
    "    print_subsection_header(\"Date sequence validation\")\n",
    "    \n",
    "    # Medication: StartDate before StopDate\n",
    "    if 'medication' in data_dict and 'StartDate' in data_dict['medication'].columns and 'StopDate' in data_dict['medication'].columns:\n",
    "        med_df = data_dict['medication']\n",
    "        # Only check rows with both dates non-null\n",
    "        both_dates = med_df['StartDate'].notna() & med_df['StopDate'].notna()\n",
    "        total_both_dates = both_dates.sum()\n",
    "        \n",
    "        if total_both_dates > 0:\n",
    "            invalid_sequence = (med_df['StartDate'] > med_df['StopDate']) & both_dates\n",
    "            invalid_count = invalid_sequence.sum()\n",
    "            invalid_pct = invalid_count / total_both_dates\n",
    "            \n",
    "            print(f\"Medication - StartDate before StopDate: {(1-invalid_pct):.2%} valid\")\n",
    "            if invalid_pct > 0:\n",
    "                print(f\"  WARNING: {invalid_pct:.2%} ({invalid_count:,}/{total_both_dates:,}) \" +\n",
    "                      f\"medication records have StartDate after StopDate\")\n",
    "                \n",
    "            temporal_metrics['medication_sequence'] = {\n",
    "                'check': 'StartDate_before_StopDate',\n",
    "                'valid_percentage': 1 - invalid_pct,\n",
    "                'invalid_count': invalid_count,\n",
    "                'total_checked': total_both_dates\n",
    "            }\n",
    "    \n",
    "    # 3. Check referral sequences for patients (relevant for pathway analysis)\n",
    "    if 'referral' in data_dict and 'CompletedDate' in data_dict['referral'].columns:\n",
    "        ref_df = data_dict['referral']\n",
    "        # Group by patient and sort by date\n",
    "        patient_ref_counts = ref_df.groupby('Patient_ID')['CompletedDate'].count()\n",
    "        multiple_refs = (patient_ref_counts > 1).sum()\n",
    "        multiple_refs_pct = multiple_refs / len(patient_ref_counts)\n",
    "        \n",
    "        print(f\"Referral sequences: {multiple_refs_pct:.2%} ({multiple_refs:,}/{len(patient_ref_counts):,}) \" +\n",
    "              f\"patients have multiple referrals\")\n",
    "              \n",
    "        temporal_metrics['referral_sequence'] = {\n",
    "            'check': 'multiple_referrals',\n",
    "            'patients_with_multiple_refs': multiple_refs,\n",
    "            'percentage': multiple_refs_pct\n",
    "        }\n",
    "    \n",
    "    # 4. Visualize date distributions\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Collect date ranges for key tables\n",
    "    key_tables = ['encounter', 'lab', 'medication', 'referral']\n",
    "    date_ranges = []\n",
    "    \n",
    "    for table in key_tables:\n",
    "        if table not in temporal_metrics:\n",
    "            continue\n",
    "            \n",
    "        for col, metrics in temporal_metrics[table].items():\n",
    "            if 'min_date' in metrics and 'max_date' in metrics:\n",
    "                date_ranges.append({\n",
    "                    'table': table,\n",
    "                    'column': col,\n",
    "                    'min_date': metrics['min_date'],\n",
    "                    'max_date': metrics['max_date']\n",
    "                })\n",
    "    \n",
    "    # Create date range plot\n",
    "    if date_ranges:\n",
    "        df_ranges = pd.DataFrame(date_ranges)\n",
    "        df_ranges['label'] = df_ranges['table'] + '.' + df_ranges['column']\n",
    "        \n",
    "        # Sort by min_date\n",
    "        df_ranges = df_ranges.sort_values('min_date')\n",
    "        \n",
    "        # Plot\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        for i, row in df_ranges.iterrows():\n",
    "            plt.plot([row['min_date'], row['max_date']], [i, i], 'o-', linewidth=2, markersize=8)\n",
    "            plt.text(row['min_date'], i+0.1, row['min_date'].strftime('%Y-%m-%d'), fontsize=9)\n",
    "            plt.text(row['max_date'], i+0.1, row['max_date'].strftime('%Y-%m-%d'), fontsize=9)\n",
    "            \n",
    "        plt.yticks(range(len(df_ranges)), df_ranges['label'])\n",
    "        plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "        plt.title('Date Ranges by Table and Column')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(config.OUTPUT_PATH / 'date_ranges.png')\n",
    "        plt.close()\n",
    "    \n",
    "    return temporal_metrics\n",
    "\n",
    "def analyze_patient_population(data_dict):\n",
    "    \"\"\"\n",
    "    Analyze the patient population demographics and coverage.\n",
    "    \n",
    "    This function:\n",
    "    1. Analyzes core demographic distributions (age, sex)\n",
    "    2. Checks data coverage across key tables for patient cohort\n",
    "    3. Identifies potential inclusion/exclusion issues\n",
    "    \n",
    "    Understanding the patient population is essential for:\n",
    "    - Assessing potential selection bias (Haneuse & Daniels, 2016)\n",
    "    - Ensuring adequate representation across key strata (Deeny & Steventon, 2015)\n",
    "    - Establishing the generalizability of findings (Hersh et al., 2013)\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data_dict : dict\n",
    "        Dictionary of dataframes with table names as keys\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary of population metrics\n",
    "    \"\"\"\n",
    "    print_section_header(\"Patient Population Analysis\")\n",
    "    \n",
    "    population_metrics = {}\n",
    "    \n",
    "    # Exit if patient table is missing\n",
    "    if 'patient' not in data_dict:\n",
    "        print(\"ERROR: Patient table missing, cannot analyze population\")\n",
    "        return population_metrics\n",
    "        \n",
    "    patient_df = data_dict['patient']\n",
    "\n",
    "    if 'Sex' in patient_df.columns:\n",
    "        # Normalize sex values to standardized format\n",
    "        sex_mapping = {\n",
    "            'F': 'Female', 'FEMALE': 'Female', 'Female': 'Female', \n",
    "            'M': 'Male', 'MALE': 'Male', 'Male': 'Male',\n",
    "            'U': 'Unknown', 'Unknown': 'Unknown', \n",
    "            'Undifferentiated': 'Other'\n",
    "        }\n",
    "        \n",
    "        # Apply mapping (preserve original for reference)\n",
    "        patient_df['Sex_normalized'] = patient_df['Sex'].map(sex_mapping).fillna('Unknown')\n",
    "        \n",
    "        # Get normalized distribution\n",
    "        sex_counts = patient_df['Sex_normalized'].value_counts()\n",
    "        sex_pct = sex_counts / len(patient_df) * 100\n",
    "        \n",
    "        print(\"\\nNormalized sex distribution:\")\n",
    "        for sex, count in sex_counts.items():\n",
    "            print(f\"  {sex}: {count:,} ({sex_pct[sex]:.1f}%)\")\n",
    "            \n",
    "        # Store in metrics\n",
    "        population_metrics['sex_normalized'] = {\n",
    "            'counts': sex_counts.to_dict(),\n",
    "            'percentage': sex_pct.to_dict()\n",
    "        }\n",
    "        \n",
    "        # Create visualization with normalized values\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        ax = sns.barplot(x=sex_counts.index, y=sex_counts.values)\n",
    "        plt.title('Patient Sex Distribution (Normalized)', fontsize=14)\n",
    "        plt.xlabel('Sex', fontsize=12)\n",
    "        plt.ylabel('Number of Patients', fontsize=12)\n",
    "        \n",
    "        # Add count and percentage labels\n",
    "        for i, p in enumerate(ax.patches):\n",
    "            height = p.get_height()\n",
    "            percentage = sex_pct.iloc[i]\n",
    "            ax.text(p.get_x() + p.get_width()/2., height + height*0.02,\n",
    "                   f'{int(height):,}\\n({percentage:.1f}%)', \n",
    "                   ha=\"center\", va=\"bottom\", fontsize=9)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(config.OUTPUT_PATH / 'sex_distribution_normalized.png')\n",
    "        plt.close()\n",
    "        \n",
    "    \n",
    "    # 1. Basic demographic analysis\n",
    "    print_subsection_header(\"Demographic Distribution\")\n",
    "    \n",
    "    # Calculate age from birth year\n",
    "    if 'BirthYear' in patient_df.columns:\n",
    "        # Check if DeceasedYear column exists in demographic data\n",
    "        has_deceased_info = 'patient_demographic' in data_dict and 'DeceasedYear' in data_dict['patient_demographic'].columns\n",
    " \n",
    "        patient_df['Age'] = config.CURRENT_YEAR - patient_df['BirthYear']\n",
    "        if has_deceased_info:\n",
    "            # Merge with demographic data to get deceased year\n",
    "            demo_df = data_dict['patient_demographic'][['Patient_ID', 'DeceasedYear']]\n",
    "            patient_df = patient_df.merge(demo_df, on='Patient_ID', how='left')\n",
    "            \n",
    "            # Calculate age considering death year when available\n",
    "            patient_df['reference_year'] = config.CURRENT_YEAR  # Default to current year\n",
    "            deceased_mask = patient_df['DeceasedYear'].notna() & (patient_df['DeceasedYear'] > 0)\n",
    "            if deceased_mask.any():\n",
    "                patient_df.loc[deceased_mask, 'reference_year'] = patient_df.loc[deceased_mask, 'DeceasedYear']\n",
    "            \n",
    "            patient_df['Age'] = patient_df['reference_year'] - patient_df['BirthYear']\n",
    "            \n",
    "            # Report on deceased patients\n",
    "            deceased_count = deceased_mask.sum()\n",
    "            print(f\"Deceased patients with valid death year: {deceased_count:,} ({deceased_count/len(patient_df)*100:.2f}%)\")\n",
    "        else:\n",
    "            # Standard age calculation based on current year\n",
    "            patient_df['Age'] = config.CURRENT_YEAR - patient_df['BirthYear']\n",
    "            \n",
    "        # Age statistics\n",
    "        age_mean = patient_df['Age'].mean()\n",
    "        age_median = patient_df['Age'].median()\n",
    "        age_min = patient_df['Age'].min()\n",
    "        age_max = patient_df['Age'].max()\n",
    "        \n",
    "        print(f\"Age statistics (as of {config.CURRENT_YEAR}):\")\n",
    "        print(f\"  Mean: {age_mean:.1f} years\")\n",
    "        print(f\"  Median: {age_median:.1f} years\")\n",
    "        print(f\"  Range: {age_min} to {age_max} years\")\n",
    "        \n",
    "        # Age distribution\n",
    "        age_bins = [0, 18, 35, 50, 65, 80, 120]\n",
    "        age_labels = ['<18', '18-34', '35-49', '50-64', '65-79', '80+']\n",
    "        \n",
    "        patient_df['Age_Group'] = pd.cut(patient_df['Age'], bins=age_bins, labels=age_labels)\n",
    "        age_dist = patient_df['Age_Group'].value_counts().sort_index()\n",
    "        age_pct = age_dist / len(patient_df) * 100\n",
    "        \n",
    "        # Display age distribution\n",
    "        age_table = pd.DataFrame({\n",
    "            'Age Group': age_dist.index,\n",
    "            'Count': age_dist.values,\n",
    "            'Percentage': age_pct.values\n",
    "        })\n",
    "        \n",
    "        print(\"\\nAge distribution:\")\n",
    "        display(age_table)\n",
    "        \n",
    "        # Store in metrics\n",
    "        population_metrics['age'] = {\n",
    "            'mean': age_mean,\n",
    "            'median': age_median,\n",
    "            'min': age_min,\n",
    "            'max': age_max,\n",
    "            'distribution': age_dist.to_dict(),\n",
    "            'percentage': age_pct.to_dict()\n",
    "        }\n",
    "        \n",
    "        # Plot age distribution\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        ax = sns.barplot(x=age_dist.index, y=age_dist.values)\n",
    "        plt.title('Patient Age Distribution', fontsize=14)\n",
    "        plt.xlabel('Age Group', fontsize=12)\n",
    "        plt.ylabel('Number of Patients', fontsize=12)\n",
    "        \n",
    "        # Add count and percentage labels\n",
    "        for i, p in enumerate(ax.patches):\n",
    "            height = p.get_height()\n",
    "            percentage = age_pct.iloc[i]\n",
    "            ax.text(p.get_x() + p.get_width()/2., height + height*0.02,\n",
    "                   f'{int(height):,}\\n({percentage:.1f}%)', \n",
    "                   ha=\"center\", va=\"bottom\", fontsize=9)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(config.OUTPUT_PATH / 'age_distribution.png')\n",
    "        plt.close()\n",
    "    \n",
    "    # Sex distribution\n",
    "    if 'Sex' in patient_df.columns:\n",
    "        sex_counts = patient_df['Sex'].value_counts()\n",
    "        sex_pct = sex_counts / len(patient_df) * 100\n",
    "        \n",
    "        print(\"\\nSex distribution:\")\n",
    "        for sex, count in sex_counts.items():\n",
    "            print(f\"  {sex}: {count:,} ({sex_pct[sex]:.1f}%)\")\n",
    "            \n",
    "        # Store in metrics\n",
    "        population_metrics['sex'] = {\n",
    "            'counts': sex_counts.to_dict(),\n",
    "            'percentage': sex_pct.to_dict()\n",
    "        }\n",
    "        \n",
    "        # Plot sex distribution\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        ax = sns.barplot(x=sex_counts.index, y=sex_counts.values)\n",
    "        plt.title('Patient Sex Distribution', fontsize=14)\n",
    "        plt.xlabel('Sex', fontsize=12)\n",
    "        plt.ylabel('Number of Patients', fontsize=12)\n",
    "        \n",
    "        # Add count and percentage labels\n",
    "        for i, p in enumerate(ax.patches):\n",
    "            height = p.get_height()\n",
    "            percentage = sex_pct.iloc[i]\n",
    "            ax.text(p.get_x() + p.get_width()/2., height + height*0.02,\n",
    "                   f'{int(height):,}\\n({percentage:.1f}%)', \n",
    "                   ha=\"center\", va=\"bottom\", fontsize=9)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(config.OUTPUT_PATH / 'sex_distribution.png')\n",
    "        plt.close()\n",
    "    \n",
    "    # 2. Data coverage across tables\n",
    "    print_subsection_header(\"Patient Data Coverage\")\n",
    "    \n",
    "    # Get patient ID sets for each table\n",
    "    coverage = {}\n",
    "    all_patients = set(patient_df['Patient_ID'])\n",
    "    total_patients = len(all_patients)\n",
    "    \n",
    "    for table, df in data_dict.items():\n",
    "        if table == 'patient':\n",
    "            continue\n",
    "            \n",
    "        if 'Patient_ID' in df.columns:\n",
    "            table_patients = set(df['Patient_ID'].unique())\n",
    "            overlap = table_patients.intersection(all_patients)\n",
    "            \n",
    "            coverage_pct = len(overlap) / total_patients\n",
    "            coverage[table] = {\n",
    "                'patients': len(overlap),\n",
    "                'percentage': coverage_pct\n",
    "            }\n",
    "            \n",
    "            print(f\"{table}: {coverage_pct:.2%} ({len(overlap):,}/{total_patients:,} patients)\")\n",
    "    \n",
    "    # Create intersection visualization\n",
    "    if coverage:\n",
    "        # Sort tables by coverage\n",
    "        sorted_tables = sorted(coverage.keys(), key=lambda x: coverage[x]['percentage'], reverse=True)\n",
    "        \n",
    "        # Create bar chart of coverage\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        coverage_vals = [coverage[t]['percentage'] for t in sorted_tables]\n",
    "        bars = plt.barh(sorted_tables, coverage_vals)\n",
    "        \n",
    "        # Add percentage labels\n",
    "        for i, bar in enumerate(bars):\n",
    "            width = bar.get_width()\n",
    "            label = f\"{width:.1%}\"\n",
    "            plt.text(max(0.05, width - 0.1), bar.get_y() + bar.get_height()/2, \n",
    "                    label, ha='center', va='center', color='white', fontweight='bold')\n",
    "        \n",
    "        plt.xlabel('Percentage of Patients with Data')\n",
    "        plt.title('Patient Coverage by Data Table')\n",
    "        plt.xlim(0, 1.0)\n",
    "        plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(config.OUTPUT_PATH / 'patient_coverage.png')\n",
    "        plt.close()\n",
    "    \n",
    "    # Store in metrics\n",
    "    population_metrics['coverage'] = coverage\n",
    "    \n",
    "    # 3. Eligibility analysis based on protocol criteria\n",
    "    print_subsection_header(\"Study Eligibility Analysis\")\n",
    "    \n",
    "    # Age eligibility (adults ≥18)\n",
    "    if 'Age' in patient_df.columns:\n",
    "        age_eligible = patient_df['Age'] >= config.MIN_AGE\n",
    "        age_eligible_count = age_eligible.sum()\n",
    "        age_eligible_pct = age_eligible_count / len(patient_df)\n",
    "        \n",
    "        print(f\"Age eligible (≥{config.MIN_AGE}): {age_eligible_pct:.2%} ({age_eligible_count:,}/{len(patient_df):,} patients)\")\n",
    "    \n",
    "    # Encounter eligibility (≥2 encounters)\n",
    "    if 'encounter' in data_dict and 'Patient_ID' in data_dict['encounter'].columns:\n",
    "        encounter_counts = data_dict['encounter']['Patient_ID'].value_counts()\n",
    "        encounter_eligible = encounter_counts[encounter_counts >= config.MIN_ENCOUNTERS]\n",
    "        encounter_eligible_count = len(encounter_eligible)\n",
    "        encounter_eligible_pct = encounter_eligible_count / len(patient_df)\n",
    "        \n",
    "        print(f\"Encounter eligible (≥{config.MIN_ENCOUNTERS} encounters): \" +\n",
    "              f\"{encounter_eligible_pct:.2%} ({encounter_eligible_count:,}/{len(patient_df):,} patients)\")\n",
    "        \n",
    "        # Encounter statistics\n",
    "        enc_mean = encounter_counts.mean()\n",
    "        enc_median = encounter_counts.median()\n",
    "        enc_p90 = encounter_counts.quantile(0.9)\n",
    "        \n",
    "        print(f\"Encounter statistics:\")\n",
    "        print(f\"  Mean: {enc_mean:.1f} encounters per patient\")\n",
    "        print(f\"  Median: {enc_median:.0f} encounters per patient\")\n",
    "        print(f\"  90th percentile: {enc_p90:.0f} encounters per patient\")\n",
    "        \n",
    "        # Store in metrics\n",
    "        population_metrics['encounters'] = {\n",
    "            'mean': enc_mean,\n",
    "            'median': enc_median,\n",
    "            'p90': enc_p90,\n",
    "            'eligible_count': encounter_eligible_count,\n",
    "            'eligible_percentage': encounter_eligible_pct\n",
    "        }\n",
    "        \n",
    "        # Create histogram of encounter counts\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        # Log transform for better visualization\n",
    "        log_counts = np.log10(encounter_counts + 1)  # +1 to handle zeros\n",
    "        plt.hist(log_counts, bins=50)\n",
    "        plt.title('Distribution of Encounters per Patient (Log Scale)', fontsize=14)\n",
    "        plt.xlabel('log10(Encounters + 1)', fontsize=12)\n",
    "        plt.ylabel('Number of Patients', fontsize=12)\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(config.OUTPUT_PATH / 'encounter_distribution.png')\n",
    "        plt.close()\n",
    "    \n",
    "    # 4. Combined eligibility criteria\n",
    "    if 'Age' in patient_df.columns and 'encounter' in data_dict:\n",
    "        # Get patient IDs with sufficient encounters\n",
    "        encounter_counts = data_dict['encounter']['Patient_ID'].value_counts()\n",
    "        encounter_eligible_ids = set(encounter_counts[encounter_counts >= config.MIN_ENCOUNTERS].index)\n",
    "        \n",
    "        # Combine with age eligibility\n",
    "        age_eligible_ids = set(patient_df.loc[patient_df['Age'] >= config.MIN_AGE, 'Patient_ID'])\n",
    "        \n",
    "        # Intersection\n",
    "        eligible_ids = age_eligible_ids.intersection(encounter_eligible_ids)\n",
    "        eligible_count = len(eligible_ids)\n",
    "        eligible_pct = eligible_count / len(patient_df)\n",
    "        \n",
    "        print(f\"\\nCombined eligibility (age ≥{config.MIN_AGE} AND ≥{config.MIN_ENCOUNTERS} encounters): \" +\n",
    "              f\"{eligible_pct:.2%} ({eligible_count:,}/{len(patient_df):,} patients)\")\n",
    "              \n",
    "        # Store in metrics\n",
    "        population_metrics['combined_eligibility'] = {\n",
    "            'eligible_count': eligible_count,\n",
    "            'eligible_percentage': eligible_pct,\n",
    "            'age_criteria': f\"≥{config.MIN_AGE}\",\n",
    "            'encounter_criteria': f\"≥{config.MIN_ENCOUNTERS}\"\n",
    "        }\n",
    "    \n",
    "    return population_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def link_labs_to_encounters_by_time(lab_df, encounter_df, window_days=14):\n",
    "    \"\"\"Link lab records to encounters based on temporal proximity.\"\"\"\n",
    "    print(\"Implementing time-based lab-encounter linkage...\")\n",
    "    \n",
    "    # Only process labs with missing Encounter_ID but valid dates\n",
    "    labs_to_link = lab_df[\n",
    "        (lab_df['Encounter_ID'].isna()) & \n",
    "        (lab_df['PerformedDate'].notna())\n",
    "    ].copy()\n",
    "    \n",
    "    if len(labs_to_link) == 0:\n",
    "        return lab_df\n",
    "    \n",
    "    print(f\"Attempting to link {len(labs_to_link):,} labs to encounters\")\n",
    "    \n",
    "    # Create columns for linkage data\n",
    "    result = lab_df.copy()\n",
    "    result['Linked_Encounter_ID'] = None\n",
    "    result['Days_To_Encounter'] = None\n",
    "    result['Linkage_Confidence'] = None\n",
    "    \n",
    "    # Process in chunks for efficiency\n",
    "    chunk_size = 10000\n",
    "    chunks = [labs_to_link.iloc[i:i+chunk_size] for i in range(0, len(labs_to_link), chunk_size)]\n",
    "    \n",
    "    linked_count = 0\n",
    "    for chunk_idx, chunk in enumerate(chunks):\n",
    "        print(f\"Processing chunk {chunk_idx+1}/{len(chunks)}...\")\n",
    "        \n",
    "        for lab_idx, lab in chunk.iterrows():\n",
    "            # Get all encounters for this patient\n",
    "            patient_encounters = encounter_df[\n",
    "                (encounter_df['Patient_ID'] == lab['Patient_ID']) &\n",
    "                (encounter_df['EncounterDate'].notna())\n",
    "            ]\n",
    "            \n",
    "            if len(patient_encounters) == 0:\n",
    "                continue\n",
    "                \n",
    "            # Calculate time differences\n",
    "            patient_encounters['days_diff'] = abs(\n",
    "                (patient_encounters['EncounterDate'] - lab['PerformedDate']).dt.days\n",
    "            )\n",
    "            \n",
    "            # Find best match within window\n",
    "            valid_matches = patient_encounters[patient_encounters['days_diff'] <= window_days]\n",
    "            \n",
    "            if len(valid_matches) == 0:\n",
    "                continue\n",
    "                \n",
    "            # Sort by days_diff to get closest encounter\n",
    "            valid_matches = valid_matches.sort_values('days_diff')\n",
    "            best_match = valid_matches.iloc[0]\n",
    "            \n",
    "            # Calculate confidence score (1.0 = same day, decreases with distance)\n",
    "            confidence = 1.0 - (best_match['days_diff'] / (window_days * 2))\n",
    "            \n",
    "            # Store the linkage data\n",
    "            result.loc[lab_idx, 'Linked_Encounter_ID'] = best_match['Encounter_ID']\n",
    "            result.loc[lab_idx, 'Days_To_Encounter'] = best_match['days_diff']\n",
    "            result.loc[lab_idx, 'Linkage_Confidence'] = confidence\n",
    "            \n",
    "            linked_count += 1\n",
    "    \n",
    "    # Create effective ID column for downstream analysis\n",
    "    result['Effective_Encounter_ID'] = result['Encounter_ID']\n",
    "    mask = result['Effective_Encounter_ID'].isna() & result['Linked_Encounter_ID'].notna()\n",
    "    result.loc[mask, 'Effective_Encounter_ID'] = result.loc[mask, 'Linked_Encounter_ID']\n",
    "    \n",
    "    print(f\"Successfully linked {linked_count:,} labs to encounters by temporal proximity\")\n",
    "    print(f\"Average confidence score: {result['Linkage_Confidence'].mean():.2f}\")\n",
    "    print(f\"Total labs with encounter association: {result['Effective_Encounter_ID'].notna().sum():,} \"\n",
    "          f\"({result['Effective_Encounter_ID'].notna().sum()/len(result)*100:.2f}%)\")\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def analyze_coding_patterns(data_dict):\n",
    "    \"\"\"\n",
    "    Analyze diagnostic coding patterns relevant for SSD identification.\n",
    "    \n",
    "    This function examines:\n",
    "    1. Distribution of ICD-9/ICD-10 codes\n",
    "    2. Frequency of key diagnostic codes\n",
    "    3. Preliminary identification of potential NYD codes\n",
    "    \n",
    "    Understanding coding patterns is critical for:\n",
    "    - Proper identification of NYD status (Vital & Health Statistics, 1987)\n",
    "    - Accurate detection of SSD criteria based on diagnostic codes\n",
    "    - Assessment of coding variability across providers\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data_dict : dict\n",
    "        Dictionary of dataframes with table names as keys\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary of coding pattern metrics\n",
    "    \"\"\"\n",
    "    print_section_header(\"Diagnostic Coding Pattern Analysis\")\n",
    "    \n",
    "    coding_metrics = {}\n",
    "    \n",
    "    # Skip if encounter_diagnosis or health_condition tables are missing\n",
    "    if 'encounter_diagnosis' not in data_dict or 'health_condition' not in data_dict:\n",
    "        print(\"WARNING: Missing diagnosis tables, skipping coding analysis\")\n",
    "        return coding_metrics\n",
    "    \n",
    "    # 1. Analyze ICD code types and patterns in encounter diagnoses\n",
    "    print_subsection_header(\"Encounter Diagnosis Coding Patterns\")\n",
    "    \n",
    "    ed_df = data_dict['encounter_diagnosis']\n",
    "    \n",
    "    # Check code type distribution\n",
    "    if 'DiagnosisCodeType_calc' in ed_df.columns:\n",
    "        code_types = ed_df['DiagnosisCodeType_calc'].value_counts()\n",
    "        code_pct = code_types / len(ed_df) * 100\n",
    "        \n",
    "        print(\"Diagnosis code types:\")\n",
    "        for code_type, count in code_types.items():\n",
    "            print(f\"  {code_type}: {count:,} ({code_pct[code_type]:.1f}%)\")\n",
    "            \n",
    "        # Store in metrics\n",
    "        coding_metrics['code_types'] = {\n",
    "            'counts': code_types.to_dict(),\n",
    "            'percentage': code_pct.to_dict()\n",
    "        }\n",
    "    \n",
    "    # 2. Check for known NYD (Not Yet Diagnosed) patterns\n",
    "    if 'DiagnosisCode_calc' in ed_df.columns:\n",
    "        print_subsection_header(\"Preliminary NYD Code Analysis\")\n",
    "        \n",
    "        # Define NYD code patterns based on research\n",
    "        # nyd_patterns = [\n",
    "        #     r'^799\\.9',    # Other unknown and unspecified cause\n",
    "        #     r'^V71\\.',     # Observation without finding - all V71 subcodes\n",
    "        #     r'^R69',       # Illness, unspecified (ICD-10)\n",
    "        #     r'^Z03\\.',     # Medical observation (ICD-10)\n",
    "        # ]\n",
    "        nyd_patterns = [\n",
    "            r'799',       # General symptoms (includes 799.9, which is \"Other unknown cause\")\n",
    "            r'^V71',      # Observation without finding (without requiring the dot)\n",
    "            r'^R69',      # Illness, unspecified (ICD-10)\n",
    "            r'^Z03',      # Medical observation (ICD-10, without requiring the dot)\n",
    "            r'^780\\.9',   # Other general symptoms (including \"unspecified\")\n",
    "            r'^V65\\.5'    # Person with feared condition where no diagnosis was made\n",
    "        ]\n",
    "        \n",
    "        # Check for each pattern\n",
    "        nyd_counts = {}\n",
    "        for pattern in nyd_patterns:\n",
    "            matches = ed_df['DiagnosisCode_calc'].astype(str).str.contains(pattern, na=False)\n",
    "            count = matches.sum()\n",
    "            patient_count = ed_df.loc[matches, 'Patient_ID'].nunique()\n",
    "            \n",
    "            nyd_counts[pattern] = {\n",
    "                'code_count': count,\n",
    "                'patient_count': patient_count,\n",
    "                'percentage': count / len(ed_df) * 100 if len(ed_df) > 0 else 0\n",
    "            }\n",
    "            \n",
    "            print(f\"NYD pattern '{pattern}': {count:,} codes ({nyd_counts[pattern]['percentage']:.2f}%) \" +\n",
    "                  f\"in {patient_count:,} patients\")\n",
    "        \n",
    "        # Store in metrics\n",
    "        coding_metrics['nyd_patterns'] = nyd_counts\n",
    "        \n",
    "        # Count most common code roots (first 3 characters)\n",
    "        ed_df['code_root'] = ed_df['DiagnosisCode_calc'].astype(str).str.extract(r'([A-Za-z0-9]{1,3})')\n",
    "        root_counts = ed_df['code_root'].value_counts().head(20)\n",
    "        \n",
    "        print(\"\\nMost common diagnostic code roots (first 3 characters):\")\n",
    "        for root, count in root_counts.items():\n",
    "            print(f\"  {root}: {count:,} ({count/len(ed_df)*100:.2f}%)\")\n",
    "        \n",
    "        # Store in metrics\n",
    "        coding_metrics['common_roots'] = root_counts.to_dict()\n",
    "    \n",
    "    \n",
    "    print(\"\\nChecking for potential NYD indicators in diagnostic code content...\")\n",
    "    # Look for 799 codes specifically (which includes 799.9 - Other unknown causes)\n",
    "    code_799 = ed_df['DiagnosisCode_calc'].astype(str).str.contains('^799', regex=True, na=False)\n",
    "    code_799_count = code_799.sum() \n",
    "    code_799_patient_count = ed_df.loc[code_799, 'Patient_ID'].nunique()\n",
    "\n",
    "    print(f\"Code 799 (symptoms/signs): {code_799_count:,} codes ({code_799_count/len(ed_df)*100:.2f}%) in {code_799_patient_count:,} patients\")\n",
    "\n",
    "    # Look for V71 (observation without diagnosis)\n",
    "    code_v71 = ed_df['DiagnosisCode_calc'].astype(str).str.contains('^V71', regex=True, na=False)\n",
    "    code_v71_count = code_v71.sum()\n",
    "    code_v71_patient_count = ed_df.loc[code_v71, 'Patient_ID'].nunique()\n",
    "\n",
    "    print(f\"Code V71 (observation without diagnosis): {code_v71_count:,} codes ({code_v71_count/len(ed_df)*100:.2f}%) in {code_v71_patient_count:,} patients\")\n",
    "    \n",
    "\n",
    "    # 3. Check for text patterns indicating NYD\n",
    "    if 'DiagnosisText_calc' in ed_df.columns:\n",
    "        # Define NYD text patterns\n",
    "        nyd_text_patterns = [\n",
    "            r'\\bNYD\\b', \n",
    "            r'\\bnot yet diagnosed\\b', \n",
    "            r'\\bdiagnosis deferred\\b',\n",
    "            r'\\bunknown etiology\\b', \n",
    "            r'\\brule out\\b', \n",
    "            r'\\bunexplained\\b',\n",
    "            r'\\bundiagnosed\\b',\n",
    "            r'\\bundetermined\\b',\n",
    "            r'\\bsymptoms\\b',\n",
    "            r'\\bsymptom\\b NOT OTHERWISE SPECIFIED',\n",
    "            r'without definitive diagnosis',\n",
    "            r'no clear',\n",
    "            r'no specific',\n",
    "        ]\n",
    "        \n",
    "        # Check for each text pattern\n",
    "        text_counts = {}\n",
    "        for pattern in nyd_text_patterns:\n",
    "            matches = ed_df['DiagnosisText_calc'].astype(str).str.contains(pattern, case=False, regex=True, na=False)\n",
    "            count = matches.sum()\n",
    "            patient_count = ed_df.loc[matches, 'Patient_ID'].nunique()\n",
    "            \n",
    "            text_counts[pattern] = {\n",
    "                'code_count': count,\n",
    "                'patient_count': patient_count,\n",
    "                'percentage': count / len(ed_df) * 100 if len(ed_df) > 0 else 0\n",
    "            }\n",
    "            \n",
    "            print(f\"NYD text pattern '{pattern}': {count:,} entries ({text_counts[pattern]['percentage']:.2f}%) \" +\n",
    "                  f\"in {patient_count:,} patients\")\n",
    "        \n",
    "        # Store in metrics\n",
    "        coding_metrics['nyd_text_patterns'] = text_counts\n",
    "    \n",
    "    # 4. Preliminary analysis of potential symptom codes (780-789)\n",
    "    if 'DiagnosisCode_calc' in ed_df.columns:\n",
    "        print_subsection_header(\"Symptom Code Analysis\")\n",
    "        \n",
    "        # Check for ICD-9 symptom codes (780-789 range)\n",
    "        symptom_pattern = r'^78[0-9]'\n",
    "        symptom_matches = ed_df['DiagnosisCode_calc'].astype(str).str.contains(symptom_pattern, regex=True, na=False)\n",
    "        symptom_count = symptom_matches.sum()\n",
    "        symptom_patient_count = ed_df.loc[symptom_matches, 'Patient_ID'].nunique()\n",
    "        \n",
    "        symptom_pct = symptom_count / len(ed_df) * 100 if len(ed_df) > 0 else 0\n",
    "        patient_pct = symptom_patient_count / ed_df['Patient_ID'].nunique() * 100\n",
    "        \n",
    "        print(f\"ICD-9 Symptom codes (780-789): {symptom_count:,} codes ({symptom_pct:.2f}%) \" +\n",
    "              f\"in {symptom_patient_count:,} patients ({patient_pct:.2f}%)\")\n",
    "              \n",
    "        # Get top symptom codes\n",
    "        if symptom_count > 0:\n",
    "            symptom_codes = ed_df.loc[symptom_matches, 'DiagnosisCode_calc'].value_counts().head(10)\n",
    "            print(\"\\nTop symptom codes:\")\n",
    "            for code, count in symptom_codes.items():\n",
    "                print(f\"  {code}: {count:,}\")\n",
    "\n",
    "            print(\"\\nNote: ICD-9 codes 780-789 represent 'Symptoms, Signs, and Ill-defined Conditions' and are\")\n",
    "            print(\"particularly relevant for SSD research as they often indicate medically unexplained symptoms.\")\n",
    "            print(f\"The presence of these codes in {patient_pct:.1f}% of patients suggests a large pool of potential\")\n",
    "            print(\"cases with somatic symptoms that could be evaluated for SSD criteria.\")\n",
    "                \n",
    "            # Store in metrics\n",
    "            coding_metrics['symptom_codes'] = {\n",
    "                'total_count': symptom_count,\n",
    "                'patient_count': symptom_patient_count,\n",
    "                'percentage': symptom_pct,\n",
    "                'patient_percentage': patient_pct,\n",
    "                'top_codes': symptom_codes.to_dict()\n",
    "            }\n",
    "    \n",
    "    # 5. Check for body-system distribution of symptom codes\n",
    "    print_subsection_header(\"Body System Distribution\")\n",
    "    \n",
    "    # Define body systems based on ICD-9 ranges\n",
    "    body_systems = {\n",
    "        'general': ['^780', '^R50', '^R53'],  # Fever, fatigue, malaise\n",
    "        'gi': ['^787', '^789', '^K5', '^K6', '^R1'], # Digestive symptoms\n",
    "        'neuro': ['^784', '^346', '^307.81', '^G43', '^G44', '^R51'], # Headache, dizziness\n",
    "        'cardio': ['^785', '^I10', '^R0'], # Chest pain, palpitations\n",
    "        'respiratory': ['^786', '^R0[67]'], # Shortness of breath\n",
    "        'musculo': ['^729', '^M79', '^M25', '^M54'], # Pain, joint, back\n",
    "        'skin': ['^782', '^L2', '^L3'], # Rash, skin sensations\n",
    "        'other': ['^788', '^R3'] # Urinary, etc.\n",
    "    }\n",
    "    \n",
    "    # Count codes by body system\n",
    "    system_counts = {}\n",
    "    \n",
    "    for system, patterns in body_systems.items():\n",
    "        # Combine patterns\n",
    "        system_pattern = '|'.join(patterns)\n",
    "        matches = ed_df['DiagnosisCode_calc'].astype(str).str.contains(system_pattern, regex=True, na=False)\n",
    "        count = matches.sum()\n",
    "        patient_count = ed_df.loc[matches, 'Patient_ID'].nunique()\n",
    "        \n",
    "        system_counts[system] = {\n",
    "            'code_count': count,\n",
    "            'patient_count': patient_count,\n",
    "            'percentage': count / len(ed_df) * 100 if len(ed_df) > 0 else 0\n",
    "        }\n",
    "        \n",
    "        print(f\"Body system '{system}': {count:,} codes ({system_counts[system]['percentage']:.2f}%) \" +\n",
    "              f\"in {patient_count:,} patients\")\n",
    "    \n",
    "    # Calculate multi-system counts\n",
    "    if len(system_counts) > 0:\n",
    "        # Get patients with symptoms in each system\n",
    "        system_patients = {}\n",
    "        for system, patterns in body_systems.items():\n",
    "            system_pattern = '|'.join(patterns)\n",
    "            matches = ed_df['DiagnosisCode_calc'].astype(str).str.contains(system_pattern, regex=True, na=False)\n",
    "            system_patients[system] = set(ed_df.loc[matches, 'Patient_ID'].unique())\n",
    "        \n",
    "        # Count patients with symptoms in multiple systems\n",
    "        patient_system_count = {}\n",
    "        all_patients = set(ed_df['Patient_ID'].unique())\n",
    "        \n",
    "        for patient_id in all_patients:\n",
    "            systems = [system for system, patients in system_patients.items() if patient_id in patients]\n",
    "            patient_system_count[patient_id] = len(systems)\n",
    "        \n",
    "        # Summarize\n",
    "        system_count_df = pd.Series(patient_system_count).value_counts().sort_index()\n",
    "        system_count_pct = system_count_df / len(all_patients) * 100\n",
    "        \n",
    "        print(\"\\nPatients by number of body systems with symptoms:\")\n",
    "        for num_systems, count in system_count_df.items():\n",
    "            print(f\"  {num_systems} systems: {count:,} patients ({system_count_pct[num_systems]:.2f}%)\")\n",
    "\n",
    "        print(\"\\nNote: This analysis shows how many patients have symptom codes across different body systems.\")\n",
    "        print(\"  - 0 systems: Patients with no symptom codes in any defined body system\")\n",
    "        print(\"  - 1 system: Patients with symptoms in exactly one body system (e.g., only GI)\")\n",
    "        print(\"  - 2+ systems: Patients with symptoms in multiple body systems - a key DSM-5 criterion for SSD\")\n",
    "        print(f\"  => {system_count_df.loc[lambda x: x.index >= 2].sum():,} patients ({system_count_df.loc[lambda x: x.index >= 2].sum()/len(all_patients)*100:.2f}%) have symptoms in 2+ body systems\")\n",
    "        \n",
    "\n",
    "        # Store in metrics\n",
    "        coding_metrics['multi_system'] = {\n",
    "            'counts': system_count_df.to_dict(),\n",
    "            'percentage': system_count_pct.to_dict()\n",
    "        }\n",
    "        \n",
    "        # Create visualization\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        ax = sns.barplot(x=system_count_df.index, y=system_count_df.values)\n",
    "        plt.title('Patients by Number of Body Systems with Symptoms', fontsize=14)\n",
    "        plt.xlabel('Number of Body Systems', fontsize=12)\n",
    "        plt.ylabel('Number of Patients', fontsize=12)\n",
    "        \n",
    "        # Add count and percentage labels\n",
    "        for i, p in enumerate(ax.patches):\n",
    "            height = p.get_height()\n",
    "            percentage = system_count_pct.iloc[i]\n",
    "            ax.text(p.get_x() + p.get_width()/2., height + height*0.02,\n",
    "                   f'{int(height):,}\\n({percentage:.1f}%)', \n",
    "                   ha=\"center\", va=\"bottom\", fontsize=9)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(config.OUTPUT_PATH / 'body_system_distribution.png')\n",
    "        plt.close()\n",
    "    \n",
    "    return coding_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def analyze_lab_data(data_dict):\n",
    "    \"\"\"\n",
    "    Analyze lab data structure and completeness for negative cascade detection.\n",
    "    \n",
    "    This function examines:\n",
    "    1. Lab test type distribution\n",
    "    2. Normal range data availability\n",
    "    3. Completeness of test results\n",
    "    4. Patient-level lab testing patterns\n",
    "    \n",
    "    Lab data analysis is critical for:\n",
    "    - Identifying the \"negative lab cascade\" central to SSD research\n",
    "    - Assessing data quality for normal/abnormal determination\n",
    "    - Establishing baseline lab testing patterns\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data_dict : dict\n",
    "        Dictionary of dataframes with table names as keys\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary of lab data metrics\n",
    "    \"\"\"\n",
    "    print_section_header(\"Lab Data Analysis\")\n",
    "    \n",
    "    lab_metrics = {}\n",
    "    \n",
    "    # Skip if lab table is missing\n",
    "    if 'lab' not in data_dict:\n",
    "        print(\"WARNING: Lab table missing, skipping analysis\")\n",
    "        return lab_metrics\n",
    "    \n",
    "    lab_df = data_dict['lab']\n",
    "    \n",
    "    # 1. Basic lab count metrics\n",
    "    print_subsection_header(\"Lab Test Overview\")\n",
    "    \n",
    "    total_labs = len(lab_df)\n",
    "    patient_count = lab_df['Patient_ID'].nunique()\n",
    "    average_labs_per_patient = total_labs / patient_count if patient_count > 0 else 0\n",
    "    \n",
    "    print(f\"Total lab tests: {total_labs:,}\")\n",
    "    print(f\"Patients with lab data: {patient_count:,}\")\n",
    "    print(f\"Average lab tests per patient: {average_labs_per_patient:.1f}\")\n",
    "    \n",
    "    # Store in metrics\n",
    "    lab_metrics['overview'] = {\n",
    "        'total_labs': total_labs,\n",
    "        'patient_count': patient_count,\n",
    "        'avg_per_patient': average_labs_per_patient\n",
    "    }\n",
    "    \n",
    "    # 2. Lab test type distribution\n",
    "    if 'Name_calc' in lab_df.columns:\n",
    "        # Get top lab tests\n",
    "        test_counts = lab_df['Name_calc'].value_counts().head(15)\n",
    "        test_pct = test_counts / len(lab_df) * 100\n",
    "        \n",
    "        print(\"\\nMost common lab tests:\")\n",
    "        for test, count in test_counts.items():\n",
    "            print(f\"  {test}: {count:,} ({test_pct[test]:.2f}%)\")\n",
    "            \n",
    "        # Store in metrics\n",
    "        lab_metrics['test_types'] = {\n",
    "            'counts': test_counts.to_dict(),\n",
    "            'percentage': test_pct.to_dict()\n",
    "        }\n",
    "    \n",
    "    # 3. Normal range data availability\n",
    "    print_subsection_header(\"Normal Range Data Availability\")\n",
    "    \n",
    "    if 'UpperNormal' in lab_df.columns and 'LowerNormal' in lab_df.columns:\n",
    "        # Check for presence of both normal range bounds\n",
    "        has_upper = lab_df['UpperNormal'].notna()\n",
    "        has_lower = lab_df['LowerNormal'].notna()\n",
    "        has_both = has_upper & has_lower\n",
    "        \n",
    "        both_count = has_both.sum()\n",
    "        both_pct = both_count / len(lab_df) * 100\n",
    "        \n",
    "        print(f\"Labs with both normal bounds: {both_count:,} ({both_pct:.2f}%)\")\n",
    "        \n",
    "        # Check by top test types\n",
    "        if 'Name_calc' in lab_df.columns:\n",
    "            test_normal_rates = {}\n",
    "            for test in test_counts.index[:10]:  # Top 10 tests\n",
    "                test_labs = lab_df['Name_calc'] == test\n",
    "                test_total = test_labs.sum()\n",
    "                test_with_bounds = (test_labs & has_both).sum()\n",
    "                test_rate = test_with_bounds / test_total * 100 if test_total > 0 else 0\n",
    "                \n",
    "                test_normal_rates[test] = {\n",
    "                    'total': test_total,\n",
    "                    'with_bounds': test_with_bounds,\n",
    "                    'percentage': test_rate\n",
    "                }\n",
    "                \n",
    "                print(f\"  {test}: {test_with_bounds:,}/{test_total:,} ({test_rate:.2f}%)\")\n",
    "                \n",
    "            # Store in metrics\n",
    "            lab_metrics['normal_range'] = {\n",
    "                'total_with_bounds': both_count,\n",
    "                'percentage': both_pct,\n",
    "                'by_test': test_normal_rates\n",
    "            }\n",
    "            \n",
    "            # Create visualization\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            tests = list(test_normal_rates.keys())\n",
    "            rates = [info['percentage'] for test, info in test_normal_rates.items()]\n",
    "            \n",
    "            # Sort by rate for better visualization\n",
    "            sorted_data = sorted(zip(tests, rates), key=lambda x: x[1], reverse=True)\n",
    "            tests = [t for t, r in sorted_data]\n",
    "            rates = [r for t, r in sorted_data]\n",
    "            \n",
    "            bars = plt.barh(tests, rates)\n",
    "            \n",
    "            # Add percentage labels\n",
    "            for i, bar in enumerate(bars):\n",
    "                width = bar.get_width()\n",
    "                label = f\"{width:.1f}%\"\n",
    "                plt.text(max(5, width - 10), bar.get_y() + bar.get_height()/2, \n",
    "                        label, ha='center', va='center', color='white', fontweight='bold')\n",
    "            \n",
    "            plt.xlabel('Percentage with Normal Range Bounds')\n",
    "            plt.title('Normal Range Data Availability by Lab Test Type')\n",
    "            plt.xlim(0, 100)\n",
    "            plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(config.OUTPUT_PATH / 'lab_normal_range_availability.png')\n",
    "            plt.close()\n",
    "    \n",
    "    # 4. Numeric result availability\n",
    "    print_subsection_header(\"Numeric Test Result Availability\")\n",
    "    \n",
    "    if 'TestResult_calc' in lab_df.columns:\n",
    "        # Check for numeric values\n",
    "        lab_df['TestResult_numeric'] = pd.to_numeric(lab_df['TestResult_calc'], errors='coerce')\n",
    "        has_numeric = lab_df['TestResult_numeric'].notna()\n",
    "        \n",
    "        numeric_count = has_numeric.sum()\n",
    "        numeric_pct = numeric_count / len(lab_df) * 100\n",
    "        \n",
    "        print(f\"Labs with numeric results: {numeric_count:,} ({numeric_pct:.2f}%)\")\n",
    "        \n",
    "        # Store in metrics\n",
    "        lab_metrics['numeric_results'] = {\n",
    "            'count': numeric_count,\n",
    "            'percentage': numeric_pct\n",
    "        }\n",
    "    \n",
    "    # 5. Patient-level lab testing patterns\n",
    "    print_subsection_header(\"Patient-Level Lab Testing Patterns\")\n",
    "    \n",
    "    # Count labs per patient\n",
    "    patient_lab_counts = lab_df.groupby('Patient_ID').size()\n",
    "    \n",
    "    # Calculate statistics\n",
    "    mean_labs = patient_lab_counts.mean()\n",
    "    median_labs = patient_lab_counts.median()\n",
    "    p90_labs = patient_lab_counts.quantile(0.9)\n",
    "    max_labs = patient_lab_counts.max()\n",
    "    \n",
    "    print(f\"Lab test statistics:\")\n",
    "    print(f\"  Mean: {mean_labs:.1f} tests per patient\")\n",
    "    print(f\"  Median: {median_labs:.0f} tests per patient\")\n",
    "    print(f\"  90th percentile: {p90_labs:.0f} tests per patient\")\n",
    "    print(f\"  Maximum: {max_labs:.0f} tests per patient\")\n",
    "    \n",
    "    # Store in metrics\n",
    "    lab_metrics['patient_labs'] = {\n",
    "        'mean': mean_labs,\n",
    "        'median': median_labs,\n",
    "        'p90': p90_labs,\n",
    "        'max': max_labs\n",
    "    }\n",
    "    \n",
    "    # Create histogram of lab counts\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    # Log transform for better visualization\n",
    "    log_counts = np.log10(patient_lab_counts + 1)  # +1 to handle zeros\n",
    "    plt.hist(log_counts, bins=50)\n",
    "    plt.title('Distribution of Lab Tests per Patient (Log Scale)', fontsize=14)\n",
    "    plt.xlabel('log10(Lab Tests + 1)', fontsize=12)\n",
    "    plt.ylabel('Number of Patients', fontsize=12)\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(config.OUTPUT_PATH / 'lab_test_distribution.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # 6. Preliminary normal lab cascade analysis\n",
    "    if 'TestResult_calc' in lab_df.columns and 'UpperNormal' in lab_df.columns and 'LowerNormal' in lab_df.columns:\n",
    "        print_subsection_header(\"Preliminary Normal Lab Analysis\")\n",
    "        \n",
    "        # Find labs with full normal range data\n",
    "        has_full_data = lab_df['TestResult_numeric'].notna() & lab_df['UpperNormal'].notna() & lab_df['LowerNormal'].notna()\n",
    "        \n",
    "        if has_full_data.any():\n",
    "            # Convert range boundaries to numeric\n",
    "            lab_df['upper_numeric'] = pd.to_numeric(lab_df['UpperNormal'], errors='coerce')\n",
    "            lab_df['lower_numeric'] = pd.to_numeric(lab_df['LowerNormal'], errors='coerce')\n",
    "            \n",
    "            # Get subset with full data\n",
    "            full_data = lab_df[has_full_data].copy()\n",
    "            \n",
    "            # Flag normal results\n",
    "            full_data['is_normal'] = (\n",
    "                (full_data['TestResult_numeric'] >= full_data['lower_numeric']) &\n",
    "                (full_data['TestResult_numeric'] <= full_data['upper_numeric'])\n",
    "            )\n",
    "            \n",
    "            # Count normal labs\n",
    "            normal_count = full_data['is_normal'].sum()\n",
    "            normal_pct = normal_count / len(full_data) * 100\n",
    "            \n",
    "            print(f\"Labs with full data for normal analysis: {len(full_data):,} ({len(full_data)/len(lab_df)*100:.2f}%)\")\n",
    "            print(f\"Normal lab results: {normal_count:,} ({normal_pct:.2f}%)\")\n",
    "            \n",
    "            # Count patients with multiple normal labs\n",
    "            patient_normal_counts = full_data.groupby('Patient_ID')['is_normal'].sum()\n",
    "            \n",
    "            # Thresholds for normal labs\n",
    "            for threshold in [3, 4, 5]:\n",
    "                patients_above = (patient_normal_counts >= threshold).sum()\n",
    "                pct_above = patients_above / len(patient_normal_counts) * 100\n",
    "                \n",
    "                print(f\"Patients with ≥{threshold} normal labs: {patients_above:,} ({pct_above:.2f}%)\")\n",
    "                \n",
    "            # Store in metrics\n",
    "            lab_metrics['normal_analysis'] = {\n",
    "                'normal_count': normal_count,\n",
    "                'normal_percentage': normal_pct,\n",
    "                'patient_thresholds': {\n",
    "                    f'ge_{threshold}': (patient_normal_counts >= threshold).sum()\n",
    "                    for threshold in [3, 4, 5]\n",
    "                }\n",
    "            }\n",
    "    \n",
    "    return lab_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def analyze_referral_patterns(data_dict):\n",
    "    \"\"\"\n",
    "    Analyze referral patterns with focus on psychiatry vs. other specialists.\n",
    "    \n",
    "    This function examines:\n",
    "    1. Referral type distribution\n",
    "    2. Preliminary psychiatry referral identification\n",
    "    3. Multi-specialty referral patterns\n",
    "    \n",
    "    Referral analysis is critical for:\n",
    "    - Identifying the specialist to psychiatry sequence in SSD pathway\n",
    "    - Quantifying \"doctor shopping\" behavior\n",
    "    - Understanding typical specialty consultation patterns\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data_dict : dict\n",
    "        Dictionary of dataframes with table names as keys\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary of referral pattern metrics\n",
    "    \"\"\"\n",
    "    print_section_header(\"Referral Pattern Analysis\")\n",
    "    \n",
    "    referral_metrics = {}\n",
    "    \n",
    "    # Skip if referral table is missing\n",
    "    if 'referral' not in data_dict:\n",
    "        print(\"WARNING: Referral table missing, skipping analysis\")\n",
    "        return referral_metrics\n",
    "    \n",
    "    ref_df = data_dict['referral']\n",
    "    \n",
    "    # 1. Basic referral metrics\n",
    "    print_subsection_header(\"Referral Overview\")\n",
    "    \n",
    "    total_refs = len(ref_df)\n",
    "    patient_count = ref_df['Patient_ID'].nunique()\n",
    "    average_refs_per_patient = total_refs / patient_count if patient_count > 0 else 0\n",
    "    \n",
    "    print(f\"Total referrals: {total_refs:,}\")\n",
    "    print(f\"Patients with referrals: {patient_count:,}\")\n",
    "    print(f\"Average referrals per patient: {average_refs_per_patient:.1f}\")\n",
    "    \n",
    "    # Store in metrics\n",
    "    referral_metrics['overview'] = {\n",
    "        'total_referrals': total_refs,\n",
    "        'patient_count': patient_count,\n",
    "        'avg_per_patient': average_refs_per_patient\n",
    "    }\n",
    "    \n",
    "    # 2. Referral type distribution\n",
    "    if 'Name_calc' in ref_df.columns:\n",
    "        # Get top referral types\n",
    "        ref_counts = ref_df['Name_calc'].value_counts().head(15)\n",
    "        ref_pct = ref_counts / len(ref_df) * 100\n",
    "        \n",
    "        print(\"\\nMost common referral types:\")\n",
    "        for ref_type, count in ref_counts.items():\n",
    "            print(f\"  {ref_type}: {count:,} ({ref_pct[ref_type]:.2f}%)\")\n",
    "            \n",
    "        # Store in metrics\n",
    "        referral_metrics['ref_types'] = {\n",
    "            'counts': ref_counts.to_dict(),\n",
    "            'percentage': ref_pct.to_dict()\n",
    "        }\n",
    "    \n",
    "    # 3. Identify psychiatric referrals\n",
    "    print_subsection_header(\"Psychiatric Referral Analysis\")\n",
    "    \n",
    "    if 'Name_calc' in ref_df.columns:\n",
    "        # Define psychiatry patterns based on validated terminology\n",
    "        psych_patterns = [\n",
    "            'psychiatr', 'mental health', 'psych', 'behavioral health', 'mood',\n",
    "            'mental', 'anxiety', 'depression', 'counseling', 'mh consult'\n",
    "        ]\n",
    "        psych_pattern = '|'.join([f\"\\\\b{p}\" for p in psych_patterns])\n",
    "        \n",
    "        # Flag psychiatric referrals\n",
    "        ref_df['to_psychiatrist'] = ref_df['Name_calc'].str.contains(\n",
    "            psych_pattern, case=False, regex=True, na=False)\n",
    "        \n",
    "        psych_count = ref_df['to_psychiatrist'].sum()\n",
    "        psych_pct = psych_count / len(ref_df) * 100\n",
    "        psych_patient_count = ref_df.loc[ref_df['to_psychiatrist'], 'Patient_ID'].nunique()\n",
    "        psych_patient_pct = psych_patient_count / patient_count * 100\n",
    "        \n",
    "        print(f\"Psychiatric referrals: {psych_count:,} ({psych_pct:.2f}%)\")\n",
    "        print(f\"Patients with psychiatric referrals: {psych_patient_count:,} ({psych_patient_pct:.2f}%)\")\n",
    "        \n",
    "        # Store in metrics\n",
    "        referral_metrics['psychiatry'] = {\n",
    "            'referral_count': psych_count,\n",
    "            'referral_percentage': psych_pct,\n",
    "            'patient_count': psych_patient_count,\n",
    "            'patient_percentage': psych_patient_pct\n",
    "        }\n",
    "    \n",
    "    # 4. Define and analyze body system specialists\n",
    "    print_subsection_header(\"Body System Specialist Analysis\")\n",
    "    \n",
    "    if 'Name_calc' in ref_df.columns:\n",
    "        # Define body system specialists based on validated terminology\n",
    "        body_systems = {\n",
    "            'cardio': ['cardiol', 'heart', 'cardiac', 'vascular', 'circulat', 'cardiolog', 'cardio'],\n",
    "            'gastro': ['gastro', 'gi', 'digestive', 'stomach', 'intestin', 'bowel', 'endo'],\n",
    "            'neuro': ['neuro', 'brain', 'headache', 'seizure', 'cognit', 'memory', 'nervous'],\n",
    "            'musculo': ['orthoped', 'rheumat', 'joint', 'pain', 'musculo', 'arthrit', 'back', 'spine', 'ortho'],\n",
    "            'respiratory': ['pulmon', 'lung', 'respirat', 'breath', 'asthma', 'copd', 'pulm', 'resp'],\n",
    "            'endo': ['endocrin', 'diabet', 'thyroid', 'hormone', 'metabol', 'endo'],\n",
    "            'derm': ['dermatol', 'skin', 'rash', 'lesion', 'derm'],\n",
    "            'gyn': ['gynecol', 'obstetric', 'women', 'pelvic', 'genital', 'urolog', 'gyn', 'repro']\n",
    "        }\n",
    "        \n",
    "        # Flag each body system\n",
    "        for system, keywords in body_systems.items():\n",
    "            system_pattern = '|'.join([f\"\\\\b{k}\" for k in keywords])\n",
    "            col_name = f'to_{system}'\n",
    "            ref_df[col_name] = ref_df['Name_calc'].str.contains(\n",
    "                system_pattern, case=False, regex=True, na=False)\n",
    "        \n",
    "        # Summarize body system referrals\n",
    "        system_metrics = {}\n",
    "        print(\"\\nBody system referral distribution:\")\n",
    "        for system in body_systems.keys():\n",
    "            col_name = f'to_{system}'\n",
    "            count = ref_df[col_name].sum()\n",
    "            pct = count / len(ref_df) * 100\n",
    "            patient_count = ref_df.loc[ref_df[col_name], 'Patient_ID'].nunique()\n",
    "            patient_pct = patient_count / ref_df['Patient_ID'].nunique() * 100\n",
    "            \n",
    "            system_metrics[system] = {\n",
    "                'referral_count': count,\n",
    "                'referral_percentage': pct,\n",
    "                'patient_count': patient_count,\n",
    "                'patient_percentage': patient_pct\n",
    "            }\n",
    "            \n",
    "            print(f\"  {system}: {count:,} referrals ({pct:.2f}%) in {patient_count:,} patients ({patient_pct:.2f}%)\")\n",
    "        \n",
    "        # Store in metrics\n",
    "        referral_metrics['body_systems'] = system_metrics\n",
    "        \n",
    "        # Create visualization\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        systems = list(system_metrics.keys())\n",
    "        counts = [info['referral_count'] for system, info in system_metrics.items()]\n",
    "        \n",
    "        # Sort by count for better visualization\n",
    "        sorted_data = sorted(zip(systems, counts), key=lambda x: x[1], reverse=True)\n",
    "        systems = [s for s, c in sorted_data]\n",
    "        counts = [c for s, c in sorted_data]\n",
    "        \n",
    "        ax = plt.bar(systems, counts)\n",
    "        \n",
    "        # Add count labels\n",
    "        for i, p in enumerate(ax):\n",
    "            height = p.get_height()\n",
    "            plt.text(p.get_x() + p.get_width()/2., height + height*0.02,\n",
    "                   f'{int(height):,}', \n",
    "                   ha=\"center\", va=\"bottom\", fontsize=9)\n",
    "        \n",
    "        plt.ylabel('Number of Referrals')\n",
    "        plt.title('Referrals by Body System')\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(config.OUTPUT_PATH / 'body_system_referrals.png')\n",
    "        plt.close()\n",
    "    \n",
    "    # 5. Multi-specialty referral patterns\n",
    "    print_subsection_header(\"Multi-Specialty Referral Patterns\")\n",
    "    \n",
    "    # Count referrals per patient\n",
    "    patient_ref_counts = ref_df.groupby('Patient_ID').size()\n",
    "    \n",
    "    # Calculate statistics\n",
    "    mean_refs = patient_ref_counts.mean()\n",
    "    median_refs = patient_ref_counts.median()\n",
    "    p90_refs = patient_ref_counts.quantile(0.9)\n",
    "    \n",
    "    print(f\"Referral statistics:\")\n",
    "    print(f\"  Mean: {mean_refs:.1f} referrals per patient\")\n",
    "    print(f\"  Median: {median_refs:.0f} referrals per patient\")\n",
    "    print(f\"  90th percentile: {p90_refs:.0f} referrals per patient\")\n",
    "    \n",
    "    # Analyze multi-specialty patterns\n",
    "    if 'to_psychiatrist' in ref_df.columns and any(f'to_{system}' in ref_df.columns for system in body_systems.keys()):\n",
    "        # Flag any non-psychiatric specialty\n",
    "        ref_df['to_any_body_system'] = False\n",
    "        for system in body_systems.keys():\n",
    "            col_name = f'to_{system}'\n",
    "            if col_name in ref_df.columns:\n",
    "                ref_df['to_any_body_system'] = ref_df['to_any_body_system'] | ref_df[col_name]\n",
    "        \n",
    "        # Get patient-level specialty flags\n",
    "        patient_specialties = ref_df.groupby('Patient_ID').agg({\n",
    "            'to_psychiatrist': 'any',\n",
    "            'to_any_body_system': 'any'\n",
    "        })\n",
    "        \n",
    "        # Calculate patterns\n",
    "        patient_specialties['psych_only'] = patient_specialties['to_psychiatrist'] & ~patient_specialties['to_any_body_system']\n",
    "        patient_specialties['body_only'] = ~patient_specialties['to_psychiatrist'] & patient_specialties['to_any_body_system']\n",
    "        patient_specialties['both'] = patient_specialties['to_psychiatrist'] & patient_specialties['to_any_body_system']\n",
    "        patient_specialties['neither'] = ~patient_specialties['to_psychiatrist'] & ~patient_specialties['to_any_body_system']\n",
    "        \n",
    "        # Summarize\n",
    "        pattern_counts = {\n",
    "            'psych_only': patient_specialties['psych_only'].sum(),\n",
    "            'body_only': patient_specialties['body_only'].sum(),\n",
    "            'both': patient_specialties['both'].sum(),\n",
    "            'neither': patient_specialties['neither'].sum()\n",
    "        }\n",
    "        \n",
    "        pattern_pct = {k: v / len(patient_specialties) * 100 for k, v in pattern_counts.items()}\n",
    "        \n",
    "        print(\"\\nPatient referral patterns:\")\n",
    "        print(f\"  Psychiatry only: {pattern_counts['psych_only']:,} patients ({pattern_pct['psych_only']:.2f}%)\")\n",
    "        print(f\"  Body system only: {pattern_counts['body_only']:,} patients ({pattern_pct['body_only']:.2f}%)\")\n",
    "        print(f\"  Both psychiatry and body system: {pattern_counts['both']:,} patients ({pattern_pct['both']:.2f}%)\")\n",
    "        print(f\"  Neither (other or unclassified referrals): {pattern_counts['neither']:,} patients ({pattern_pct['neither']:.2f}%)\")\n",
    "        \n",
    "        # Store in metrics\n",
    "        referral_metrics['patterns'] = {\n",
    "            'counts': pattern_counts,\n",
    "            'percentage': pattern_pct\n",
    "        }\n",
    "        \n",
    "        # Create visualization\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        labels = ['Psychiatry Only', 'Body System Only', 'Both', 'Neither/Other']\n",
    "        values = [pattern_counts[k] for k in ['psych_only', 'body_only', 'both', 'neither']]\n",
    "        \n",
    "        ax = plt.bar(labels, values)\n",
    "        \n",
    "        # Add count and percentage labels\n",
    "        for i, p in enumerate(ax):\n",
    "            height = p.get_height()\n",
    "            percentage = list(pattern_pct.values())[i]\n",
    "            plt.text(p.get_x() + p.get_width()/2., height + height*0.02,\n",
    "                   f'{int(height):,}\\n({percentage:.1f}%)', \n",
    "                   ha=\"center\", va=\"bottom\", fontsize=9)\n",
    "        \n",
    "        plt.ylabel('Number of Patients')\n",
    "        plt.title('Patient Referral Patterns')\n",
    "        plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(config.OUTPUT_PATH / 'referral_patterns.png')\n",
    "        plt.close()\n",
    "    \n",
    "    # 6. Doctor shopping analysis (multiple providers)\n",
    "    if 'referral' in data_dict and 'Provider_ID' in ref_df.columns:\n",
    "        print_subsection_header(\"Doctor Shopping Analysis\")\n",
    "        \n",
    "        # Count distinct providers per patient\n",
    "        provider_counts = ref_df.groupby('Patient_ID')['Provider_ID'].nunique()\n",
    "        \n",
    "        # Calculate statistics\n",
    "        mean_providers = provider_counts.mean()\n",
    "        median_providers = provider_counts.median()\n",
    "        p90_providers = provider_counts.quantile(0.9)\n",
    "        \n",
    "        print(f\"Provider statistics:\")\n",
    "        print(f\"  Mean: {mean_providers:.1f} distinct providers per patient\")\n",
    "        print(f\"  Median: {median_providers:.0f} distinct providers per patient\")\n",
    "        print(f\"  90th percentile: {p90_providers:.0f} distinct providers per patient\")\n",
    "        \n",
    "        # Define doctor shopping as ≥5 providers (from research protocol)\n",
    "        shopping_threshold = 5\n",
    "        shoppers = (provider_counts >= shopping_threshold).sum()\n",
    "        shoppers_pct = shoppers / len(provider_counts) * 100\n",
    "        \n",
    "        print(f\"Patients with ≥{shopping_threshold} different providers (potential doctor shopping): \" +\n",
    "              f\"{shoppers:,} ({shoppers_pct:.2f}%)\")\n",
    "        \n",
    "        # Store in metrics\n",
    "        referral_metrics['doctor_shopping'] = {\n",
    "            'mean_providers': mean_providers,\n",
    "            'median_providers': median_providers,\n",
    "            'p90_providers': p90_providers,\n",
    "            'shoppers_count': shoppers,\n",
    "            'shoppers_percentage': shoppers_pct,\n",
    "            'threshold': shopping_threshold\n",
    "        }\n",
    "        \n",
    "        # Create histogram of provider counts\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.hist(provider_counts, bins=range(0, 20), alpha=0.7)\n",
    "        plt.axvline(x=shopping_threshold, color='r', linestyle='--', linewidth=2, \n",
    "                   label=f'Shopping threshold (≥{shopping_threshold})')\n",
    "        plt.title('Distribution of Distinct Providers per Patient', fontsize=14)\n",
    "        plt.xlabel('Number of Distinct Providers', fontsize=12)\n",
    "        plt.ylabel('Number of Patients', fontsize=12)\n",
    "        plt.legend()\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(config.OUTPUT_PATH / 'provider_distribution.png')\n",
    "        plt.close()\n",
    "    \n",
    "    return referral_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_validation_results(data_quality, relationship_metrics, temporal_metrics,\n",
    "                         population_metrics, coding_metrics, lab_metrics, referral_metrics):\n",
    "    \"\"\"\n",
    "    Save all validation results to a structured JSON file for future reference.\n",
    "    \n",
    "    This function combines all metrics into a single, comprehensive report that can be:\n",
    "    1. Loaded in subsequent notebooks\n",
    "    2. Used for data quality monitoring over time\n",
    "    3. Included in supplementary materials for publications\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    Various metric dictionaries from validation functions\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    str\n",
    "        Path to saved report file\n",
    "    \"\"\"\n",
    "    print_section_header(\"Saving Validation Results\")\n",
    "    \n",
    "     # Combine all metrics\n",
    "    validation_report = {\n",
    "        'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        'data_quality': data_quality,\n",
    "        'relationships': relationship_metrics,\n",
    "        'temporal': temporal_metrics,\n",
    "        'population': population_metrics,\n",
    "        'coding': coding_metrics,\n",
    "        'lab': lab_metrics,\n",
    "        'referral': referral_metrics\n",
    "    }\n",
    "    \n",
    "    # Save to file\n",
    "    report_path = config.OUTPUT_PATH / 'data_validation_report.json'\n",
    "    \n",
    "    with open(report_path, 'w') as f:\n",
    "        json.dump(validation_report, f, indent=2, default=str)  # default=str handles non-serializable objects\n",
    "    \n",
    "    print(f\"Saved validation report to {report_path}\")\n",
    "    \n",
    "    # Create summary for display\n",
    "    summary = {\n",
    "        'Tables Loaded': len(data_quality),\n",
    "        'Total Patients': population_metrics.get('overview', {}).get('total_patients', 'Unknown'),\n",
    "        'Data Relationship Issues': any(rel.get('orphan_percentage', 0) > 0.05 for rel in relationship_metrics.values()) if relationship_metrics else 'Unknown',\n",
    "        'Normal Lab Data Available': lab_metrics.get('normal_range', {}).get('percentage', 0) if lab_metrics else 'Unknown',\n",
    "        'Patients with NYD Codes': calculate_nyd_patients(coding_metrics),\n",
    "        'Psychiatry Referrals': referral_metrics.get('psychiatry', {}).get('patient_count', 0) if referral_metrics else 'Unknown'\n",
    "    }\n",
    "    \n",
    "    print(\"\\nValidation Summary:\")\n",
    "    for key, value in summary.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "    \n",
    "    return report_path\n",
    "    \n",
    "    # def calculate_nyd_patients(coding_metrics):\n",
    "    #     \"\"\"Calculate total patients with any NYD code pattern.\"\"\"\n",
    "    #     if not coding_metrics or 'nyd_patterns' not in coding_metrics:\n",
    "    #         return 0\n",
    "            \n",
    "    #     # Use the highest patient count from any NYD pattern\n",
    "    #     # This avoids double-counting patients with multiple patterns\n",
    "    #     return max([pattern.get('patient_count', 0) \n",
    "    #                 for pattern in coding_metrics['nyd_patterns'].values()], default=0)\n",
    "\n",
    "    def calculate_nyd_patients(coding_metrics):\n",
    "        \"\"\"Calculate total patients with any NYD code pattern.\"\"\"\n",
    "        if not coding_metrics or 'nyd_patterns' not in coding_metrics:\n",
    "            return 0\n",
    "            \n",
    "        # Get all patient counts from patterns\n",
    "        pattern_counts = [pattern.get('patient_count', 0) \n",
    "                        for pattern in coding_metrics['nyd_patterns'].values()]\n",
    "        \n",
    "        # Return the highest count (as a conservative estimate)\n",
    "        # This avoids double-counting while ensuring we don't miss patients\n",
    "        return max(pattern_counts, default=0)\n",
    "\n",
    "    # Create summary for display\n",
    "    summary = {\n",
    "        'Tables Loaded': len(data_quality),\n",
    "        'Total Patients': population_metrics.get('overview', {}).get('total_patients', 'Unknown'),\n",
    "        'Data Relationship Issues': any(rel.get('orphan_percentage', 0) > 0.05 for rel in relationship_metrics.values()) if relationship_metrics else 'Unknown',\n",
    "        'Normal Lab Data Available': lab_metrics.get('normal_range', {}).get('percentage', 0) if lab_metrics else 'Unknown',\n",
    "        'Patients with NYD Codes': calculate_nyd_patients(coding_metrics),\n",
    "        'Psychiatry Referrals': referral_metrics.get('psychiatry', {}).get('patient_count', 0) if referral_metrics else 'Unknown'\n",
    "    }\n",
    "    \n",
    "    print(\"\\nValidation Summary:\")\n",
    "    for key, value in summary.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "    \n",
    "    return report_path\n",
    "\n",
    "def save_checkpoint(data_dict, validation_report_path, notebook_number=1):\n",
    "    \"\"\"\n",
    "    Save datasets and validation report as checkpoint for next notebook.\n",
    "    \n",
    "    This function:\n",
    "    1. Saves key tables needed for subsequent analysis\n",
    "    2. Handles problematic columns with mixed data types\n",
    "    3. Provides fallback to CSV format when needed\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data_dict : dict\n",
    "        Dictionary of dataframes to save\n",
    "    validation_report_path : str\n",
    "        Path to validation report\n",
    "    notebook_number : int\n",
    "        Current notebook number\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Metadata about the saved checkpoint\n",
    "    \"\"\"\n",
    "    print_section_header(\"Saving Checkpoint for Next Notebook\")\n",
    "    \n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    # Determine which tables to save\n",
    "    # For notebook 1, we primarily need core tables for NYD identification\n",
    "    key_tables = ['patient', 'encounter', 'encounter_diagnosis', 'health_condition', \n",
    "                'lab', 'medication', 'referral']\n",
    "    \n",
    "    tables_to_save = {k: data_dict[k] for k in key_tables if k in data_dict}\n",
    "    \n",
    "    # Create checkpoint directory\n",
    "    checkpoint_dir = config.INTERIM_PATH / f\"checkpoint_{notebook_number}_{timestamp}\"\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    \n",
    "    # Save each table\n",
    "    saved_tables = {}\n",
    "    for name, df in tables_to_save.items():\n",
    "        try:\n",
    "            # Use special handling for lab table which has mixed data types\n",
    "            if name == 'lab':\n",
    "                # Convert problematic columns to string\n",
    "                lab_df = df.copy()\n",
    "                problematic_cols = ['TestResult_calc', 'UpperNormal', 'LowerNormal', 'NormalRange', \n",
    "                                   'UnitOfMeasure_orig', 'UnitOfMeasure_calc']\n",
    "                \n",
    "                for col in problematic_cols:\n",
    "                    if col in lab_df.columns:\n",
    "                        lab_df[col] = lab_df[col].astype(str)\n",
    "                \n",
    "                # Save the cleaned version\n",
    "                output_path = checkpoint_dir / f\"{name}.csv\"\n",
    "                lab_df.to_csv(output_path, index=False)\n",
    "                print(f\"Saved {name} ({len(df):,} rows) as CSV due to mixed data types\")\n",
    "            else:\n",
    "                # Save other tables as parquet\n",
    "                output_path = checkpoint_dir / f\"{name}.parquet\"\n",
    "                df.to_parquet(output_path, index=False)\n",
    "                print(f\"Saved {name} ({len(df):,} rows) to {output_path}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            # Fallback to CSV for any other issues\n",
    "            print(f\"Warning: Could not save {name} in parquet format: {str(e)}\")\n",
    "            output_path = checkpoint_dir / f\"{name}.csv\"\n",
    "            df.to_csv(output_path, index=False)\n",
    "            print(f\"Saved {name} ({len(df):,} rows) as CSV instead\")\n",
    "        \n",
    "        saved_tables[name] = {\n",
    "            'path': str(output_path),\n",
    "            'rows': len(df),\n",
    "            'columns': len(df.columns),\n",
    "            'size_mb': os.path.getsize(output_path) / (1024 * 1024)\n",
    "        }\n",
    "    \n",
    "    # Create metadata file\n",
    "    metadata = {\n",
    "        'notebook': notebook_number,\n",
    "        'description': \"Data Loading and Validation\",\n",
    "        'timestamp': timestamp,\n",
    "        'validation_report': str(validation_report_path),\n",
    "        'saved_tables': saved_tables,\n",
    "        'next_notebook': f\"{notebook_number + 1:02d}_NYD_Identification.ipynb\"\n",
    "    }\n",
    "    \n",
    "    metadata_path = checkpoint_dir / \"metadata.json\"\n",
    "    with open(metadata_path, 'w') as f:\n",
    "        json.dump(metadata, f, indent=2, default=str)\n",
    "    \n",
    "    print(f\"Saved metadata to {metadata_path}\")\n",
    "    print(f\"\\nNext notebook: {metadata['next_notebook']}\")\n",
    "    print(f\"Load data from: {checkpoint_dir}\")\n",
    "    \n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhance_lab_classification(lab_df):\n",
    "    \"\"\"Multi-strategy approach to classify lab results as normal/abnormal.\"\"\"\n",
    "    print(\"Enhancing normal lab classification...\")\n",
    "    \n",
    "    result = lab_df.copy()\n",
    "    total_labs = len(result)\n",
    "    result['is_normal'] = pd.NA\n",
    "    \n",
    "    # 1. Explicit normal ranges where available\n",
    "    has_bounds = result['LowerNormal'].notna() & result['UpperNormal'].notna() & result['TestResult_calc'].notna()\n",
    "    \n",
    "    if has_bounds.any():\n",
    "        # Convert to numeric for comparison\n",
    "        lower_numeric = pd.to_numeric(result.loc[has_bounds, 'LowerNormal'], errors='coerce')\n",
    "        upper_numeric = pd.to_numeric(result.loc[has_bounds, 'UpperNormal'], errors='coerce')\n",
    "        result_numeric = pd.to_numeric(result.loc[has_bounds, 'TestResult_calc'], errors='coerce')\n",
    "        \n",
    "        # Identify normal results within bounds\n",
    "        valid_bounds = lower_numeric.notna() & upper_numeric.notna() & result_numeric.notna()\n",
    "        if valid_bounds.any():\n",
    "            normal_mask = valid_bounds & (result_numeric >= lower_numeric) & (result_numeric <= upper_numeric)\n",
    "            result.loc[has_bounds[has_bounds].index[normal_mask], 'is_normal'] = True\n",
    "            result.loc[has_bounds[has_bounds].index[~normal_mask & valid_bounds], 'is_normal'] = False\n",
    "        \n",
    "        processed_count = valid_bounds.sum()\n",
    "        print(f\"Method 1 (Explicit ranges): {processed_count:,} labs processed ({processed_count/total_labs*100:.2f}%)\")\n",
    "    \n",
    "    # 2. Standard reference intervals for common tests\n",
    "    common_tests = {\n",
    "        'TOTAL CHOLESTEROL': {'min': 0, 'max': 5.2, 'unit': 'mmol/L'},\n",
    "        'HDL': {'min': 1.0, 'max': 3.0, 'unit': 'mmol/L'},\n",
    "        'LDL': {'min': 0, 'max': 3.4, 'unit': 'mmol/L'},\n",
    "        'TRIGLYCERIDES': {'min': 0, 'max': 1.7, 'unit': 'mmol/L'},\n",
    "        'FASTING GLUCOSE': {'min': 3.9, 'max': 5.6, 'unit': 'mmol/L'},\n",
    "        'HBA1C': {'min': 0, 'max': 5.7, 'unit': '%'},\n",
    "        'TSH': {'min': 0.4, 'max': 4.0, 'unit': 'mIU/L'},\n",
    "        'ALT': {'min': 0, 'max': 40, 'unit': 'U/L'},\n",
    "        'AST': {'min': 0, 'max': 40, 'unit': 'U/L'},\n",
    "        'CREATININE': {'min': 50, 'max': 120, 'unit': 'umol/L'},\n",
    "        'HEMOGLOBIN': {'min': 120, 'max': 160, 'unit': 'g/L'},\n",
    "        'WBC': {'min': 4.0, 'max': 11.0, 'unit': '10^9/L'},\n",
    "        'POTASSIUM': {'min': 3.5, 'max': 5.0, 'unit': 'mmol/L'},\n",
    "        'SODIUM': {'min': 135, 'max': 145, 'unit': 'mmol/L'}\n",
    "    }\n",
    "    \n",
    "    # Convert TestResult_calc to numeric once\n",
    "    result['result_numeric'] = pd.to_numeric(result['TestResult_calc'], errors='coerce')\n",
    "    \n",
    "    # Process each common test\n",
    "    reference_count = 0\n",
    "    for test_name, reference in common_tests.items():\n",
    "        # Find pending labs for this test (result known but normal status unknown)\n",
    "        test_mask = (\n",
    "            result['Name_calc'].str.contains(test_name, case=False, regex=False, na=False) &\n",
    "            result['result_numeric'].notna() &\n",
    "            result['is_normal'].isna()\n",
    "        )\n",
    "        \n",
    "        if test_mask.any():\n",
    "            normal_mask = (\n",
    "                (result.loc[test_mask, 'result_numeric'] >= reference['min']) & \n",
    "                (result.loc[test_mask, 'result_numeric'] <= reference['max'])\n",
    "            )\n",
    "            result.loc[test_mask[test_mask].index[normal_mask], 'is_normal'] = True\n",
    "            result.loc[test_mask[test_mask].index[~normal_mask], 'is_normal'] = False\n",
    "            reference_count += test_mask.sum()\n",
    "    \n",
    "    print(f\"Method 2 (Reference intervals): {reference_count:,} labs processed ({reference_count/total_labs*100:.2f}%)\")\n",
    "    \n",
    "    # 3. Text pattern search for remaining labs\n",
    "    pending_mask = result['is_normal'].isna() & result['TestResult_calc'].notna()\n",
    "    text_count = 0\n",
    "    \n",
    "    if pending_mask.any():\n",
    "        # Normal indicators\n",
    "        normal_patterns = [\n",
    "            'normal', 'neg', 'negative', 'unremarkable', 'w/in normal', 'within normal', \n",
    "            'wnl', 'within reference', 'not detected', 'n/a'\n",
    "        ]\n",
    "        normal_pattern = '|'.join([f\"\\\\b{p}\" for p in normal_patterns])\n",
    "        \n",
    "        # Abnormal indicators\n",
    "        abnormal_patterns = [\n",
    "            'abnormal', 'pos', 'positive', 'high', 'low', 'elevated', 'depressed', \n",
    "            'outside', 'detected', 'present'\n",
    "        ]\n",
    "        abnormal_pattern = '|'.join([f\"\\\\b{p}\" for p in abnormal_patterns])\n",
    "        \n",
    "        # Apply normal patterns\n",
    "        normal_text = result.loc[pending_mask, 'TestResult_calc'].astype(str).str.contains(\n",
    "            normal_pattern, case=False, regex=True, na=False\n",
    "        )\n",
    "        result.loc[pending_mask[pending_mask].index[normal_text], 'is_normal'] = True\n",
    "        \n",
    "        # Apply abnormal patterns (where normal wasn't found)\n",
    "        still_pending = result['is_normal'].isna() & result['TestResult_calc'].notna()\n",
    "        if still_pending.any():\n",
    "            abnormal_text = result.loc[still_pending, 'TestResult_calc'].astype(str).str.contains(\n",
    "                abnormal_pattern, case=False, regex=True, na=False\n",
    "            )\n",
    "            result.loc[still_pending[still_pending].index[abnormal_text], 'is_normal'] = False\n",
    "        \n",
    "        text_count = (normal_text.sum() + abnormal_text.sum())\n",
    "    \n",
    "    print(f\"Method 3 (Text patterns): {text_count:,} labs processed ({text_count/total_labs*100:.2f}%)\")\n",
    "    \n",
    "    # Calculate overall coverage\n",
    "    classified_count = result['is_normal'].notna().sum()\n",
    "    coverage_pct = classified_count / total_labs * 100\n",
    "    normal_count = result['is_normal'].sum()\n",
    "    abnormal_count = (~result['is_normal'] & result['is_normal'].notna()).sum()\n",
    "    \n",
    "    print(f\"Overall: Classified {classified_count:,} labs ({coverage_pct:.2f}%)\")\n",
    "    print(f\"Normal: {normal_count:,} ({normal_count/classified_count*100:.2f}% of classified)\")\n",
    "    print(f\"Abnormal: {abnormal_count:,} ({abnormal_count/classified_count*100:.2f}% of classified)\")\n",
    "    \n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhance_referral_dates(referral_df):\n",
    "    \"\"\"Enhance referral dates using fallback strategies.\"\"\"\n",
    "    print(\"Implementing referral date enhancement...\")\n",
    "    \n",
    "    result = referral_df.copy()\n",
    "    total_refs = len(result)\n",
    "    \n",
    "    # Check completion date coverage\n",
    "    missing_completion = result['CompletedDate'].isna()\n",
    "    missing_count = missing_completion.sum()\n",
    "    missing_pct = missing_count / total_refs * 100\n",
    "    \n",
    "    print(f\"CompletedDate missing in {missing_count:,} referrals ({missing_pct:.2f}%)\")\n",
    "    \n",
    "    # Create effective date column with source tracking\n",
    "    result['EffectiveDate'] = result['CompletedDate']\n",
    "    result['DateSource'] = 'CompletedDate'\n",
    "    \n",
    "    # Use DateCreated as fallback when needed\n",
    "    if missing_count > 0:\n",
    "        result.loc[missing_completion, 'EffectiveDate'] = result.loc[missing_completion, 'DateCreated']\n",
    "        result.loc[missing_completion, 'DateSource'] = 'DateCreated'\n",
    "        \n",
    "        # Check coverage after fallback\n",
    "        remaining_missing = result['EffectiveDate'].isna().sum()\n",
    "        \n",
    "        print(f\"After fallback: {remaining_missing:,} referrals still missing dates ({remaining_missing/total_refs*100:.2f}%)\")\n",
    "        print(f\"Using DateCreated for {missing_count-remaining_missing:,} referrals\")\n",
    "    \n",
    "    # Flag referral status based on available dates\n",
    "    result['ReferralStatus'] = 'Unknown'\n",
    "    \n",
    "    # Completed referrals have CompletedDate\n",
    "    result.loc[result['CompletedDate'].notna(), 'ReferralStatus'] = 'Completed'\n",
    "    \n",
    "    # Pending referrals have DateCreated but no CompletedDate\n",
    "    result.loc[(result['CompletedDate'].isna()) & (result['DateCreated'].notna()), \n",
    "               'ReferralStatus'] = 'Pending'\n",
    "    \n",
    "    # Count by status\n",
    "    status_counts = result['ReferralStatus'].value_counts()\n",
    "    print(\"\\nReferral Status Distribution:\")\n",
    "    for status, count in status_counts.items():\n",
    "        print(f\"  {status}: {count:,} ({count/total_refs*100:.2f}%)\")\n",
    "    \n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint_with_documentation(data_dict, notebook_number, description, changes=None):\n",
    "    \"\"\"Save checkpoint with clear documentation for future reference.\"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    # Create checkpoint directory\n",
    "    checkpoint_dir = config.INTERIM_PATH / f\"checkpoint_{notebook_number}_{timestamp}\"\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    \n",
    "    # Save each dataframe with appropriate format\n",
    "    saved_tables = {}\n",
    "    for name, df in data_dict.items():\n",
    "        try:\n",
    "            # Handle special case for lab table\n",
    "            if name == 'lab':\n",
    "                csv_path = checkpoint_dir / f\"{name}.csv\"\n",
    "                df.to_csv(csv_path, index=False)\n",
    "                saved_tables[name] = {\n",
    "                    'path': str(csv_path),\n",
    "                    'rows': len(df),\n",
    "                    'columns': len(df.columns),\n",
    "                    'format': 'csv'\n",
    "                }\n",
    "                print(f\"Saved {name} ({len(df):,} rows) as CSV\")\n",
    "            else:\n",
    "                # Try parquet first\n",
    "                try:\n",
    "                    parquet_path = checkpoint_dir / f\"{name}.parquet\"\n",
    "                    df.to_parquet(parquet_path, index=False)\n",
    "                    saved_tables[name] = {\n",
    "                        'path': str(parquet_path),\n",
    "                        'rows': len(df),\n",
    "                        'columns': len(df.columns),\n",
    "                        'format': 'parquet'\n",
    "                    }\n",
    "                    print(f\"Saved {name} ({len(df):,} rows) as parquet\")\n",
    "                except Exception:\n",
    "                    # Fall back to CSV\n",
    "                    csv_path = checkpoint_dir / f\"{name}.csv\"\n",
    "                    df.to_csv(csv_path, index=False)\n",
    "                    saved_tables[name] = {\n",
    "                        'path': str(csv_path),\n",
    "                        'rows': len(df),\n",
    "                        'columns': len(df.columns),\n",
    "                        'format': 'csv'\n",
    "                    }\n",
    "                    print(f\"Saved {name} ({len(df):,} rows) as CSV (parquet failed)\")\n",
    "        except Exception as e:\n",
    "            print(f\"ERROR saving {name}: {str(e)}\")\n",
    "    \n",
    "    # Create detailed README\n",
    "    readme_content = f\"\"\"# Notebook {notebook_number}: {description}\n",
    "\n",
    "## Summary\n",
    "This checkpoint contains data processed through notebook {notebook_number}.\n",
    "\n",
    "## Date\n",
    "{datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}\n",
    "\n",
    "## Tables\n",
    "{chr(10).join([f\"- **{name}**: {info['rows']:,} rows, {len(data_dict[name].columns)} columns ({info['format']})\" \n",
    "               for name, info in saved_tables.items()])}\n",
    "\n",
    "## Changes Made\n",
    "{chr(10).join([f\"- {change}\" for change in (changes or ['No specific changes documented.'])])}\n",
    "\n",
    "## Key Notes\n",
    "- Lab normal detection uses multiple methods (explicit ranges, reference intervals, text patterns)\n",
    "- Orphaned labs linked to encounters using temporal proximity\n",
    "- Referral dates use DateCreated as fallback when CompletedDate missing\n",
    "- NYD codes enhanced with both numeric and text-based identification\n",
    "\n",
    "## Next Steps\n",
    "Continue with Notebook {notebook_number + 1} for NYD identification refinement.\n",
    "\"\"\"\n",
    "    \n",
    "    readme_path = checkpoint_dir / \"README.md\"\n",
    "    with open(readme_path, 'w') as f:\n",
    "        f.write(readme_content)\n",
    "    \n",
    "    # Create metadata JSON\n",
    "    metadata = {\n",
    "        'notebook': notebook_number,\n",
    "        'description': description,\n",
    "        'timestamp': timestamp,\n",
    "        'tables': saved_tables,\n",
    "        'changes': changes or [],\n",
    "        'next_notebook': f\"{notebook_number + 1:02d}_NYD_Identification.ipynb\"\n",
    "    }\n",
    "    \n",
    "    metadata_path = checkpoint_dir / \"metadata.json\"\n",
    "    with open(metadata_path, 'w') as f:\n",
    "        json.dump(metadata, f, indent=2, default=str)\n",
    "    \n",
    "    print(f\"\\nCheckpoint saved at: {checkpoint_dir}\")\n",
    "    print(f\"README created: {readme_path}\")\n",
    "    \n",
    "    return checkpoint_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def link_labs_to_encounters_by_time_optimized(lab_df, encounter_df, window_days=14):\n",
    "    \"\"\"\n",
    "    Highly optimized version of lab-encounter linkage using vectorized operations.\n",
    "    Processes data in larger chunks with efficient patient-based indexing.\n",
    "    \"\"\"\n",
    "    print(\"Implementing optimized time-based lab-encounter linkage...\")\n",
    "    \n",
    "    # Create efficient copy with only necessary columns\n",
    "    result = lab_df.copy()\n",
    "    result['Linked_Encounter_ID'] = None\n",
    "    result['Days_To_Encounter'] = None\n",
    "    result['Linkage_Confidence'] = None\n",
    "    \n",
    "    # Only process labs with missing Encounter_ID but valid dates\n",
    "    labs_to_link = lab_df[\n",
    "        lab_df['PerformedDate'].notna()\n",
    "    ].copy()\n",
    "    \n",
    "    print(f\"Preparing to link {len(labs_to_link):,} labs to encounters\")\n",
    "    \n",
    "    # Create patient index for encounters (do this ONCE)\n",
    "    print(\"Indexing encounters by patient (one-time operation)...\")\n",
    "    valid_encounters = encounter_df[encounter_df['EncounterDate'].notna()].copy()\n",
    "    \n",
    "    # Pre-sort encounters by date for each patient (more efficient lookups)\n",
    "    patient_encounter_dict = {}\n",
    "    for patient_id, group in valid_encounters.groupby('Patient_ID'):\n",
    "        # Pre-sort by date once per patient\n",
    "        patient_encounter_dict[patient_id] = group.sort_values('EncounterDate')\n",
    "    \n",
    "    # Use much larger chunks for better performance\n",
    "    chunk_size = 250000  # Increased from 10,000 to 250,000\n",
    "    chunks = np.array_split(labs_to_link, max(1, len(labs_to_link) // chunk_size))\n",
    "    total_chunks = len(chunks)\n",
    "    \n",
    "    print(f\"Processing {len(labs_to_link):,} labs in {total_chunks} optimized chunks...\")\n",
    "    \n",
    "    linked_count = 0\n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    for chunk_idx, chunk in enumerate(chunks):\n",
    "        chunk_start = datetime.now()\n",
    "        print(f\"Processing chunk {chunk_idx+1}/{total_chunks} ({len(chunk):,} labs)...\")\n",
    "        \n",
    "        # Process each patient's labs as a group (much more efficient)\n",
    "        for patient_id, patient_labs in chunk.groupby('Patient_ID'):\n",
    "            if patient_id not in patient_encounter_dict:\n",
    "                continue\n",
    "                \n",
    "            patient_encounters = patient_encounter_dict[patient_id]\n",
    "            if len(patient_encounters) == 0:\n",
    "                continue\n",
    "            \n",
    "            # Convert encounter dates to numpy array once per patient\n",
    "            encounter_dates = patient_encounters['EncounterDate'].values\n",
    "            encounter_ids = patient_encounters['Encounter_ID'].values\n",
    "            \n",
    "            # Process all labs for this patient with vectorized operations\n",
    "            for idx, lab in patient_labs.iterrows():\n",
    "                if pd.isna(lab['PerformedDate']):\n",
    "                    continue\n",
    "                    \n",
    "                # Calculate days difference using numpy (much faster)\n",
    "                lab_date = np.datetime64(lab['PerformedDate'])\n",
    "                days_diff = np.abs((encounter_dates - lab_date).astype('timedelta64[D]').astype(np.int64))\n",
    "                \n",
    "                # Find matches within window\n",
    "                valid_match_indices = np.where(days_diff <= window_days)[0]\n",
    "                if len(valid_match_indices) == 0:\n",
    "                    continue\n",
    "                \n",
    "                # Find index of minimum days difference\n",
    "                min_idx = valid_match_indices[np.argmin(days_diff[valid_match_indices])]\n",
    "                best_days_diff = days_diff[min_idx]\n",
    "                best_encounter_id = encounter_ids[min_idx]\n",
    "                \n",
    "                # Calculate confidence score (1.0 = same day)\n",
    "                confidence = 1.0 - (best_days_diff / (window_days * 2))\n",
    "                \n",
    "                # Store linkage data efficiently\n",
    "                result.loc[idx, 'Linked_Encounter_ID'] = best_encounter_id\n",
    "                result.loc[idx, 'Days_To_Encounter'] = best_days_diff\n",
    "                result.loc[idx, 'Linkage_Confidence'] = confidence\n",
    "                \n",
    "                linked_count += 1\n",
    "        \n",
    "        chunk_time = (datetime.now() - chunk_start).total_seconds()\n",
    "        labs_per_second = len(chunk) / max(1, chunk_time)\n",
    "        remaining_chunks = total_chunks - (chunk_idx + 1)\n",
    "        est_remaining_time = remaining_chunks * chunk_time / 60  # minutes\n",
    "        \n",
    "        print(f\"  Chunk {chunk_idx+1} processed in {chunk_time:.1f}s ({labs_per_second:.1f} labs/second)\")\n",
    "        print(f\"  Progress: {linked_count:,} labs linked, ~{est_remaining_time:.1f} minutes remaining\")\n",
    "    \n",
    "    # Create effective ID column for downstream analysis\n",
    "    result['Effective_Encounter_ID'] = result['Encounter_ID']\n",
    "    mask = result['Effective_Encounter_ID'].isna() & result['Linked_Encounter_ID'].notna()\n",
    "    result.loc[mask, 'Effective_Encounter_ID'] = result.loc[mask, 'Linked_Encounter_ID']\n",
    "    \n",
    "    total_time = (datetime.now() - start_time).total_seconds() / 60  # minutes\n",
    "    print(f\"Successfully linked {linked_count:,} labs in {total_time:.1f} minutes\")\n",
    "    print(f\"Total labs with encounter association: {result['Effective_Encounter_ID'].notna().sum():,} \"\n",
    "          f\"({result['Effective_Encounter_ID'].notna().sum()/len(result)*100:.2f}%)\")\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhance_lab_classification_optimized(lab_df):\n",
    "    \"\"\"\n",
    "    Optimized implementation of lab normal/abnormal classification\n",
    "    using vectorized operations for better performance.\n",
    "    \"\"\"\n",
    "    print(\"Enhancing lab classification with optimized approach...\")\n",
    "    \n",
    "    result = lab_df.copy()\n",
    "    total_labs = len(result)\n",
    "    \n",
    "    # Initialize as NA - will fill with True/False\n",
    "    result['is_normal'] = pd.NA\n",
    "    \n",
    "    # Convert TestResult_calc to numeric once (more efficient)\n",
    "    result['result_numeric'] = pd.to_numeric(result['TestResult_calc'], errors='coerce')\n",
    "    \n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    # 1. APPROACH 1: Explicit normal ranges\n",
    "    has_bounds = ~result['LowerNormal'].isna() & ~result['UpperNormal'].isna() & ~result['result_numeric'].isna()\n",
    "    \n",
    "    if has_bounds.any():\n",
    "        print(f\"Processing {has_bounds.sum():,} labs with explicit normal ranges...\")\n",
    "        \n",
    "        # Vectorized conversion (once per field)\n",
    "        lower_numeric = pd.to_numeric(result.loc[has_bounds, 'LowerNormal'], errors='coerce')\n",
    "        upper_numeric = pd.to_numeric(result.loc[has_bounds, 'UpperNormal'], errors='coerce')\n",
    "        \n",
    "        # Check valid bounds and determine normal/abnormal (vectorized)\n",
    "        valid_bounds = ~lower_numeric.isna() & ~upper_numeric.isna()\n",
    "        bounds_indices = has_bounds[has_bounds].index[valid_bounds]\n",
    "        \n",
    "        # Vectorized comparison\n",
    "        result.loc[bounds_indices, 'is_normal'] = (\n",
    "            (result.loc[bounds_indices, 'result_numeric'] >= lower_numeric[valid_bounds]) & \n",
    "            (result.loc[bounds_indices, 'result_numeric'] <= upper_numeric[valid_bounds])\n",
    "        )\n",
    "        \n",
    "        method1_count = valid_bounds.sum()\n",
    "        print(f\"Method 1: Processed {method1_count:,} labs ({method1_count/total_labs*100:.2f}%)\")\n",
    "    \n",
    "    # 2. APPROACH 2: Reference ranges for common tests\n",
    "    common_tests = {\n",
    "        'TOTAL CHOLESTEROL': {'min': 0, 'max': 5.2, 'unit': 'mmol/L'},\n",
    "        'HDL': {'min': 1.0, 'max': 3.0, 'unit': 'mmol/L'},\n",
    "        'LDL': {'min': 0, 'max': 3.4, 'unit': 'mmol/L'},\n",
    "        'TRIGLYCERIDES': {'min': 0, 'max': 1.7, 'unit': 'mmol/L'},\n",
    "        'FASTING GLUCOSE': {'min': 3.9, 'max': 5.6, 'unit': 'mmol/L'},\n",
    "        'HBA1C': {'min': 0, 'max': 5.7, 'unit': '%'},\n",
    "        'TSH': {'min': 0.4, 'max': 4.0, 'unit': 'mIU/L'},\n",
    "        'ALT': {'min': 0, 'max': 40, 'unit': 'U/L'},\n",
    "        'AST': {'min': 0, 'max': 40, 'unit': 'U/L'},\n",
    "        'CREATININE': {'min': 50, 'max': 120, 'unit': 'umol/L'},\n",
    "        'HEMOGLOBIN': {'min': 120, 'max': 160, 'unit': 'g/L'},\n",
    "        'WBC': {'min': 4.0, 'max': 11.0, 'unit': '10^9/L'},\n",
    "        'POTASSIUM': {'min': 3.5, 'max': 5.0, 'unit': 'mmol/L'},\n",
    "        'SODIUM': {'min': 135, 'max': 145, 'unit': 'mmol/L'}\n",
    "    }\n",
    "    \n",
    "    method2_count = 0\n",
    "    # Process all test types at once using a more efficient approach\n",
    "    for test_name, reference in common_tests.items():\n",
    "        # Find pending labs for this test (using case-insensitive string operations)\n",
    "        missing_normal = result['is_normal'].isna()\n",
    "        test_mask = (\n",
    "            result['Name_calc'].str.contains(test_name, case=False, regex=False, na=False) &\n",
    "            ~result['result_numeric'].isna() &\n",
    "            missing_normal\n",
    "        )\n",
    "        \n",
    "        if test_mask.any():\n",
    "            mask_count = test_mask.sum()\n",
    "            method2_count += mask_count\n",
    "            \n",
    "            # Vectorized normal check\n",
    "            result.loc[test_mask, 'is_normal'] = (\n",
    "                (result.loc[test_mask, 'result_numeric'] >= reference['min']) & \n",
    "                (result.loc[test_mask, 'result_numeric'] <= reference['max'])\n",
    "            )\n",
    "    \n",
    "    print(f\"Method 2: Processed {method2_count:,} labs ({method2_count/total_labs*100:.2f}%)\")\n",
    "    \n",
    "    # 3. APPROACH 3: Text pattern search\n",
    "    still_pending = result['is_normal'].isna() & ~result['TestResult_calc'].isna()\n",
    "    method3_count = 0\n",
    "    \n",
    "    if still_pending.any():\n",
    "        # Improved text pattern analysis with exact match phrases (better performance)\n",
    "        # Convert TestResult_calc to string once (for all text operations)\n",
    "        test_result_str = result.loc[still_pending, 'TestResult_calc'].astype(str)\n",
    "        \n",
    "        # Normal patterns\n",
    "        normal_patterns = [\n",
    "            'normal', 'neg', 'negative', 'unremarkable', 'w/in normal', 'within normal', \n",
    "            'wnl', 'within reference', 'not detected', 'n/a'\n",
    "        ]\n",
    "        \n",
    "        # Apply all normal patterns at once (more efficient)\n",
    "        normal_mask = np.zeros(len(test_result_str), dtype=bool)\n",
    "        for pattern in normal_patterns:\n",
    "            pattern_match = test_result_str.str.contains(\n",
    "                f\"\\\\b{pattern}\\\\b\", case=False, regex=True, na=False\n",
    "            )\n",
    "            normal_mask = normal_mask | pattern_match.values\n",
    "        \n",
    "        # Set normal flags\n",
    "        result.loc[still_pending[still_pending].index[normal_mask], 'is_normal'] = True\n",
    "        method3_count += normal_mask.sum()\n",
    "        \n",
    "        # Update pending labs\n",
    "        still_pending = result['is_normal'].isna() & ~result['TestResult_calc'].isna()\n",
    "        \n",
    "        # Apply abnormal patterns to remaining labs\n",
    "        if still_pending.any():\n",
    "            test_result_str = result.loc[still_pending, 'TestResult_calc'].astype(str)\n",
    "            \n",
    "            # Abnormal patterns\n",
    "            abnormal_patterns = [\n",
    "                'abnormal', 'pos', 'positive', 'high', 'low', 'elevated', 'depressed', \n",
    "                'outside', 'detected', 'present'\n",
    "            ]\n",
    "            \n",
    "            # Apply all abnormal patterns at once\n",
    "            abnormal_mask = np.zeros(len(test_result_str), dtype=bool)\n",
    "            for pattern in abnormal_patterns:\n",
    "                pattern_match = test_result_str.str.contains(\n",
    "                    f\"\\\\b{pattern}\\\\b\", case=False, regex=True, na=False\n",
    "                )\n",
    "                abnormal_mask = abnormal_mask | pattern_match.values\n",
    "            \n",
    "            # Set abnormal flags\n",
    "            result.loc[still_pending[still_pending].index[abnormal_mask], 'is_normal'] = False\n",
    "            method3_count += abnormal_mask.sum()\n",
    "    \n",
    "    print(f\"Method 3: Processed {method3_count:,} labs ({method3_count/total_labs*100:.2f}%)\")\n",
    "    \n",
    "    # Calculate overall coverage\n",
    "    classified_count = result['is_normal'].notna().sum()\n",
    "    coverage_pct = classified_count / total_labs * 100\n",
    "    normal_count = (result['is_normal'] == True).sum()  # Explicitly check for True\n",
    "    abnormal_count = (result['is_normal'] == False).sum()  # Explicitly check for False\n",
    "    \n",
    "    total_time = (datetime.now() - start_time).total_seconds()\n",
    "    print(f\"Lab classification completed in {total_time:.1f} seconds\")\n",
    "    print(f\"Overall: Classified {classified_count:,} labs ({coverage_pct:.2f}%)\")\n",
    "    print(f\"Normal: {normal_count:,} ({normal_count/classified_count*100:.2f}% of classified)\")\n",
    "    print(f\"Abnormal: {abnormal_count:,} ({abnormal_count/classified_count*100:.2f}% of classified)\")\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhance_referral_dates_optimized(referral_df):\n",
    "    \"\"\"\n",
    "    Optimized referral date enhancement using vectorized operations\n",
    "    for better performance.\n",
    "    \"\"\"\n",
    "    print(\"Implementing referral date enhancement (optimized)...\")\n",
    "    \n",
    "    result = referral_df.copy()\n",
    "    total_refs = len(result)\n",
    "    \n",
    "    # Check completion date coverage\n",
    "    missing_completion = result['CompletedDate'].isna()\n",
    "    missing_count = missing_completion.sum()\n",
    "    missing_pct = missing_count / total_refs * 100\n",
    "    \n",
    "    print(f\"CompletedDate missing in {missing_count:,} referrals ({missing_pct:.2f}%)\")\n",
    "    \n",
    "    # Create effective date column and source tracking (vectorized)\n",
    "    result['EffectiveDate'] = result['CompletedDate']\n",
    "    result['DateSource'] = 'CompletedDate'\n",
    "    \n",
    "    # Use vectorized operations for fallback\n",
    "    if missing_count > 0:\n",
    "        # Apply DateCreated fallback where needed (single operation)\n",
    "        result.loc[missing_completion, 'EffectiveDate'] = result.loc[missing_completion, 'DateCreated']\n",
    "        result.loc[missing_completion, 'DateSource'] = 'DateCreated'\n",
    "        \n",
    "        # Check coverage after fallback\n",
    "        remaining_missing = result['EffectiveDate'].isna().sum()\n",
    "        \n",
    "        print(f\"After fallback: {remaining_missing:,} referrals still missing dates ({remaining_missing/total_refs*100:.2f}%)\")\n",
    "        print(f\"Using DateCreated for {missing_count-remaining_missing:,} referrals\")\n",
    "    \n",
    "    # Flag referral status (vectorized operations)\n",
    "    result['ReferralStatus'] = 'Unknown'\n",
    "    \n",
    "    # Completed referrals have CompletedDate (single operation)\n",
    "    result.loc[result['CompletedDate'].notna(), 'ReferralStatus'] = 'Completed'\n",
    "    \n",
    "    # Pending referrals have DateCreated but no CompletedDate (single operation)\n",
    "    pending_mask = (result['CompletedDate'].isna()) & (result['DateCreated'].notna())\n",
    "    result.loc[pending_mask, 'ReferralStatus'] = 'Pending'\n",
    "    \n",
    "    # Count by status\n",
    "    status_counts = result['ReferralStatus'].value_counts()\n",
    "    print(\"\\nReferral Status Distribution:\")\n",
    "    for status, count in status_counts.items():\n",
    "        print(f\"  {status}: {count:,} ({count/total_refs*100:.2f}%)\")\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## CPCSSN Care4Mind Dataset: Data Loading and Validation"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Analysis date: 2025-03-15\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## Data Loading and Initial Validation"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Loading patient (Patient_prepared.csv)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Successfully loaded with encoding: utf-8-sig\n",
      "Loaded 352,161 rows and 6 columns\n",
      "WARNING: High missing data (>20%) in columns: ['BirthMonth', 'OptOutDate']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Loading patient_demographic (PatientDemographic_merged_prepared.csv)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Successfully loaded with encoding: utf-8-sig\n",
      "Loaded 352,220 rows and 22 columns\n",
      "WARNING: High missing data (>20%) in columns: ['Occupation', 'HighestEducation', 'HousingStatus', 'ResidencePostalCode', 'PatientStatus_calc', 'Language', 'Ethnicity', 'DeceasedYear', 'BirthMonth', 'OptOutDate', 'age']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Loading encounter (Encounter_prepared.csv)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Large table detected. Loading encounter in chunks of 500,000 rows...\n",
      "Successfully loaded with encoding: utf-8-sig\n",
      "Loaded 11,577,739 rows and 11 columns\n",
      "Converted EncounterDate to datetime. Parse failures: 0.00%\n",
      "Converted DateCreated to datetime. Parse failures: 0.00%\n",
      "WARNING: High missing data (>20%) in columns: ['Reason_orig', 'Reason_calc', 'EncounterType']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Loading encounter_diagnosis (EncounterDiagnosis_prepared.csv)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Large table detected. Loading encounter_diagnosis in chunks of 500,000 rows...\n",
      "Successfully loaded with encoding: utf-8-sig\n",
      "Loaded 12,471,764 rows and 14 columns\n",
      "Converted DateCreated to datetime. Parse failures: 0.00%\n",
      "WARNING: High missing data (>20%) in columns: ['DiagnosisText_calc', 'DiagnosisCodeType_orig', 'DiagnosisCodeType_calc', 'DiagnosisCode_calc']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Loading health_condition (HealthCondition_prepared.csv)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Successfully loaded with encoding: utf-8-sig\n",
      "Loaded 2,571,583 rows and 16 columns\n",
      "Converted DateOfOnset to datetime. Parse failures: 0.00%\n",
      "Converted DateCreated to datetime. Parse failures: 0.00%\n",
      "WARNING: High missing data (>20%) in columns: ['Encounter_ID', 'DateOfOnset', 'ActiveInactiveFlag']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Loading lab (Lab_prepared.csv)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Large table detected. Loading lab in chunks of 500,000 rows...\n",
      "Successfully loaded with encoding: utf-8-sig\n",
      "Loaded 8,528,807 rows and 22 columns\n",
      "Converted PerformedDate to datetime. Parse failures: 0.00%\n",
      "Converted DateCreated to datetime. Parse failures: 0.00%\n",
      "WARNING: High missing data (>20%) in columns: ['Encounter_ID', 'Name_calc', 'CodeType_orig', 'CodeType_calc', 'Code_orig', 'Code_calc', 'TestResult_calc', 'UpperNormal', 'LowerNormal', 'NormalRange', 'UnitOfMeasure_orig', 'UnitOfMeasure_calc']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Loading medication (Medication_prepared.csv)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Successfully loaded with encoding: utf-8-sig\n",
      "Loaded 7,706,628 rows and 27 columns\n",
      "Converted StartDate to datetime. Parse failures: 0.00%\n",
      "Converted StopDate to datetime. Parse failures: 0.00%\n",
      "Converted DateCreated to datetime. Parse failures: 0.00%\n",
      "WARNING: High missing data (>20%) in columns: ['Encounter_ID', 'StopDate', 'Reason', 'DIN', 'CodeType_orig', 'Strength', 'Dose', 'UnitOfMeasure', 'DurationCount', 'DurationUnit', 'DispensedForm']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Loading referral (Referral_prepared.csv)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Successfully loaded with encoding: utf-8-sig\n",
      "Loaded 1,141,061 rows and 12 columns\n",
      "Converted CompletedDate to datetime. Parse failures: 0.00%\n",
      "Converted DateCreated to datetime. Parse failures: 0.00%\n",
      "WARNING: High missing data (>20%) in columns: ['Encounter_ID', 'CompletedDate', 'DescriptionCode']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Loading family_history (FamilyHistory_prepared.csv)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Successfully loaded with encoding: utf-8-sig\n",
      "Loaded 325,202 rows and 20 columns\n",
      "WARNING: High missing data (>20%) in columns: ['Encounter_ID', 'DiagnosisText_calc', 'DiagnosisCodeType_orig', 'DiagnosisCodeType_calc', 'DiagnosisCode_orig', 'DiagnosisCode_calc', 'Relationship_Side_calc', 'Relationship_Degree_calc', 'AgeAtOnset', 'VitalStatus', 'AgeAtDeath']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Loading medical_procedure (MedicalProcedure_prepared.csv)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Successfully loaded with encoding: utf-8-sig\n",
      "Loaded 1,203,002 rows and 10 columns\n",
      "Converted PerformedDate to datetime. Parse failures: 0.00%\n",
      "Converted DateCreated to datetime. Parse failures: 0.00%\n",
      "WARNING: High missing data (>20%) in columns: ['Encounter_ID', 'Name_calc']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Loading risk_factor (RiskFactor_prepared.csv)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Successfully loaded with encoding: utf-8-sig\n",
      "Loaded 603,298 rows and 25 columns\n",
      "Converted StartDate to datetime. Parse failures: 0.00%\n",
      "Converted EndDate to datetime. Parse failures: 0.00%\n",
      "Converted DateCreated to datetime. Parse failures: 0.00%\n",
      "WARNING: High missing data (>20%) in columns: ['Encounter_ID', 'StartDate', 'EndDate', 'Value_orig', 'Value_calc', 'Status_orig', 'Status_calc', 'Frequency', 'FrequencyType', 'FrequencyUnit', 'Duration', 'DurationType', 'DurationUnit', 'EndDuration', 'EndDurationType', 'EndDurationUnit', 'RiskDetails']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## Data Loading Summary"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Successfully loaded 11 files with 46,833,465 total rows\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## Data Relationship Validation"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Relationship: encounter.Patient_ID -> patient.Patient_ID\n",
      "  Match rate: 100.00% (351,991/351,991 keys)\n",
      "\n",
      "Relationship: encounter_diagnosis.Encounter_ID -> encounter.Encounter_ID\n",
      "  Match rate: 93.25% (9,362,095/10,039,549 keys)\n",
      "  Orphaned records: 6.75% (677,454 keys)\n",
      "  Sample orphaned keys: [1003000000675862.0, 1003000000675866.0, 1003000000675872.0, 8001000004649001.0, 8001000004649004.0] ...\n",
      "\n",
      "Relationship: encounter_diagnosis.Patient_ID -> patient.Patient_ID\n",
      "  Match rate: 100.00% (352,161/352,161 keys)\n",
      "\n",
      "Relationship: lab.Patient_ID -> patient.Patient_ID\n",
      "  Match rate: 100.00% (207,836/207,836 keys)\n",
      "\n",
      "Relationship: lab.Encounter_ID -> encounter.Encounter_ID\n",
      "  Match rate: 11.22% (1,860/16,583 keys)\n",
      "  Orphaned records: 88.78% (14,723 keys)\n",
      "  Sample orphaned keys: [6003000000380932.0, 6003000004673540.0, 6003000000380936.0, 6003000004280328.0, 6004000000147466.0] ...\n",
      "\n",
      "Relationship: medication.Patient_ID -> patient.Patient_ID\n",
      "  Match rate: 100.00% (292,050/292,050 keys)\n",
      "\n",
      "Relationship: referral.Patient_ID -> patient.Patient_ID\n",
      "  Match rate: 100.00% (215,996/215,996 keys)\n",
      "\n",
      "Relationship: health_condition.Patient_ID -> patient.Patient_ID\n",
      "  Match rate: 100.00% (262,760/262,760 keys)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## Temporal Consistency Validation"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Date ranges by table"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Table: encounter\n",
      "  EncounterDate: 1800-02-01 00:00:00 to 2016-03-24 00:00:00 (Null: 0.00%)\n",
      "    WARNING: 0.00% (3) implausibly old dates before 1900\n",
      "  DateCreated: 1900-01-01 00:00:00 to 2015-07-21 00:00:00 (Null: 0.00%)\n",
      "Table: encounter_diagnosis\n",
      "  DateCreated: 1976-06-01 00:00:00 to 2015-07-21 00:00:00 (Null: 0.00%)\n",
      "Table: health_condition\n",
      "  DateOfOnset: 1800-01-01 00:00:00 to 2209-01-26 00:00:00 (Null: 20.48%)\n",
      "    WARNING: 0.00% (10) future dates beyond 2025\n",
      "    WARNING: 0.00% (4) implausibly old dates before 1900\n",
      "  DateCreated: 1900-01-01 00:00:00 to 2015-06-30 00:00:00 (Null: 0.00%)\n",
      "Table: lab\n",
      "  PerformedDate: 1904-10-12 00:00:00 to 2015-06-30 00:00:00 (Null: 0.02%)\n",
      "  DateCreated: 1900-01-01 00:00:00 to 2015-07-15 00:00:00 (Null: 0.00%)\n",
      "Table: medication\n",
      "  StartDate: 1800-01-13 00:00:00 to 2072-05-24 00:00:00 (Null: 0.20%)\n",
      "    WARNING: 0.00% (6) future dates beyond 2025\n",
      "    WARNING: 0.00% (1) implausibly old dates before 1900\n",
      "  StopDate: 1900-01-09 00:00:00 to 2190-07-21 00:00:00 (Null: 25.45%)\n",
      "    WARNING: 0.02% (1,026) future dates beyond 2025\n",
      "  DateCreated: 1800-01-13 00:00:00 to 2072-05-24 00:00:00 (Null: 0.00%)\n",
      "    WARNING: 0.00% (3) future dates beyond 2025\n",
      "    WARNING: 0.00% (1) implausibly old dates before 1900\n",
      "Table: referral\n",
      "  CompletedDate: 1931-03-11 00:00:00 to 2103-04-30 00:00:00 (Null: 97.41%)\n",
      "    WARNING: 0.01% (2) future dates beyond 2025\n",
      "  DateCreated: 1969-12-31 00:00:00 to 2015-08-11 00:00:00 (Null: 0.00%)\n",
      "Table: medical_procedure\n",
      "  PerformedDate: 1777-01-01 00:00:00 to 2207-01-01 00:00:00 (Null: 7.35%)\n",
      "    WARNING: 0.00% (3) future dates beyond 2025\n",
      "    WARNING: 0.00% (2) implausibly old dates before 1900\n",
      "  DateCreated: 1900-01-01 00:00:00 to 2015-06-30 00:00:00 (Null: 0.00%)\n",
      "Table: risk_factor\n",
      "  StartDate: 1922-07-15 00:00:00 to 2015-06-30 00:00:00 (Null: 92.64%)\n",
      "  EndDate: 1940-06-15 00:00:00 to 2015-06-15 00:00:00 (Null: 99.39%)\n",
      "  DateCreated: 1900-01-01 00:00:00 to 2015-06-30 00:00:00 (Null: 0.00%)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Date sequence validation"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Medication - StartDate before StopDate: 99.96% valid\n",
      "  WARNING: 0.04% (2,166/5,741,543) medication records have StartDate after StopDate\n",
      "Referral sequences: 2.74% (5,912/215,996) patients have multiple referrals\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## Patient Population Analysis"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Normalized sex distribution:\n",
      "  Female: 208,501 (59.2%)\n",
      "  Male: 143,617 (40.8%)\n",
      "  Unknown: 42 (0.0%)\n",
      "  Other: 1 (0.0%)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Demographic Distribution"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Deceased patients with valid death year: 6,472 (1.84%)\n",
      "Age statistics (as of 2025):\n",
      "  Mean: 55.7 years\n",
      "  Median: 56.0 years\n",
      "  Range: -12.0 to 125.0 years\n",
      "\n",
      "Age distribution:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age Group</th>\n",
       "      <th>Count</th>\n",
       "      <th>Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;18</td>\n",
       "      <td>20010</td>\n",
       "      <td>5.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18-34</td>\n",
       "      <td>56463</td>\n",
       "      <td>16.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35-49</td>\n",
       "      <td>69661</td>\n",
       "      <td>19.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50-64</td>\n",
       "      <td>81147</td>\n",
       "      <td>23.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65-79</td>\n",
       "      <td>73213</td>\n",
       "      <td>20.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>80+</td>\n",
       "      <td>51576</td>\n",
       "      <td>14.64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Age Group  Count  Percentage\n",
       "0       <18  20010        5.68\n",
       "1     18-34  56463       16.03\n",
       "2     35-49  69661       19.78\n",
       "3     50-64  81147       23.04\n",
       "4     65-79  73213       20.79\n",
       "5       80+  51576       14.64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sex distribution:\n",
      "  Female: 185,694 (52.7%)\n",
      "  Male: 126,316 (35.9%)\n",
      "  FEMALE: 22,845 (6.5%)\n",
      "  MALE: 17,323 (4.9%)\n",
      "  Unknown: 2 (0.0%)\n",
      "  Undifferentiated: 1 (0.0%)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Patient Data Coverage"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "patient_demographic: 100.00% (352,160/352,161 patients)\n",
      "encounter: 99.95% (351,991/352,161 patients)\n",
      "encounter_diagnosis: 100.00% (352,161/352,161 patients)\n",
      "health_condition: 74.61% (262,760/352,161 patients)\n",
      "lab: 59.02% (207,836/352,161 patients)\n",
      "medication: 82.93% (292,050/352,161 patients)\n",
      "referral: 61.33% (215,996/352,161 patients)\n",
      "family_history: 26.38% (92,902/352,161 patients)\n",
      "medical_procedure: 45.43% (159,981/352,161 patients)\n",
      "risk_factor: 54.08% (190,436/352,161 patients)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Study Eligibility Analysis"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Age eligible (≥18): 95.13% (335,066/352,221 patients)\n",
      "Encounter eligible (≥2 encounters): 97.68% (344,066/352,221 patients)\n",
      "Encounter statistics:\n",
      "  Mean: 32.9 encounters per patient\n",
      "  Median: 22 encounters per patient\n",
      "  90th percentile: 72 encounters per patient\n",
      "\n",
      "Combined eligibility (age ≥18 AND ≥2 encounters): 92.95% (327,382/352,221 patients)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## Diagnostic Coding Pattern Analysis"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Encounter Diagnosis Coding Patterns"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Diagnosis code types:\n",
      "  ICD9: 8,136,952 (65.2%)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Preliminary NYD Code Analysis"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "NYD pattern '799': 184,927 codes (1.48%) in 64,120 patients\n",
      "NYD pattern '^V71': 654 codes (0.01%) in 575 patients\n",
      "NYD pattern '^R69': 0 codes (0.00%) in 0 patients\n",
      "NYD pattern '^Z03': 0 codes (0.00%) in 0 patients\n",
      "NYD pattern '^780\\.9': 0 codes (0.00%) in 0 patients\n",
      "NYD pattern '^V65\\.5': 0 codes (0.00%) in 0 patients\n",
      "\n",
      "Most common diagnostic code roots (first 3 characters):\n",
      "  nan: 4,334,812 (34.76%)\n",
      "  401: 544,608 (4.37%)\n",
      "  250: 298,080 (2.39%)\n",
      "  V70: 280,468 (2.25%)\n",
      "  300: 266,989 (2.14%)\n",
      "  780: 261,846 (2.10%)\n",
      "  311: 231,790 (1.86%)\n",
      "  799: 177,653 (1.42%)\n",
      "  272: 170,642 (1.37%)\n",
      "  724: 167,541 (1.34%)\n",
      "  786: 135,582 (1.09%)\n",
      "  715: 108,108 (0.87%)\n",
      "  789: 96,081 (0.77%)\n",
      "  V04: 88,000 (0.71%)\n",
      "  719: 87,352 (0.70%)\n",
      "  460: 85,932 (0.69%)\n",
      "  493: 85,504 (0.69%)\n",
      "  V22: 84,470 (0.68%)\n",
      "  244: 81,464 (0.65%)\n",
      "  781: 80,681 (0.65%)\n",
      "\n",
      "Checking for potential NYD indicators in diagnostic code content...\n",
      "Code 799 (symptoms/signs): 177,653 codes (1.42%) in 58,285 patients\n",
      "Code V71 (observation without diagnosis): 654 codes (0.01%) in 575 patients\n",
      "NYD text pattern '\\bNYD\\b': 0 entries (0.00%) in 0 patients\n",
      "NYD text pattern '\\bnot yet diagnosed\\b': 0 entries (0.00%) in 0 patients\n",
      "NYD text pattern '\\bdiagnosis deferred\\b': 0 entries (0.00%) in 0 patients\n",
      "NYD text pattern '\\bunknown etiology\\b': 0 entries (0.00%) in 0 patients\n",
      "NYD text pattern '\\brule out\\b': 0 entries (0.00%) in 0 patients\n",
      "NYD text pattern '\\bunexplained\\b': 0 entries (0.00%) in 0 patients\n",
      "NYD text pattern '\\bundiagnosed\\b': 1,359 entries (0.01%) in 1,089 patients\n",
      "NYD text pattern '\\bundetermined\\b': 20 entries (0.00%) in 20 patients\n",
      "NYD text pattern '\\bsymptoms\\b': 431,974 entries (3.46%) in 125,436 patients\n",
      "NYD text pattern '\\bsymptom\\b NOT OTHERWISE SPECIFIED': 0 entries (0.00%) in 0 patients\n",
      "NYD text pattern 'without definitive diagnosis': 0 entries (0.00%) in 0 patients\n",
      "NYD text pattern 'no clear': 0 entries (0.00%) in 0 patients\n",
      "NYD text pattern 'no specific': 0 entries (0.00%) in 0 patients\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Symptom Code Analysis"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "ICD-9 Symptom codes (780-789): 867,700 codes (6.96%) in 214,774 patients (60.99%)\n",
      "\n",
      "Top symptom codes:\n",
      "  780: 128,863\n",
      "  781: 76,306\n",
      "  7862: 52,057\n",
      "  787: 51,249\n",
      "  7807: 47,291\n",
      "  7890: 46,235\n",
      "  786: 30,745\n",
      "  7840: 28,048\n",
      "  78900: 22,033\n",
      "  7865: 21,908\n",
      "\n",
      "Note: ICD-9 codes 780-789 represent 'Symptoms, Signs, and Ill-defined Conditions' and are\n",
      "particularly relevant for SSD research as they often indicate medically unexplained symptoms.\n",
      "The presence of these codes in 61.0% of patients suggests a large pool of potential\n",
      "cases with somatic symptoms that could be evaluated for SSD criteria.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Body System Distribution"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Body system 'general': 261,846 codes (2.10%) in 105,133 patients\n",
      "Body system 'gi': 176,674 codes (1.42%) in 81,585 patients\n",
      "Body system 'neuro': 97,335 codes (0.78%) in 42,654 patients\n",
      "Body system 'cardio': 36,668 codes (0.29%) in 23,332 patients\n",
      "Body system 'respiratory': 135,582 codes (1.09%) in 75,542 patients\n",
      "Body system 'musculo': 50,863 codes (0.41%) in 25,063 patients\n",
      "Body system 'skin': 60,946 codes (0.49%) in 36,027 patients\n",
      "Body system 'other': 42,632 codes (0.34%) in 26,579 patients\n",
      "\n",
      "Patients by number of body systems with symptoms:\n",
      "  0 systems: 138,298 patients (39.27%)\n",
      "  1 systems: 101,915 patients (28.94%)\n",
      "  2 systems: 58,305 patients (16.56%)\n",
      "  3 systems: 30,196 patients (8.57%)\n",
      "  4 systems: 14,309 patients (4.06%)\n",
      "  5 systems: 6,115 patients (1.74%)\n",
      "  6 systems: 2,277 patients (0.65%)\n",
      "  7 systems: 639 patients (0.18%)\n",
      "  8 systems: 107 patients (0.03%)\n",
      "\n",
      "Note: This analysis shows how many patients have symptom codes across different body systems.\n",
      "  - 0 systems: Patients with no symptom codes in any defined body system\n",
      "  - 1 system: Patients with symptoms in exactly one body system (e.g., only GI)\n",
      "  - 2+ systems: Patients with symptoms in multiple body systems - a key DSM-5 criterion for SSD\n",
      "  => 111,948 patients (31.79%) have symptoms in 2+ body systems\n",
      "\n",
      "Applying enhanced lab processing...\n",
      "Implementing time-based lab-encounter linkage...\n",
      "Attempting to link 8,321,681 labs to encounters\n",
      "Processing chunk 1/833...\n",
      "Processing chunk 2/833...\n",
      "Processing chunk 3/833...\n",
      "Processing chunk 4/833...\n",
      "Processing chunk 5/833...\n",
      "Processing chunk 6/833...\n",
      "Processing chunk 7/833...\n",
      "Processing chunk 8/833...\n",
      "Processing chunk 9/833...\n",
      "Processing chunk 10/833...\n",
      "Processing chunk 11/833...\n",
      "Processing chunk 12/833...\n",
      "Processing chunk 13/833...\n",
      "Processing chunk 14/833...\n",
      "Processing chunk 15/833...\n",
      "Processing chunk 16/833...\n",
      "Processing chunk 17/833...\n",
      "Processing chunk 18/833...\n",
      "Processing chunk 19/833...\n",
      "Processing chunk 20/833...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 117\u001b[0m\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoad data from: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcheckpoint_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 117\u001b[0m     main()\n",
      "Cell \u001b[1;32mIn[30], line 72\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m# Link orphaned labs to encounters\u001b[39;00m\n\u001b[0;32m     71\u001b[0m original_labs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlab\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 72\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlab\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m link_labs_to_encounters_by_time(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlab\u001b[39m\u001b[38;5;124m'\u001b[39m], data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencounter\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     73\u001b[0m changes\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLinked orphaned labs to encounters through temporal proximity\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     75\u001b[0m \u001b[38;5;66;03m# Enhance normal lab classification\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[22], line 32\u001b[0m, in \u001b[0;36mlink_labs_to_encounters_by_time\u001b[1;34m(lab_df, encounter_df, window_days)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing chunk \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchunk_idx\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(chunks)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m lab_idx, lab \u001b[38;5;129;01min\u001b[39;00m chunk\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;66;03m# Get all encounters for this patient\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m     patient_encounters \u001b[38;5;241m=\u001b[39m encounter_df[\n\u001b[0;32m     33\u001b[0m         (encounter_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPatient_ID\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m lab[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPatient_ID\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m&\u001b[39m\n\u001b[0;32m     34\u001b[0m         (encounter_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEncounterDate\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mnotna())\n\u001b[0;32m     35\u001b[0m     ]\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(patient_encounters) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     38\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ProjectC4M\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4093\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4091\u001b[0m \u001b[38;5;66;03m# Do we have a (boolean) 1d indexer?\u001b[39;00m\n\u001b[0;32m   4092\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m com\u001b[38;5;241m.\u001b[39mis_bool_indexer(key):\n\u001b[1;32m-> 4093\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_bool_array(key)\n\u001b[0;32m   4095\u001b[0m \u001b[38;5;66;03m# We are left with two options: a single key, and a collection of keys,\u001b[39;00m\n\u001b[0;32m   4096\u001b[0m \u001b[38;5;66;03m# We interpret tuples as collections only for non-MultiIndex\u001b[39;00m\n\u001b[0;32m   4097\u001b[0m is_single_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_list_like(key)\n",
      "File \u001b[1;32mc:\\Users\\ProjectC4M\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4151\u001b[0m, in \u001b[0;36mDataFrame._getitem_bool_array\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4147\u001b[0m \u001b[38;5;66;03m# check_bool_indexer will throw exception if Series key cannot\u001b[39;00m\n\u001b[0;32m   4148\u001b[0m \u001b[38;5;66;03m# be reindexed to match DataFrame rows\u001b[39;00m\n\u001b[0;32m   4149\u001b[0m key \u001b[38;5;241m=\u001b[39m check_bool_indexer(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, key)\n\u001b[1;32m-> 4151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key\u001b[38;5;241m.\u001b[39mall():\n\u001b[0;32m   4152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m   4154\u001b[0m indexer \u001b[38;5;241m=\u001b[39m key\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\ProjectC4M\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:64\u001b[0m, in \u001b[0;36m_all\u001b[1;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_all\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;66;03m# Parsing keyword arguments is currently fairly slow, so avoid it for now\u001b[39;00m\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m where \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m umr_all(a, axis, dtype, out, keepdims)\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m umr_all(a, axis, dtype, out, keepdims, where\u001b[38;5;241m=\u001b[39mwhere)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# ---------------------------- Main Execution ------------------------------ #\n",
    "# v1 - ORIGINAL \n",
    "# def main():\n",
    "#     \"\"\"Main execution function to run the full data loading and validation process.\"\"\"\n",
    "#     print_section_header(\"CPCSSN Care4Mind Dataset: Data Loading and Validation\")\n",
    "#     print(f\"Analysis date: {datetime.now().strftime('%Y-%m-%d')}\")\n",
    "   \n",
    "#     # Step 1: Load and perform initial data validation\n",
    "#     data, data_quality = load_and_validate_data()\n",
    "   \n",
    "#     # Step 2: Validate data relationships\n",
    "#     relationship_metrics = validate_data_relationships(data)\n",
    "   \n",
    "#     # Step 3: Validate temporal consistency\n",
    "#     temporal_metrics = validate_temporal_consistency(data)\n",
    "   \n",
    "#     # Step 4: Analyze patient population\n",
    "#     population_metrics = analyze_patient_population(data)\n",
    "   \n",
    "#     # Step 5: Analyze coding patterns\n",
    "#     coding_metrics = analyze_coding_patterns(data)\n",
    "   \n",
    "#     # Step 6: Analyze lab data\n",
    "#     lab_metrics = analyze_lab_data(data)\n",
    "   \n",
    "#     # Step 7: Analyze referral patterns\n",
    "#     referral_metrics = analyze_referral_patterns(data)\n",
    "   \n",
    "#     # Step 8: Save validation results\n",
    "#     validation_report_path = save_validation_results(\n",
    "#         data_quality, relationship_metrics, temporal_metrics,\n",
    "#         population_metrics, coding_metrics, lab_metrics, referral_metrics\n",
    "#     )\n",
    "   \n",
    "#     # Step 9: Save checkpoint for next notebook\n",
    "#     save_checkpoint(data, validation_report_path)\n",
    "   \n",
    "#     print_section_header(\"Data Validation Complete\")\n",
    "#     print(\"✓ Data loaded and validated\")\n",
    "#     print(\"✓ Quality metrics calculated\")\n",
    "#     print(\"✓ Visualizations generated\")\n",
    "#     print(\"✓ Checkpoint saved for next notebook\")\n",
    "   \n",
    "#     print(\"\\nProceed to Notebook 2: NYD Identification\")\n",
    "\n",
    "\n",
    "# V2 - ENHANCED\n",
    "\n",
    "# Updated main function with changes tracked\n",
    "def main():\n",
    "    \"\"\"Main execution with optimized data processing.\"\"\"\n",
    "    print_section_header(\"CPCSSN Care4Mind Dataset: Data Loading and Validation\")\n",
    "    print(f\"Analysis date: {datetime.now().strftime('%Y-%m-%d')}\")\n",
    "    \n",
    "    # Track changes for documentation\n",
    "    changes = []\n",
    "    \n",
    "    # Step 1: Load and validate data\n",
    "    data, data_quality = load_and_validate_data()\n",
    "    \n",
    "    # Step 2-5: Standard validation and analysis\n",
    "    relationship_metrics = validate_data_relationships(data)\n",
    "    temporal_metrics = validate_temporal_consistency(data)\n",
    "    population_metrics = analyze_patient_population(data)\n",
    "    coding_metrics = analyze_coding_patterns(data)\n",
    "    \n",
    "    # Step 6: Enhanced lab processing with optimized implementation\n",
    "    print(\"\\nApplying optimized lab processing...\")\n",
    "    \n",
    "    # Link orphaned labs to encounters using optimized function\n",
    "    original_labs = len(data['lab'])\n",
    "    data['lab'] = link_labs_to_encounters_by_time_optimized(data['lab'], data['encounter'])\n",
    "    changes.append(f\"Linked orphaned labs to encounters through temporal proximity (optimized)\")\n",
    "    \n",
    "    # Enhance normal lab classification using optimized function\n",
    "    data['lab'] = enhance_lab_classification_optimized(data['lab'])\n",
    "    changes.append(\"Expanded normal lab detection from 14% to ~45% using multiple methods (optimized)\")\n",
    "    \n",
    "    # Continue with regular lab analysis\n",
    "    lab_metrics = analyze_lab_data(data)\n",
    "    \n",
    "    # Step 7: Enhanced referral processing with optimized implementation\n",
    "    print(\"\\nApplying optimized referral processing...\")\n",
    "    data['referral'] = enhance_referral_dates_optimized(data['referral'])\n",
    "    changes.append(\"Implemented referral date fallbacks and status tracking (optimized)\")\n",
    "    \n",
    "    # Continue with regular referral analysis\n",
    "    referral_metrics = analyze_referral_patterns(data)\n",
    "    \n",
    "    # Step 8: Save validation with corrected NYD reporting\n",
    "    validation_report_path = save_validation_results(\n",
    "        data_quality, relationship_metrics, temporal_metrics, \n",
    "        population_metrics, coding_metrics, lab_metrics, referral_metrics\n",
    "    )\n",
    "    changes.append(\"Fixed NYD code reporting in validation summary\")\n",
    "    \n",
    "    # Step 9: Save comprehensive checkpoint\n",
    "    checkpoint_dir = save_checkpoint_with_documentation(\n",
    "        data,\n",
    "        notebook_number=1,\n",
    "        description=\"Data Loading and Validation with Optimized Processing\",\n",
    "        changes=changes\n",
    "    )\n",
    "    \n",
    "    print_section_header(\"Optimized Data Validation Complete\")\n",
    "    print(\"✓ Data loaded and validated with fixes\")\n",
    "    print(\"✓ NYD code reporting corrected\")\n",
    "    print(\"✓ Lab-encounter temporal linkage implemented (optimized)\")\n",
    "    print(\"✓ Normal lab detection significantly expanded (optimized)\")\n",
    "    print(\"✓ Referral date handling improved (optimized)\")\n",
    "    print(\"✓ Comprehensive documentation created\")\n",
    "    \n",
    "    print(f\"\\nProceed to Notebook 2: NYD_Identification.ipynb\")\n",
    "    print(f\"Load data from: {checkpoint_dir}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab-Encounter Relationship Failure (11.22% match rate)\n",
    "This is a critical issue since our SSD causal chain relies on proper temporal sequencing:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relationship: lab.Encounter_ID -> encounter.Encounter_ID\n",
    "  Match rate: 11.22% (1,860/16,583 keys)\n",
    "  Orphaned records: 88.78% (14,723 keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix: Modify  approach to establish temporal sequences without relying on the Lab-Encounter relationship. Instead, use direct timestamps from both tables independently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal Lab Availability Limited to 14.3%\n",
    "This severely limits your ability to identify the \"negative lab cascade\" central to your research:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Labs with both normal bounds: 1,219,699 (14.30%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix: Implement the domain-specific cutoffs mentioned in the data completeness check:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- # Add this to analyze_lab_data function\n",
    "common_tests = {\n",
    "    'TOTAL CHOLESTEROL': {'min': 0, 'max': 5.2, 'unit': 'mmol/L'},\n",
    "    'HDL': {'min': 1.0, 'max': 3.0, 'unit': 'mmol/L'},\n",
    "    'LDL': {'min': 0, 'max': 3.4, 'unit': 'mmol/L'},\n",
    "    'TRIGLYCERIDES': {'min': 0, 'max': 1.7, 'unit': 'mmol/L'},\n",
    "    'FASTING GLUCOSE': {'min': 3.9, 'max': 5.6, 'unit': 'mmol/L'},\n",
    "    # Add more tests as needed\n",
    "}\n",
    "\n",
    "# Then apply these rules when range data is missing -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Add this to analyze_lab_data function\n",
    "# common_tests = {\n",
    "#     'TOTAL CHOLESTEROL': {'min': 0, 'max': 5.2, 'unit': 'mmol/L'},\n",
    "#     'HDL': {'min': 1.0, 'max': 3.0, 'unit': 'mmol/L'},\n",
    "#     'LDL': {'min': 0, 'max': 3.4, 'unit': 'mmol/L'},\n",
    "#     'TRIGLYCERIDES': {'min': 0, 'max': 1.7, 'unit': 'mmol/L'},\n",
    "#     'FASTING GLUCOSE': {'min': 3.9, 'max': 5.6, 'unit': 'mmol/L'},\n",
    "#     # Add more tests as needed\n",
    "# }\n",
    "\n",
    "# # Then apply these rules when range data is missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Missing Referral Completion Dates (97.41%)\n",
    "This makes it nearly impossible to establish referral sequences accurately:\n",
    "CompletedDate: 1931-03-11 00:00:00 to 2103-04-30 00:00:00 (Null: 97.41%)\n",
    "\n",
    "Fix: Use DateCreated as a fallback when CompletedDate is missing to establish temporal sequences???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Symptom Codes: While direct NYD pattern matching didn't identify explicit \"Not Yet Diagnosed\" codes, we found substantial presence of symptom codes (780-789 range) with 867,700 occurrences across 214,774 patients (60.99%). This gives us a good foundation for identifying patients with unexplained symptoms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-System Involvement: 16.56% of patients have symptoms across 2 body systems and 8.57% have symptoms across 3 systems - this aligns well with the SSD criteria requiring multi-system involvement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Referral Patterns: 6.46% of patients have psychiatric referrals, and 3.73% have both psychiatric and body system referrals - this will be important for the causal pathway analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: missingno in c:\\users\\projectc4m\\anaconda3\\lib\\site-packages (0.5.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\projectc4m\\anaconda3\\lib\\site-packages (from missingno) (1.26.4)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\projectc4m\\anaconda3\\lib\\site-packages (from missingno) (3.9.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\projectc4m\\anaconda3\\lib\\site-packages (from missingno) (1.13.1)\n",
      "Requirement already satisfied: seaborn in c:\\users\\projectc4m\\anaconda3\\lib\\site-packages (from missingno) (0.13.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\projectc4m\\anaconda3\\lib\\site-packages (from matplotlib->missingno) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\projectc4m\\anaconda3\\lib\\site-packages (from matplotlib->missingno) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\projectc4m\\anaconda3\\lib\\site-packages (from matplotlib->missingno) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\projectc4m\\anaconda3\\lib\\site-packages (from matplotlib->missingno) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\projectc4m\\anaconda3\\lib\\site-packages (from matplotlib->missingno) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\projectc4m\\anaconda3\\lib\\site-packages (from matplotlib->missingno) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\projectc4m\\anaconda3\\lib\\site-packages (from matplotlib->missingno) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\projectc4m\\anaconda3\\lib\\site-packages (from matplotlib->missingno) (2.9.0.post0)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\projectc4m\\anaconda3\\lib\\site-packages (from seaborn->missingno) (2.2.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\projectc4m\\anaconda3\\lib\\site-packages (from pandas>=1.2->seaborn->missingno) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\projectc4m\\anaconda3\\lib\\site-packages (from pandas>=1.2->seaborn->missingno) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\projectc4m\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->missingno) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~etuptools (C:\\Users\\ProjectC4M\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~etuptools (C:\\Users\\ProjectC4M\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~etuptools (C:\\Users\\ProjectC4M\\anaconda3\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "!pip install missingno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## CPCSSN Care4Mind Dataset: Data Loading and Validation"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Analysis date: 2025-03-18\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## Data Loading and Initial Validation"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Loading patient (Patient_prepared.csv)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Successfully loaded with encoding: utf-8-sig\n",
      "Loaded 352,161 rows and 6 columns\n",
      "WARNING: High missing data (>20%) in columns: ['BirthMonth', 'OptOutDate']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Loading patient_demographic (PatientDemographic_merged_prepared.csv)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Successfully loaded with encoding: utf-8-sig\n",
      "Loaded 352,220 rows and 22 columns\n",
      "WARNING: High missing data (>20%) in columns: ['Occupation', 'HighestEducation', 'HousingStatus', 'ResidencePostalCode', 'PatientStatus_calc', 'Language', 'Ethnicity', 'DeceasedYear', 'BirthMonth', 'OptOutDate', 'age']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Loading encounter (Encounter_prepared.csv)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Large table detected. Loading encounter in chunks of 500,000 rows...\n",
      "Successfully loaded with encoding: utf-8-sig\n",
      "Loaded 11,577,739 rows and 11 columns\n",
      "Converted EncounterDate to datetime. Parse failures: 0.00%\n",
      "Converted DateCreated to datetime. Parse failures: 0.00%\n",
      "WARNING: High missing data (>20%) in columns: ['Reason_orig', 'Reason_calc', 'EncounterType']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Loading encounter_diagnosis (EncounterDiagnosis_prepared.csv)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Large table detected. Loading encounter_diagnosis in chunks of 500,000 rows...\n",
      "Successfully loaded with encoding: utf-8-sig\n",
      "Loaded 12,471,764 rows and 14 columns\n",
      "Converted DateCreated to datetime. Parse failures: 0.00%\n",
      "WARNING: High missing data (>20%) in columns: ['DiagnosisText_calc', 'DiagnosisCodeType_orig', 'DiagnosisCodeType_calc', 'DiagnosisCode_calc']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Loading health_condition (HealthCondition_prepared.csv)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Successfully loaded with encoding: utf-8-sig\n",
      "Loaded 2,571,583 rows and 16 columns\n",
      "Converted DateOfOnset to datetime. Parse failures: 0.00%\n",
      "Converted DateCreated to datetime. Parse failures: 0.00%\n",
      "WARNING: High missing data (>20%) in columns: ['Encounter_ID', 'DateOfOnset', 'ActiveInactiveFlag']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Loading lab (Lab_prepared.csv)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Large table detected. Loading lab in chunks of 500,000 rows...\n",
      "Successfully loaded with encoding: utf-8-sig\n",
      "Loaded 8,528,807 rows and 22 columns\n",
      "Converted PerformedDate to datetime. Parse failures: 0.00%\n",
      "Converted DateCreated to datetime. Parse failures: 0.00%\n",
      "WARNING: High missing data (>20%) in columns: ['Encounter_ID', 'Name_calc', 'CodeType_orig', 'CodeType_calc', 'Code_orig', 'Code_calc', 'TestResult_calc', 'UpperNormal', 'LowerNormal', 'NormalRange', 'UnitOfMeasure_orig', 'UnitOfMeasure_calc']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Loading medication (Medication_prepared.csv)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Successfully loaded with encoding: utf-8-sig\n",
      "Loaded 7,706,628 rows and 27 columns\n",
      "Converted StartDate to datetime. Parse failures: 0.00%\n",
      "Converted StopDate to datetime. Parse failures: 0.00%\n",
      "Converted DateCreated to datetime. Parse failures: 0.00%\n",
      "WARNING: High missing data (>20%) in columns: ['Encounter_ID', 'StopDate', 'Reason', 'DIN', 'CodeType_orig', 'Strength', 'Dose', 'UnitOfMeasure', 'DurationCount', 'DurationUnit', 'DispensedForm']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Loading referral (Referral_prepared.csv)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Successfully loaded with encoding: utf-8-sig\n",
      "Loaded 1,141,061 rows and 12 columns\n",
      "Converted CompletedDate to datetime. Parse failures: 0.00%\n",
      "Converted DateCreated to datetime. Parse failures: 0.00%\n",
      "WARNING: High missing data (>20%) in columns: ['Encounter_ID', 'CompletedDate', 'DescriptionCode']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Loading family_history (FamilyHistory_prepared.csv)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Successfully loaded with encoding: utf-8-sig\n",
      "Loaded 325,202 rows and 20 columns\n",
      "WARNING: High missing data (>20%) in columns: ['Encounter_ID', 'DiagnosisText_calc', 'DiagnosisCodeType_orig', 'DiagnosisCodeType_calc', 'DiagnosisCode_orig', 'DiagnosisCode_calc', 'Relationship_Side_calc', 'Relationship_Degree_calc', 'AgeAtOnset', 'VitalStatus', 'AgeAtDeath']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Loading medical_procedure (MedicalProcedure_prepared.csv)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Successfully loaded with encoding: utf-8-sig\n",
      "Loaded 1,203,002 rows and 10 columns\n",
      "Converted PerformedDate to datetime. Parse failures: 0.00%\n",
      "Converted DateCreated to datetime. Parse failures: 0.00%\n",
      "WARNING: High missing data (>20%) in columns: ['Encounter_ID', 'Name_calc']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Loading risk_factor (RiskFactor_prepared.csv)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Successfully loaded with encoding: utf-8-sig\n",
      "Loaded 603,298 rows and 25 columns\n",
      "Converted StartDate to datetime. Parse failures: 0.00%\n",
      "Converted EndDate to datetime. Parse failures: 0.00%\n",
      "Converted DateCreated to datetime. Parse failures: 0.00%\n",
      "WARNING: High missing data (>20%) in columns: ['Encounter_ID', 'StartDate', 'EndDate', 'Value_orig', 'Value_calc', 'Status_orig', 'Status_calc', 'Frequency', 'FrequencyType', 'FrequencyUnit', 'Duration', 'DurationType', 'DurationUnit', 'EndDuration', 'EndDurationType', 'EndDurationUnit', 'RiskDetails']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## Data Loading Summary"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Successfully loaded 11 files with 46,833,465 total rows\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## Data Relationship Validation"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Relationship: encounter.Patient_ID -> patient.Patient_ID\n",
      "  Match rate: 100.00% (351,991/351,991 keys)\n",
      "\n",
      "Relationship: encounter_diagnosis.Encounter_ID -> encounter.Encounter_ID\n",
      "  Match rate: 93.25% (9,362,095/10,039,549 keys)\n",
      "  Orphaned records: 6.75% (677,454 keys)\n",
      "  Sample orphaned keys: [1003000000675862.0, 1003000000675866.0, 1003000000675872.0, 8001000004649001.0, 8001000004649004.0] ...\n",
      "\n",
      "Relationship: encounter_diagnosis.Patient_ID -> patient.Patient_ID\n",
      "  Match rate: 100.00% (352,161/352,161 keys)\n",
      "\n",
      "Relationship: lab.Patient_ID -> patient.Patient_ID\n",
      "  Match rate: 100.00% (207,836/207,836 keys)\n",
      "\n",
      "Relationship: lab.Encounter_ID -> encounter.Encounter_ID\n",
      "  Match rate: 11.22% (1,860/16,583 keys)\n",
      "  Orphaned records: 88.78% (14,723 keys)\n",
      "  Sample orphaned keys: [6003000000380932.0, 6003000004673540.0, 6003000000380936.0, 6003000004280328.0, 6004000000147466.0] ...\n",
      "\n",
      "Relationship: medication.Patient_ID -> patient.Patient_ID\n",
      "  Match rate: 100.00% (292,050/292,050 keys)\n",
      "\n",
      "Relationship: referral.Patient_ID -> patient.Patient_ID\n",
      "  Match rate: 100.00% (215,996/215,996 keys)\n",
      "\n",
      "Relationship: health_condition.Patient_ID -> patient.Patient_ID\n",
      "  Match rate: 100.00% (262,760/262,760 keys)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## Temporal Consistency Validation"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Date ranges by table"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Table: encounter\n",
      "  EncounterDate: 1800-02-01 00:00:00 to 2016-03-24 00:00:00 (Null: 0.00%)\n",
      "    WARNING: 0.00% (3) implausibly old dates before 1900\n",
      "  DateCreated: 1900-01-01 00:00:00 to 2015-07-21 00:00:00 (Null: 0.00%)\n",
      "Table: encounter_diagnosis\n",
      "  DateCreated: 1976-06-01 00:00:00 to 2015-07-21 00:00:00 (Null: 0.00%)\n",
      "Table: health_condition\n",
      "  DateOfOnset: 1800-01-01 00:00:00 to 2209-01-26 00:00:00 (Null: 20.48%)\n",
      "    WARNING: 0.00% (10) future dates beyond 2025\n",
      "    WARNING: 0.00% (4) implausibly old dates before 1900\n",
      "  DateCreated: 1900-01-01 00:00:00 to 2015-06-30 00:00:00 (Null: 0.00%)\n",
      "Table: lab\n",
      "  PerformedDate: 1904-10-12 00:00:00 to 2015-06-30 00:00:00 (Null: 0.02%)\n",
      "  DateCreated: 1900-01-01 00:00:00 to 2015-07-15 00:00:00 (Null: 0.00%)\n",
      "Table: medication\n",
      "  StartDate: 1800-01-13 00:00:00 to 2072-05-24 00:00:00 (Null: 0.20%)\n",
      "    WARNING: 0.00% (6) future dates beyond 2025\n",
      "    WARNING: 0.00% (1) implausibly old dates before 1900\n",
      "  StopDate: 1900-01-09 00:00:00 to 2190-07-21 00:00:00 (Null: 25.45%)\n",
      "    WARNING: 0.02% (1,026) future dates beyond 2025\n",
      "  DateCreated: 1800-01-13 00:00:00 to 2072-05-24 00:00:00 (Null: 0.00%)\n",
      "    WARNING: 0.00% (3) future dates beyond 2025\n",
      "    WARNING: 0.00% (1) implausibly old dates before 1900\n",
      "Table: referral\n",
      "  CompletedDate: 1931-03-11 00:00:00 to 2103-04-30 00:00:00 (Null: 97.41%)\n",
      "    WARNING: 0.01% (2) future dates beyond 2025\n",
      "  DateCreated: 1969-12-31 00:00:00 to 2015-08-11 00:00:00 (Null: 0.00%)\n",
      "Table: medical_procedure\n",
      "  PerformedDate: 1777-01-01 00:00:00 to 2207-01-01 00:00:00 (Null: 7.35%)\n",
      "    WARNING: 0.00% (3) future dates beyond 2025\n",
      "    WARNING: 0.00% (2) implausibly old dates before 1900\n",
      "  DateCreated: 1900-01-01 00:00:00 to 2015-06-30 00:00:00 (Null: 0.00%)\n",
      "Table: risk_factor\n",
      "  StartDate: 1922-07-15 00:00:00 to 2015-06-30 00:00:00 (Null: 92.64%)\n",
      "  EndDate: 1940-06-15 00:00:00 to 2015-06-15 00:00:00 (Null: 99.39%)\n",
      "  DateCreated: 1900-01-01 00:00:00 to 2015-06-30 00:00:00 (Null: 0.00%)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Date sequence validation"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Medication - StartDate before StopDate: 99.96% valid\n",
      "  WARNING: 0.04% (2,166/5,741,543) medication records have StartDate after StopDate\n",
      "Referral sequences: 2.74% (5,912/215,996) patients have multiple referrals\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## Patient Population Analysis"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Normalized sex distribution:\n",
      "  Female: 208,501 (59.2%)\n",
      "  Male: 143,617 (40.8%)\n",
      "  Unknown: 42 (0.0%)\n",
      "  Other: 1 (0.0%)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Demographic Distribution"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Deceased patients with valid death year: 6,472 (1.84%)\n",
      "Age statistics (as of 2025):\n",
      "  Mean: 55.7 years\n",
      "  Median: 56.0 years\n",
      "  Range: -12.0 to 125.0 years\n",
      "\n",
      "Age distribution:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age Group</th>\n",
       "      <th>Count</th>\n",
       "      <th>Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;18</td>\n",
       "      <td>20010</td>\n",
       "      <td>5.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18-34</td>\n",
       "      <td>56463</td>\n",
       "      <td>16.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35-49</td>\n",
       "      <td>69661</td>\n",
       "      <td>19.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50-64</td>\n",
       "      <td>81147</td>\n",
       "      <td>23.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65-79</td>\n",
       "      <td>73213</td>\n",
       "      <td>20.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>80+</td>\n",
       "      <td>51576</td>\n",
       "      <td>14.64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Age Group  Count  Percentage\n",
       "0       <18  20010        5.68\n",
       "1     18-34  56463       16.03\n",
       "2     35-49  69661       19.78\n",
       "3     50-64  81147       23.04\n",
       "4     65-79  73213       20.79\n",
       "5       80+  51576       14.64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sex distribution:\n",
      "  Female: 185,694 (52.7%)\n",
      "  Male: 126,316 (35.9%)\n",
      "  FEMALE: 22,845 (6.5%)\n",
      "  MALE: 17,323 (4.9%)\n",
      "  Unknown: 2 (0.0%)\n",
      "  Undifferentiated: 1 (0.0%)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Patient Data Coverage"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "patient_demographic: 100.00% (352,160/352,161 patients)\n",
      "encounter: 99.95% (351,991/352,161 patients)\n",
      "encounter_diagnosis: 100.00% (352,161/352,161 patients)\n",
      "health_condition: 74.61% (262,760/352,161 patients)\n",
      "lab: 59.02% (207,836/352,161 patients)\n",
      "medication: 82.93% (292,050/352,161 patients)\n",
      "referral: 61.33% (215,996/352,161 patients)\n",
      "family_history: 26.38% (92,902/352,161 patients)\n",
      "medical_procedure: 45.43% (159,981/352,161 patients)\n",
      "risk_factor: 54.08% (190,436/352,161 patients)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Study Eligibility Analysis"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Age eligible (≥18): 95.13% (335,066/352,221 patients)\n",
      "Encounter eligible (≥2 encounters): 97.68% (344,066/352,221 patients)\n",
      "Encounter statistics:\n",
      "  Mean: 32.9 encounters per patient\n",
      "  Median: 22 encounters per patient\n",
      "  90th percentile: 72 encounters per patient\n",
      "\n",
      "Combined eligibility (age ≥18 AND ≥2 encounters): 92.95% (327,382/352,221 patients)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## Diagnostic Coding Pattern Analysis"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Encounter Diagnosis Coding Patterns"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Diagnosis code types:\n",
      "  ICD9: 8,136,952 (65.2%)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Preliminary NYD Code Analysis"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "NYD pattern '799': 184,927 codes (1.48%) in 64,120 patients\n",
      "NYD pattern '^V71': 654 codes (0.01%) in 575 patients\n",
      "NYD pattern '^R69': 0 codes (0.00%) in 0 patients\n",
      "NYD pattern '^Z03': 0 codes (0.00%) in 0 patients\n",
      "NYD pattern '^780\\.9': 0 codes (0.00%) in 0 patients\n",
      "NYD pattern '^V65\\.5': 0 codes (0.00%) in 0 patients\n",
      "\n",
      "Most common diagnostic code roots (first 3 characters):\n",
      "  nan: 4,334,812 (34.76%)\n",
      "  401: 544,608 (4.37%)\n",
      "  250: 298,080 (2.39%)\n",
      "  V70: 280,468 (2.25%)\n",
      "  300: 266,989 (2.14%)\n",
      "  780: 261,846 (2.10%)\n",
      "  311: 231,790 (1.86%)\n",
      "  799: 177,653 (1.42%)\n",
      "  272: 170,642 (1.37%)\n",
      "  724: 167,541 (1.34%)\n",
      "  786: 135,582 (1.09%)\n",
      "  715: 108,108 (0.87%)\n",
      "  789: 96,081 (0.77%)\n",
      "  V04: 88,000 (0.71%)\n",
      "  719: 87,352 (0.70%)\n",
      "  460: 85,932 (0.69%)\n",
      "  493: 85,504 (0.69%)\n",
      "  V22: 84,470 (0.68%)\n",
      "  244: 81,464 (0.65%)\n",
      "  781: 80,681 (0.65%)\n",
      "\n",
      "Checking for potential NYD indicators in diagnostic code content...\n",
      "Code 799 (symptoms/signs): 177,653 codes (1.42%) in 58,285 patients\n",
      "Code V71 (observation without diagnosis): 654 codes (0.01%) in 575 patients\n",
      "NYD text pattern '\\bNYD\\b': 0 entries (0.00%) in 0 patients\n",
      "NYD text pattern '\\bnot yet diagnosed\\b': 0 entries (0.00%) in 0 patients\n",
      "NYD text pattern '\\bdiagnosis deferred\\b': 0 entries (0.00%) in 0 patients\n",
      "NYD text pattern '\\bunknown etiology\\b': 0 entries (0.00%) in 0 patients\n",
      "NYD text pattern '\\brule out\\b': 0 entries (0.00%) in 0 patients\n",
      "NYD text pattern '\\bunexplained\\b': 0 entries (0.00%) in 0 patients\n",
      "NYD text pattern '\\bundiagnosed\\b': 1,359 entries (0.01%) in 1,089 patients\n",
      "NYD text pattern '\\bundetermined\\b': 20 entries (0.00%) in 20 patients\n",
      "NYD text pattern '\\bsymptoms\\b': 431,974 entries (3.46%) in 125,436 patients\n",
      "NYD text pattern '\\bsymptom\\b NOT OTHERWISE SPECIFIED': 0 entries (0.00%) in 0 patients\n",
      "NYD text pattern 'without definitive diagnosis': 0 entries (0.00%) in 0 patients\n",
      "NYD text pattern 'no clear': 0 entries (0.00%) in 0 patients\n",
      "NYD text pattern 'no specific': 0 entries (0.00%) in 0 patients\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Symptom Code Analysis"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "ICD-9 Symptom codes (780-789): 867,700 codes (6.96%) in 214,774 patients (60.99%)\n",
      "\n",
      "Top symptom codes:\n",
      "  780: 128,863\n",
      "  781: 76,306\n",
      "  7862: 52,057\n",
      "  787: 51,249\n",
      "  7807: 47,291\n",
      "  7890: 46,235\n",
      "  786: 30,745\n",
      "  7840: 28,048\n",
      "  78900: 22,033\n",
      "  7865: 21,908\n",
      "\n",
      "Note: ICD-9 codes 780-789 represent 'Symptoms, Signs, and Ill-defined Conditions' and are\n",
      "particularly relevant for SSD research as they often indicate medically unexplained symptoms.\n",
      "The presence of these codes in 61.0% of patients suggests a large pool of potential\n",
      "cases with somatic symptoms that could be evaluated for SSD criteria.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Body System Distribution"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Body system 'general': 261,846 codes (2.10%) in 105,133 patients\n",
      "Body system 'gi': 176,674 codes (1.42%) in 81,585 patients\n",
      "Body system 'neuro': 97,335 codes (0.78%) in 42,654 patients\n",
      "Body system 'cardio': 36,668 codes (0.29%) in 23,332 patients\n",
      "Body system 'respiratory': 135,582 codes (1.09%) in 75,542 patients\n",
      "Body system 'musculo': 50,863 codes (0.41%) in 25,063 patients\n",
      "Body system 'skin': 60,946 codes (0.49%) in 36,027 patients\n",
      "Body system 'other': 42,632 codes (0.34%) in 26,579 patients\n",
      "\n",
      "Patients by number of body systems with symptoms:\n",
      "  0 systems: 138,298 patients (39.27%)\n",
      "  1 systems: 101,915 patients (28.94%)\n",
      "  2 systems: 58,305 patients (16.56%)\n",
      "  3 systems: 30,196 patients (8.57%)\n",
      "  4 systems: 14,309 patients (4.06%)\n",
      "  5 systems: 6,115 patients (1.74%)\n",
      "  6 systems: 2,277 patients (0.65%)\n",
      "  7 systems: 639 patients (0.18%)\n",
      "  8 systems: 107 patients (0.03%)\n",
      "\n",
      "Note: This analysis shows how many patients have symptom codes across different body systems.\n",
      "  - 0 systems: Patients with no symptom codes in any defined body system\n",
      "  - 1 system: Patients with symptoms in exactly one body system (e.g., only GI)\n",
      "  - 2+ systems: Patients with symptoms in multiple body systems - a key DSM-5 criterion for SSD\n",
      "  => 111,948 patients (31.79%) have symptoms in 2+ body systems\n",
      "\n",
      "Applying optimized lab processing...\n",
      "Implementing optimized time-based lab-encounter linkage...\n",
      "Preparing to link 8,526,891 labs to encounters\n",
      "Indexing encounters by patient (one-time operation)...\n",
      "Processing 8,526,891 labs in 34 optimized chunks...\n",
      "Processing chunk 1/34 (250,791 labs)...\n",
      "  Chunk 1 processed in 109.5s (2289.4 labs/second)\n",
      "  Progress: 185,310 labs linked, ~60.2 minutes remaining\n",
      "Processing chunk 2/34 (250,791 labs)...\n",
      "  Chunk 2 processed in 130.9s (1915.9 labs/second)\n",
      "  Progress: 378,416 labs linked, ~69.8 minutes remaining\n",
      "Processing chunk 3/34 (250,791 labs)...\n",
      "  Chunk 3 processed in 77.2s (3247.7 labs/second)\n",
      "  Progress: 584,877 labs linked, ~39.9 minutes remaining\n",
      "Processing chunk 4/34 (250,791 labs)...\n",
      "  Chunk 4 processed in 70.0s (3584.2 labs/second)\n",
      "  Progress: 771,381 labs linked, ~35.0 minutes remaining\n",
      "Processing chunk 5/34 (250,791 labs)...\n",
      "  Chunk 5 processed in 79.0s (3173.8 labs/second)\n",
      "  Progress: 967,411 labs linked, ~38.2 minutes remaining\n",
      "Processing chunk 6/34 (250,791 labs)...\n",
      "  Chunk 6 processed in 68.3s (3672.4 labs/second)\n",
      "  Progress: 1,144,015 labs linked, ~31.9 minutes remaining\n",
      "Processing chunk 7/34 (250,791 labs)...\n",
      "  Chunk 7 processed in 74.8s (3353.7 labs/second)\n",
      "  Progress: 1,339,330 labs linked, ~33.7 minutes remaining\n",
      "Processing chunk 8/34 (250,791 labs)...\n",
      "  Chunk 8 processed in 109.0s (2301.3 labs/second)\n",
      "  Progress: 1,527,058 labs linked, ~47.2 minutes remaining\n",
      "Processing chunk 9/34 (250,791 labs)...\n",
      "  Chunk 9 processed in 149.6s (1675.9 labs/second)\n",
      "  Progress: 1,726,116 labs linked, ~62.4 minutes remaining\n",
      "Processing chunk 10/34 (250,791 labs)...\n",
      "  Chunk 10 processed in 71.8s (3494.7 labs/second)\n",
      "  Progress: 1,905,329 labs linked, ~28.7 minutes remaining\n",
      "Processing chunk 11/34 (250,791 labs)...\n",
      "  Chunk 11 processed in 67.7s (3705.6 labs/second)\n",
      "  Progress: 2,087,371 labs linked, ~25.9 minutes remaining\n",
      "Processing chunk 12/34 (250,791 labs)...\n",
      "  Chunk 12 processed in 69.0s (3632.1 labs/second)\n",
      "  Progress: 2,269,774 labs linked, ~25.3 minutes remaining\n",
      "Processing chunk 13/34 (250,791 labs)...\n",
      "  Chunk 13 processed in 67.9s (3691.0 labs/second)\n",
      "  Progress: 2,458,010 labs linked, ~23.8 minutes remaining\n",
      "Processing chunk 14/34 (250,791 labs)...\n",
      "  Chunk 14 processed in 66.8s (3755.4 labs/second)\n",
      "  Progress: 2,646,697 labs linked, ~22.3 minutes remaining\n",
      "Processing chunk 15/34 (250,791 labs)...\n",
      "  Chunk 15 processed in 68.9s (3642.0 labs/second)\n",
      "  Progress: 2,840,129 labs linked, ~21.8 minutes remaining\n",
      "Processing chunk 16/34 (250,791 labs)...\n",
      "  Chunk 16 processed in 70.7s (3544.8 labs/second)\n",
      "  Progress: 3,033,449 labs linked, ~21.2 minutes remaining\n",
      "Processing chunk 17/34 (250,791 labs)...\n",
      "  Chunk 17 processed in 69.1s (3626.9 labs/second)\n",
      "  Progress: 3,227,288 labs linked, ~19.6 minutes remaining\n",
      "Processing chunk 18/34 (250,791 labs)...\n",
      "  Chunk 18 processed in 85.3s (2938.5 labs/second)\n",
      "  Progress: 3,427,022 labs linked, ~22.8 minutes remaining\n",
      "Processing chunk 19/34 (250,791 labs)...\n",
      "  Chunk 19 processed in 86.9s (2885.8 labs/second)\n",
      "  Progress: 3,629,333 labs linked, ~21.7 minutes remaining\n",
      "Processing chunk 20/34 (250,791 labs)...\n",
      "  Chunk 20 processed in 66.7s (3758.9 labs/second)\n",
      "  Progress: 3,825,494 labs linked, ~15.6 minutes remaining\n",
      "Processing chunk 21/34 (250,791 labs)...\n",
      "  Chunk 21 processed in 67.8s (3696.8 labs/second)\n",
      "  Progress: 4,024,553 labs linked, ~14.7 minutes remaining\n",
      "Processing chunk 22/34 (250,791 labs)...\n",
      "  Chunk 22 processed in 68.6s (3658.0 labs/second)\n",
      "  Progress: 4,223,398 labs linked, ~13.7 minutes remaining\n",
      "Processing chunk 23/34 (250,791 labs)...\n",
      "  Chunk 23 processed in 66.5s (3768.9 labs/second)\n",
      "  Progress: 4,416,259 labs linked, ~12.2 minutes remaining\n",
      "Processing chunk 24/34 (250,791 labs)...\n",
      "  Chunk 24 processed in 69.0s (3633.7 labs/second)\n",
      "  Progress: 4,617,780 labs linked, ~11.5 minutes remaining\n",
      "Processing chunk 25/34 (250,791 labs)...\n",
      "  Chunk 25 processed in 69.4s (3611.9 labs/second)\n",
      "  Progress: 4,821,088 labs linked, ~10.4 minutes remaining\n",
      "Processing chunk 26/34 (250,791 labs)...\n",
      "  Chunk 26 processed in 71.1s (3527.3 labs/second)\n",
      "  Progress: 5,027,100 labs linked, ~9.5 minutes remaining\n",
      "Processing chunk 27/34 (250,791 labs)...\n",
      "  Chunk 27 processed in 74.4s (3368.8 labs/second)\n",
      "  Progress: 5,240,997 labs linked, ~8.7 minutes remaining\n",
      "Processing chunk 28/34 (250,791 labs)...\n",
      "  Chunk 28 processed in 62.0s (4045.0 labs/second)\n",
      "  Progress: 5,394,553 labs linked, ~6.2 minutes remaining\n",
      "Processing chunk 29/34 (250,791 labs)...\n",
      "  Chunk 29 processed in 58.9s (4258.8 labs/second)\n",
      "  Progress: 5,550,258 labs linked, ~4.9 minutes remaining\n",
      "Processing chunk 30/34 (250,791 labs)...\n",
      "  Chunk 30 processed in 74.3s (3374.0 labs/second)\n",
      "  Progress: 5,751,967 labs linked, ~5.0 minutes remaining\n",
      "Processing chunk 31/34 (250,791 labs)...\n",
      "  Chunk 31 processed in 68.9s (3638.9 labs/second)\n",
      "  Progress: 5,945,926 labs linked, ~3.4 minutes remaining\n",
      "Processing chunk 32/34 (250,790 labs)...\n",
      "  Chunk 32 processed in 66.5s (3772.3 labs/second)\n",
      "  Progress: 6,133,230 labs linked, ~2.2 minutes remaining\n",
      "Processing chunk 33/34 (250,790 labs)...\n",
      "  Chunk 33 processed in 67.3s (3723.8 labs/second)\n",
      "  Progress: 6,318,771 labs linked, ~1.1 minutes remaining\n",
      "Processing chunk 34/34 (250,790 labs)...\n",
      "  Chunk 34 processed in 66.3s (3780.0 labs/second)\n",
      "  Progress: 6,503,897 labs linked, ~0.0 minutes remaining\n",
      "Successfully linked 6,503,897 labs in 43.5 minutes\n",
      "Total labs with encounter association: 6,625,349 (77.68%)\n",
      "Enhancing lab classification with optimized approach...\n",
      "Processing 1,190,548 labs with explicit normal ranges...\n",
      "Method 1: Processed 1,183,776 labs (13.88%)\n",
      "Method 2: Processed 2,983,649 labs (34.98%)\n",
      "Method 3: Processed 0 labs (0.00%)\n",
      "Lab classification completed in 22.6 seconds\n",
      "Overall: Classified 4,167,425 labs (48.86%)\n",
      "Normal: 2,400,155 (57.59% of classified)\n",
      "Abnormal: 1,767,270 (42.41% of classified)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## Lab Data Analysis"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Lab Test Overview"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Total lab tests: 8,528,807\n",
      "Patients with lab data: 207,836\n",
      "Average lab tests per patient: 41.0\n",
      "\n",
      "Most common lab tests:\n",
      "  TOTAL CHOLESTEROL: 711,481 (8.34%)\n",
      "  HDL: 710,700 (8.33%)\n",
      "  LDL: 704,991 (8.27%)\n",
      "  TRIGLYCERIDES: 688,773 (8.08%)\n",
      "  FASTING GLUCOSE: 646,306 (7.58%)\n",
      "  HBA1C: 449,108 (5.27%)\n",
      "  GFR: 197,833 (2.32%)\n",
      "  INR: 173,373 (2.03%)\n",
      "  URINE ALBUMIN CREATININE RATIO: 124,056 (1.45%)\n",
      "  MICROALBUMIN: 85,715 (1.01%)\n",
      "  GLUCOSE TOLERANCE: 7,873 (0.09%)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Normal Range Data Availability"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Labs with both normal bounds: 1,219,699 (14.30%)\n",
      "  TOTAL CHOLESTEROL: 159,118/711,481 (22.36%)\n",
      "  HDL: 137,948/710,700 (19.41%)\n",
      "  LDL: 141,267/704,991 (20.04%)\n",
      "  TRIGLYCERIDES: 174,687/688,773 (25.36%)\n",
      "  FASTING GLUCOSE: 176,601/646,306 (27.32%)\n",
      "  HBA1C: 109,416/449,108 (24.36%)\n",
      "  GFR: 133,869/197,833 (67.67%)\n",
      "  INR: 143,588/173,373 (82.82%)\n",
      "  URINE ALBUMIN CREATININE RATIO: 32,097/124,056 (25.87%)\n",
      "  MICROALBUMIN: 10,389/85,715 (12.12%)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Numeric Test Result Availability"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Labs with numeric results: 4,304,804 (50.47%)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Patient-Level Lab Testing Patterns"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Lab test statistics:\n",
      "  Mean: 41.0 tests per patient\n",
      "  Median: 15 tests per patient\n",
      "  90th percentile: 79 tests per patient\n",
      "  Maximum: 4064 tests per patient\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Preliminary Normal Lab Analysis"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Labs with full data for normal analysis: 1,190,548 (13.96%)\n",
      "Normal lab results: 483,817 (40.64%)\n",
      "Patients with ≥3 normal labs: 46,326 (68.06%)\n",
      "Patients with ≥4 normal labs: 39,952 (58.70%)\n",
      "Patients with ≥5 normal labs: 33,985 (49.93%)\n",
      "\n",
      "Applying optimized referral processing...\n",
      "Implementing referral date enhancement (optimized)...\n",
      "CompletedDate missing in 1,111,454 referrals (97.41%)\n",
      "After fallback: 0 referrals still missing dates (0.00%)\n",
      "Using DateCreated for 1,111,454 referrals\n",
      "\n",
      "Referral Status Distribution:\n",
      "  Pending: 1,111,454 (97.41%)\n",
      "  Completed: 29,607 (2.59%)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## Referral Pattern Analysis"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Referral Overview"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Total referrals: 1,141,061\n",
      "Patients with referrals: 215,996\n",
      "Average referrals per patient: 5.3\n",
      "\n",
      "Most common referral types:\n",
      "  REFERRAL TO ANESTHETIC SERVICE: 296,113 (25.95%)\n",
      "  REFERRAL TO ACCIDENT AND EMERGENCY SERVICE: 104,518 (9.16%)\n",
      "  REFERRAL TO DERMATOLOGY SERVICE: 62,564 (5.48%)\n",
      "  REFERRAL TO OBSTETRICS AND GYNECOLOGY SERVICE: 51,453 (4.51%)\n",
      "  REFERRAL TO GASTROENTEROLOGY SERVICE: 50,668 (4.44%)\n",
      "  REFERRAL TO EAR, NOSE AND THROAT SERVICE: 40,156 (3.52%)\n",
      "  REFERRAL TO ORTHOPEDIC SERVICE: 39,470 (3.46%)\n",
      "  REFERRAL TO GENERAL SURGICAL SERVICE: 30,380 (2.66%)\n",
      "  REFERRAL TO GENERAL MEDICAL SERVICE: 29,879 (2.62%)\n",
      "  REFERRAL TO OPHTHALMOLOGY SERVICE: 27,271 (2.39%)\n",
      "  REFERRAL TO CARDIOLOGY SERVICE: 22,393 (1.96%)\n",
      "  REFERRAL TO NEUROLOGY SERVICE: 21,100 (1.85%)\n",
      "  REFERRAL TO PHYSIOTHERAPY SERVICE: 21,085 (1.85%)\n",
      "  REFERRAL TO PSYCHIATRY SERVICE: 18,167 (1.59%)\n",
      "  REFERRAL TO PLASTIC SURGERY SERVICE: 17,060 (1.50%)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Psychiatric Referral Analysis"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Psychiatric referrals: 20,765 (1.82%)\n",
      "Patients with psychiatric referrals: 13,948 (6.46%)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Body System Specialist Analysis"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "\n",
      "Body system referral distribution:\n",
      "  cardio: 26,273 referrals (2.30%) in 16,431 patients (7.61%)\n",
      "  gastro: 57,913 referrals (5.08%) in 35,924 patients (16.63%)\n",
      "  neuro: 25,273 referrals (2.21%) in 17,258 patients (7.99%)\n",
      "  musculo: 53,979 referrals (4.73%) in 32,543 patients (15.07%)\n",
      "  respiratory: 6,246 referrals (0.55%) in 5,286 patients (2.45%)\n",
      "  endo: 7,594 referrals (0.67%) in 5,684 patients (2.63%)\n",
      "  derm: 62,872 referrals (5.51%) in 40,251 patients (18.64%)\n",
      "  gyn: 68,342 referrals (5.99%) in 41,946 patients (19.42%)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Multi-Specialty Referral Patterns"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Referral statistics:\n",
      "  Mean: 5.3 referrals per patient\n",
      "  Median: 3 referrals per patient\n",
      "  90th percentile: 12 referrals per patient\n",
      "\n",
      "Patient referral patterns:\n",
      "  Psychiatry only: 5,897 patients (2.73%)\n",
      "  Body system only: 110,759 patients (51.28%)\n",
      "  Both psychiatry and body system: 8,051 patients (3.73%)\n",
      "  Neither (other or unclassified referrals): 91,289 patients (42.26%)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## Saving Validation Results"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Saved validation report to output\\data_validation_report.json\n",
      "\n",
      "Validation Summary:\n",
      "  Tables Loaded: 11\n",
      "  Total Patients: Unknown\n",
      "  Data Relationship Issues: True\n",
      "  Normal Lab Data Available: 14.300933295829065\n",
      "  Patients with NYD Codes: 64120\n",
      "  Psychiatry Referrals: 13948\n",
      "Saved patient (352,161 rows) as parquet\n",
      "Saved patient_demographic (352,220 rows) as parquet\n",
      "Saved encounter (11,577,739 rows) as parquet\n",
      "Saved encounter_diagnosis (12,471,764 rows) as parquet\n",
      "Saved health_condition (2,571,583 rows) as parquet\n",
      "Saved lab (8,528,807 rows) as CSV\n",
      "Saved medication (7,706,628 rows) as parquet\n",
      "Saved referral (1,141,061 rows) as parquet\n",
      "Saved family_history (325,202 rows) as parquet\n",
      "Saved medical_procedure (1,203,002 rows) as parquet\n",
      "Saved risk_factor (603,298 rows) as parquet\n",
      "\n",
      "Checkpoint saved at: data\\interim\\checkpoint_1_20250318_024427\n",
      "README created: data\\interim\\checkpoint_1_20250318_024427\\README.md\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## Optimized Data Validation Complete"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "✓ Data loaded and validated with fixes\n",
      "✓ NYD code reporting corrected\n",
      "✓ Lab-encounter temporal linkage implemented (optimized)\n",
      "✓ Normal lab detection significantly expanded (optimized)\n",
      "✓ Referral date handling improved (optimized)\n",
      "✓ Comprehensive documentation created\n",
      "\n",
      "Proceed to Notebook 2: NYD_Identification.ipynb\n",
      "Load data from: data\\interim\\checkpoint_1_20250318_024427\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# ---------------------------------------------------------------------------- #\n",
    "# 01_Data_Loading_Validation.ipynb                                             #\n",
    "# ---------------------------------------------------------------------------- #\n",
    "# Purpose: Load CPCSSN datasets for Somatic Symptom Disorder (SSD) causal      #\n",
    "# pathway analysis, validate data quality and relationships, and establish      #\n",
    "# base statistics for downstream analysis.                                     #\n",
    "# ---------------------------------------------------------------------------- #\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import json\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import re\n",
    "import missingno as msno\n",
    "from scipy import stats\n",
    "from IPython.display import display, Markdown, HTML\n",
    "\n",
    "# Configure visualization settings for publication quality\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_context(\"paper\", font_scale=1.5)\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['savefig.dpi'] = 300\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['font.sans-serif'] = ['Arial']\n",
    "\n",
    "# Suppress specific warnings while maintaining important ones\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=pd.errors.PerformanceWarning)\n",
    "pd.options.mode.chained_assignment = None  # Suppress SettingWithCopyWarning\n",
    "\n",
    "# Display options for better readability\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 60)\n",
    "pd.set_option('display.width', 200)\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "\n",
    "# ------------------------------- Configuration ------------------------------- #\n",
    "\n",
    "# Define paths configuration\n",
    "class Config:\n",
    "    # Base paths\n",
    "    DATA_PATH = Path(r\"C:\\Users\\ProjectC4M\\Documents\\CPCSSN Datasets Care4Mind\\New Extraction Feb 2025\\prepared_data\")\n",
    "    OUTPUT_PATH = Path(\"output\")\n",
    "    INTERIM_PATH = Path(\"data/interim\")\n",
    "    \n",
    "    # Create directories if they don't exist\n",
    "    for path in [OUTPUT_PATH, INTERIM_PATH]:\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "    \n",
    "    # Dataset filenames\n",
    "    DATASETS = {\n",
    "        'patient': 'Patient_prepared.csv',\n",
    "        'patient_demographic': 'PatientDemographic_merged_prepared.csv', \n",
    "        'encounter': 'Encounter_prepared.csv',\n",
    "        'encounter_diagnosis': 'EncounterDiagnosis_prepared.csv',\n",
    "        'health_condition': 'HealthCondition_prepared.csv',\n",
    "        'lab': 'Lab_prepared.csv',\n",
    "        'medication': 'Medication_prepared.csv',\n",
    "        'referral': 'Referral_prepared.csv',\n",
    "        'family_history': 'FamilyHistory_prepared.csv',\n",
    "        'medical_procedure': 'MedicalProcedure_prepared.csv',\n",
    "        'risk_factor': 'RiskFactor_prepared.csv'\n",
    "    }\n",
    "    \n",
    "    # Required columns by table (based on provided configuration)\n",
    "    REQUIRED_COLUMNS = {\n",
    "        'patient': ['Patient_ID', 'Sex', 'BirthYear', 'BirthMonth'],\n",
    "        'patient_demographic': ['Patient_ID', 'PatientDemographic_ID', 'Network_ID', 'Site_ID'],\n",
    "        'encounter': ['Encounter_ID', 'Patient_ID', 'Provider_ID', 'EncounterDate', 'EncounterType'],\n",
    "        'encounter_diagnosis': ['EncounterDiagnosis_ID', 'Encounter_ID', 'Patient_ID', 'DiagnosisCode_calc', 'DiagnosisText_calc'],\n",
    "        'health_condition': ['HealthCondition_ID', 'Patient_ID', 'DiagnosisCode_calc', 'DateOfOnset'],\n",
    "        'lab': ['Lab_ID', 'Patient_ID', 'PerformedDate', 'Name_calc', 'TestResult_calc', 'UpperNormal', 'LowerNormal'],\n",
    "        'medication': ['Medication_ID', 'Patient_ID', 'StartDate', 'StopDate', 'Name_calc'],\n",
    "        'referral': ['Referral_ID', 'Patient_ID', 'CompletedDate', 'Name_calc']\n",
    "    }\n",
    "    \n",
    "    # Date columns that need conversion\n",
    "    DATE_COLUMNS = {\n",
    "        'encounter': ['EncounterDate', 'DateCreated'],\n",
    "        'encounter_diagnosis': ['DateCreated'],\n",
    "        'health_condition': ['DateOfOnset', 'DateCreated'],\n",
    "        'lab': ['PerformedDate', 'DateCreated'],\n",
    "        'medication': ['StartDate', 'StopDate', 'DateCreated'],\n",
    "        'referral': ['CompletedDate', 'DateCreated'],\n",
    "        'medical_procedure': ['PerformedDate', 'DateCreated'],\n",
    "        'risk_factor': ['StartDate', 'EndDate', 'DateCreated']\n",
    "    }\n",
    "    \n",
    "    # Study parameters\n",
    "    CURRENT_YEAR = 2025  # Reference year for age calculations\n",
    "    MIN_AGE = 18  # Inclusion criterion: minimum age\n",
    "    MIN_ENCOUNTERS = 2  # Minimum encounters for inclusion\n",
    "\n",
    "config = Config()\n",
    "\n",
    "\n",
    "# ----------------------------- Helper Functions ----------------------------- #\n",
    "\n",
    "def print_section_header(title):\n",
    "    \"\"\"Print formatted section header for better notebook organization.\"\"\"\n",
    "    display(Markdown(f\"## {title}\"))\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "def print_subsection_header(title):\n",
    "    \"\"\"Print formatted subsection header for better notebook organization.\"\"\"\n",
    "    display(Markdown(f\"### {title}\"))\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "def format_percentage(value):\n",
    "    \"\"\"Format decimal as percentage with 2 decimal places.\"\"\"\n",
    "    return f\"{value:.2%}\"\n",
    "\n",
    "def display_dataset_info(name, df):\n",
    "    \"\"\"Display basic dataset information in a formatted way.\"\"\"\n",
    "    print(f\"Dataset: {name}\")\n",
    "    print(f\"Shape: {df.shape[0]:,} rows × {df.shape[1]} columns\")\n",
    "    print(f\"Memory usage: {df.memory_usage(deep=True).sum() / (1024**2):.2f} MB\")\n",
    "    \n",
    "    # Sample of first few rows\n",
    "    display(df.head(3))\n",
    "    \n",
    "    # Column information\n",
    "    column_info = pd.DataFrame({\n",
    "        'Column': df.columns,\n",
    "        'Type': df.dtypes,\n",
    "        'Non-Null Count': df.count(),\n",
    "        'Non-Null %': df.count() / len(df) * 100,\n",
    "        'Unique Values': [df[col].nunique() for col in df.columns]\n",
    "    })\n",
    "    \n",
    "    display(column_info)\n",
    "    print(\"\\n\")\n",
    "\n",
    "# --------------------------- Main Loading Function -------------------------- #\n",
    "\n",
    "def load_and_validate_data(required_tables=None):\n",
    "    \"\"\"\n",
    "    Load CPCSSN datasets with comprehensive validation and quality checks.\n",
    "    \n",
    "    This function implements a robust data loading pipeline with:\n",
    "    1. Standardized error handling for file access issues\n",
    "    2. Multiple encoding fallbacks (UTF-8, latin1, etc.)\n",
    "    3. Required column validation\n",
    "    4. Automatic date column conversion\n",
    "    5. Data type verification and standardization\n",
    "    6. Basic quality metrics calculation\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    required_tables : list, optional\n",
    "        Specific tables to load; if None, loads all configured tables\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary of dataframes with table names as keys\n",
    "    dict\n",
    "        Dictionary of data quality metrics for each table\n",
    "    \n",
    "    Notes:\n",
    "    ------\n",
    "    The function follows ETL best practices from clinical data research:\n",
    "    - Standardized approach across all tables (Kahn et al., 2016)\n",
    "    - Explicit validation steps (Weiskopf & Weng, 2013)\n",
    "    - Careful attention to date/time handling (Hripcsak & Albers, 2013)\n",
    "    \"\"\"\n",
    "    print_section_header(\"Data Loading and Initial Validation\")\n",
    "    \n",
    "    # If no specific tables are requested, load all\n",
    "    if required_tables is None:\n",
    "        required_tables = config.DATASETS.keys()\n",
    "    \n",
    "    data_dict = {}\n",
    "    quality_metrics = {}\n",
    "    \n",
    "    # Track overall metrics\n",
    "    total_rows = 0\n",
    "    total_files = 0\n",
    "    loading_errors = 0\n",
    "    \n",
    "    for key in required_tables:\n",
    "        if key not in config.DATASETS:\n",
    "            print(f\"WARNING: Table '{key}' not found in configuration.\")\n",
    "            continue\n",
    "            \n",
    "        filename = config.DATASETS[key]\n",
    "        file_path = config.DATA_PATH / filename\n",
    "        \n",
    "        print_subsection_header(f\"Loading {key} ({filename})\")\n",
    "        \n",
    "        # Initialize quality metrics for this table\n",
    "        quality_metrics[key] = {\n",
    "            'exists': False,\n",
    "            'loaded_successfully': False,\n",
    "            'row_count': 0,\n",
    "            'column_count': 0,\n",
    "            'missing_required_columns': [],\n",
    "            'missing_data_percentage': {},\n",
    "            'date_column_quality': {},\n",
    "            'invalid_row_percentage': 0.0,\n",
    "        }\n",
    "        \n",
    "        # Check if file exists\n",
    "        if not file_path.exists():\n",
    "            print(f\"ERROR: File {filename} does not exist at {file_path}\")\n",
    "            continue\n",
    "            \n",
    "        quality_metrics[key]['exists'] = True\n",
    "        total_files += 1\n",
    "        \n",
    "        # Attempt to load with multiple encodings\n",
    "        for encoding in ['utf-8-sig', 'utf-8', 'latin1', 'cp1252']:\n",
    "            try:\n",
    "                # Use chunks for large files (especially Lab and Encounter tables)\n",
    "                # This is crucial for working with large CPCSSN datasets efficiently\n",
    "                if key in ['lab', 'encounter', 'encounter_diagnosis']:\n",
    "                    # For large tables, use chunked reading with dask or chunks\n",
    "                    chunk_size = 500000  # Adjust based on memory constraints\n",
    "                    print(f\"Large table detected. Loading {key} in chunks of {chunk_size:,} rows...\")\n",
    "                    \n",
    "                    chunks = []\n",
    "                    for chunk in pd.read_csv(file_path, encoding=encoding, \n",
    "                                             chunksize=chunk_size, low_memory=False):\n",
    "                        chunks.append(chunk)\n",
    "                    \n",
    "                    if chunks:\n",
    "                        df = pd.concat(chunks, ignore_index=True)\n",
    "                    else:\n",
    "                        df = pd.DataFrame()  # Empty dataframe if no chunks\n",
    "                else:\n",
    "                    # Regular loading for smaller tables\n",
    "                    df = pd.read_csv(file_path, encoding=encoding, low_memory=False)\n",
    "                \n",
    "                print(f\"Successfully loaded with encoding: {encoding}\")\n",
    "                break\n",
    "                \n",
    "            except UnicodeDecodeError:\n",
    "                print(f\"Failed to load with encoding: {encoding}, trying next...\")\n",
    "                continue\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"ERROR loading {filename}: {str(e)}\")\n",
    "                loading_errors += 1\n",
    "                break\n",
    "        else:\n",
    "            # This executes if no break occurs in the for loop (all encodings failed)\n",
    "            print(f\"ERROR: Failed to load {filename} with any encoding\")\n",
    "            continue\n",
    "            \n",
    "        # Mark as successfully loaded\n",
    "        quality_metrics[key]['loaded_successfully'] = True\n",
    "        data_dict[key] = df\n",
    "        \n",
    "        # Basic metrics\n",
    "        row_count = len(df)\n",
    "        col_count = len(df.columns)\n",
    "        total_rows += row_count\n",
    "        \n",
    "        quality_metrics[key]['row_count'] = row_count\n",
    "        quality_metrics[key]['column_count'] = col_count\n",
    "        \n",
    "        print(f\"Loaded {row_count:,} rows and {col_count} columns\")\n",
    "        \n",
    "        # Check for required columns\n",
    "        if key in config.REQUIRED_COLUMNS:\n",
    "            missing_cols = [col for col in config.REQUIRED_COLUMNS[key] \n",
    "                           if col not in df.columns]\n",
    "            \n",
    "            if missing_cols:\n",
    "                print(f\"WARNING: Missing required columns in {key}: {missing_cols}\")\n",
    "                quality_metrics[key]['missing_required_columns'] = missing_cols\n",
    "                \n",
    "        # Convert date columns\n",
    "        if key in config.DATE_COLUMNS:\n",
    "            date_quality = {}\n",
    "            for date_col in config.DATE_COLUMNS[key]:\n",
    "                if date_col in df.columns:\n",
    "                    # Store original count to measure parse failures\n",
    "                    orig_non_null = df[date_col].notna().sum()\n",
    "                    \n",
    "                    # Convert to datetime\n",
    "                    df[date_col] = pd.to_datetime(df[date_col], errors='coerce')\n",
    "                    \n",
    "                    # Measure quality\n",
    "                    new_non_null = df[date_col].notna().sum()\n",
    "                    parse_failure_rate = 1.0 - (new_non_null / orig_non_null) if orig_non_null > 0 else 0\n",
    "                    \n",
    "                    date_quality[date_col] = {\n",
    "                        'coverage': new_non_null / len(df),\n",
    "                        'parse_failure_rate': parse_failure_rate,\n",
    "                        'min_date': df[date_col].min(),\n",
    "                        'max_date': df[date_col].max(),\n",
    "                        'null_count': df[date_col].isna().sum()\n",
    "                    }\n",
    "                    \n",
    "                    print(f\"Converted {date_col} to datetime. \" +\n",
    "                          f\"Parse failures: {parse_failure_rate:.2%}\")\n",
    "            \n",
    "            quality_metrics[key]['date_column_quality'] = date_quality\n",
    "                    \n",
    "        # Calculate missing data percentage per column\n",
    "        missing_pct = df.isna().mean().to_dict()\n",
    "        quality_metrics[key]['missing_data_percentage'] = missing_pct\n",
    "        \n",
    "        # Check for basic invalid data\n",
    "        # For numeric columns, check for out-of-range values\n",
    "        invalid_rows = 0\n",
    "        # Add specific validation based on column types\n",
    "        \n",
    "        # Calculate quality statistics\n",
    "        high_missing_cols = [col for col, pct in missing_pct.items() if pct > 0.2]\n",
    "        if high_missing_cols:\n",
    "            print(f\"WARNING: High missing data (>20%) in columns: {high_missing_cols}\")\n",
    "            \n",
    "    # Print overall summary\n",
    "    print_section_header(\"Data Loading Summary\")\n",
    "    print(f\"Successfully loaded {total_files} files with {total_rows:,} total rows\")\n",
    "    if loading_errors > 0:\n",
    "        print(f\"WARNING: Encountered {loading_errors} loading errors\")\n",
    "        \n",
    "    return data_dict, quality_metrics\n",
    "\n",
    "\n",
    "# --------------------------- Data Validation Functions -------------------------- #\n",
    "\n",
    "def validate_data_relationships(data_dict):\n",
    "    \"\"\"\n",
    "    Validate foreign key relationships between datasets to ensure referential integrity.\n",
    "    \n",
    "    This function checks how well foreign keys in dependent tables (e.g., encounters, labs)\n",
    "    match primary keys in reference tables (e.g., patients). High integrity is crucial for\n",
    "    reliable analysis, as broken references can lead to data loss during joins.\n",
    "    \n",
    "    The function implements recommendations from:\n",
    "    - Kahn et al. (2016) \"A Harmonized Data Quality Assessment Terminology and Framework...\"\n",
    "    - Weiskopf & Weng (2013) \"Methods and dimensions of electronic health record data quality...\"\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data_dict : dict\n",
    "        Dictionary of dataframes with table names as keys\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary of relationship metrics between tables\n",
    "    \"\"\"\n",
    "    print_section_header(\"Data Relationship Validation\")\n",
    "    \n",
    "    relationships = {}\n",
    "    \n",
    "    # Define key relationships to check\n",
    "    key_relationships = [\n",
    "        # dependent_table, reference_table, foreign_key, primary_key\n",
    "        ('encounter', 'patient', 'Patient_ID', 'Patient_ID'),\n",
    "        ('encounter_diagnosis', 'encounter', 'Encounter_ID', 'Encounter_ID'),\n",
    "        ('encounter_diagnosis', 'patient', 'Patient_ID', 'Patient_ID'),\n",
    "        ('lab', 'patient', 'Patient_ID', 'Patient_ID'),\n",
    "        ('lab', 'encounter', 'Encounter_ID', 'Encounter_ID'),\n",
    "        ('medication', 'patient', 'Patient_ID', 'Patient_ID'),\n",
    "        ('referral', 'patient', 'Patient_ID', 'Patient_ID'),\n",
    "        ('health_condition', 'patient', 'Patient_ID', 'Patient_ID')\n",
    "    ]\n",
    "    \n",
    "    for dep_table, ref_table, fk, pk in key_relationships:\n",
    "        # Skip if either table is missing\n",
    "        if dep_table not in data_dict or ref_table not in data_dict:\n",
    "            print(f\"Skipping relationship check: {dep_table}.{fk} -> {ref_table}.{pk} (table missing)\")\n",
    "            continue\n",
    "            \n",
    "        # Skip if columns don't exist\n",
    "        if fk not in data_dict[dep_table].columns or pk not in data_dict[ref_table].columns:\n",
    "            print(f\"Skipping relationship check: {dep_table}.{fk} -> {ref_table}.{pk} (column missing)\")\n",
    "            continue\n",
    "            \n",
    "        # Get unique keys from both tables\n",
    "        dep_keys = set(data_dict[dep_table][fk].dropna().unique())\n",
    "        ref_keys = set(data_dict[ref_table][pk].dropna().unique())\n",
    "        \n",
    "        # Calculate metrics\n",
    "        matching_keys = dep_keys.intersection(ref_keys)\n",
    "        orphaned_keys = dep_keys - ref_keys\n",
    "        \n",
    "        # As percentages\n",
    "        total_dep_keys = len(dep_keys)\n",
    "        match_pct = len(matching_keys) / total_dep_keys if total_dep_keys > 0 else 0\n",
    "        orphan_pct = len(orphaned_keys) / total_dep_keys if total_dep_keys > 0 else 0\n",
    "        \n",
    "        # Store metrics\n",
    "        rel_key = f\"{dep_table}.{fk} -> {ref_table}.{pk}\"\n",
    "        relationships[rel_key] = {\n",
    "            'dependent_table': dep_table,\n",
    "            'reference_table': ref_table,\n",
    "            'foreign_key': fk,\n",
    "            'primary_key': pk,\n",
    "            'total_unique_keys': total_dep_keys,\n",
    "            'matching_keys': len(matching_keys),\n",
    "            'orphaned_keys': len(orphaned_keys),\n",
    "            'match_percentage': match_pct,\n",
    "            'orphan_percentage': orphan_pct\n",
    "        }\n",
    "        \n",
    "        # Print summary\n",
    "        print(f\"Relationship: {rel_key}\")\n",
    "        print(f\"  Match rate: {match_pct:.2%} ({len(matching_keys):,}/{total_dep_keys:,} keys)\")\n",
    "        if orphan_pct > 0:\n",
    "            print(f\"  Orphaned records: {orphan_pct:.2%} ({len(orphaned_keys):,} keys)\")\n",
    "            # Show sample of orphaned keys (useful for debugging)\n",
    "            if len(orphaned_keys) <= 5:\n",
    "                print(f\"  Sample orphaned keys: {list(orphaned_keys)}\")\n",
    "            else:\n",
    "                print(f\"  Sample orphaned keys: {list(orphaned_keys)[:5]} ...\")\n",
    "        print()\n",
    "        \n",
    "    # Create summary table for visualization\n",
    "    if relationships:\n",
    "        rel_df = pd.DataFrame([\n",
    "            {\n",
    "                'Relationship': k,\n",
    "                'Match Rate': v['match_percentage'],\n",
    "                'Orphaned Rate': v['orphan_percentage'],\n",
    "                'Total Keys': v['total_unique_keys']\n",
    "            }\n",
    "            for k, v in relationships.items()\n",
    "        ])\n",
    "        \n",
    "        # Sort by match rate\n",
    "        rel_df = rel_df.sort_values('Match Rate')\n",
    "        \n",
    "        # Plot relationship metrics\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        bars = plt.barh(rel_df['Relationship'], rel_df['Match Rate'])\n",
    "        \n",
    "        # Add percentage labels\n",
    "        for i, bar in enumerate(bars):\n",
    "            width = bar.get_width()\n",
    "            label = f\"{width:.1%}\"\n",
    "            plt.text(max(0.05, width - 0.1), bar.get_y() + bar.get_height()/2, \n",
    "                    label, ha='center', va='center', color='white', fontweight='bold')\n",
    "        \n",
    "        plt.xlabel('Match Rate (% of dependent keys found in reference table)')\n",
    "        plt.title('Data Relationship Integrity')\n",
    "        plt.xlim(0, 1.0)\n",
    "        plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(config.OUTPUT_PATH / 'relationship_integrity.png')\n",
    "        plt.close()\n",
    "        \n",
    "    return relationships\n",
    "\n",
    "def validate_temporal_consistency(data_dict):\n",
    "    \"\"\"\n",
    "    Validate temporal consistency in date columns across datasets.\n",
    "    \n",
    "    This function checks for:\n",
    "    1. Chronological consistency (e.g., start dates before end dates)\n",
    "    2. Date ranges within reasonable study period\n",
    "    3. Temporal alignment between related events\n",
    "    \n",
    "    Temporal consistency is essential for accurate pathway analysis, especially for\n",
    "    establishing the correct sequence of NYD status, lab tests, referrals, and diagnoses.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data_dict : dict\n",
    "        Dictionary of dataframes with table names as keys\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary of temporal consistency metrics\n",
    "    \"\"\"\n",
    "    print_section_header(\"Temporal Consistency Validation\")\n",
    "    \n",
    "    temporal_metrics = {}\n",
    "    \n",
    "    # 1. Check date ranges in each table\n",
    "    print_subsection_header(\"Date ranges by table\")\n",
    "    \n",
    "    for table_name, df in data_dict.items():\n",
    "        date_cols = [col for col in df.columns if pd.api.types.is_datetime64_dtype(df[col])]\n",
    "        if not date_cols:\n",
    "            continue\n",
    "            \n",
    "        table_metrics = {}\n",
    "        print(f\"Table: {table_name}\")\n",
    "        \n",
    "        for col in date_cols:\n",
    "            # Skip if all null\n",
    "            if df[col].isna().all():\n",
    "                continue\n",
    "                \n",
    "            min_date = df[col].min()\n",
    "            max_date = df[col].max()\n",
    "            null_count = df[col].isna().sum()\n",
    "            null_pct = null_count / len(df)\n",
    "            \n",
    "            # Check for future dates (beyond current study year)\n",
    "            future_date_threshold = pd.Timestamp(f\"{config.CURRENT_YEAR+1}-01-01\")\n",
    "            future_dates = df[col] >= future_date_threshold\n",
    "            future_count = future_dates.sum()\n",
    "            future_pct = future_count / df[col].notna().sum() if df[col].notna().any() else 0\n",
    "            \n",
    "            # Check for implausible past dates (before 1900)\n",
    "            past_date_threshold = pd.Timestamp(\"1900-01-01\")\n",
    "            past_dates = df[col] < past_date_threshold\n",
    "            past_count = past_dates.sum()\n",
    "            past_pct = past_count / df[col].notna().sum() if df[col].notna().any() else 0\n",
    "            \n",
    "            print(f\"  {col}: {min_date} to {max_date} (Null: {null_pct:.2%})\")\n",
    "            if future_pct > 0:\n",
    "                print(f\"    WARNING: {future_pct:.2%} ({future_count:,}) future dates beyond {config.CURRENT_YEAR}\")\n",
    "            if past_pct > 0:\n",
    "                print(f\"    WARNING: {past_pct:.2%} ({past_count:,}) implausibly old dates before 1900\")\n",
    "                \n",
    "            table_metrics[col] = {\n",
    "                'min_date': min_date,\n",
    "                'max_date': max_date,\n",
    "                'null_percentage': null_pct,\n",
    "                'future_date_percentage': future_pct,\n",
    "                'past_date_percentage': past_pct\n",
    "            }\n",
    "            \n",
    "        temporal_metrics[table_name] = table_metrics\n",
    "        \n",
    "    # 2. Check for specific date sequence consistency\n",
    "    print_subsection_header(\"Date sequence validation\")\n",
    "    \n",
    "    # Medication: StartDate before StopDate\n",
    "    if 'medication' in data_dict and 'StartDate' in data_dict['medication'].columns and 'StopDate' in data_dict['medication'].columns:\n",
    "        med_df = data_dict['medication']\n",
    "        # Only check rows with both dates non-null\n",
    "        both_dates = med_df['StartDate'].notna() & med_df['StopDate'].notna()\n",
    "        total_both_dates = both_dates.sum()\n",
    "        \n",
    "        if total_both_dates > 0:\n",
    "            invalid_sequence = (med_df['StartDate'] > med_df['StopDate']) & both_dates\n",
    "            invalid_count = invalid_sequence.sum()\n",
    "            invalid_pct = invalid_count / total_both_dates\n",
    "            \n",
    "            print(f\"Medication - StartDate before StopDate: {(1-invalid_pct):.2%} valid\")\n",
    "            if invalid_pct > 0:\n",
    "                print(f\"  WARNING: {invalid_pct:.2%} ({invalid_count:,}/{total_both_dates:,}) \" +\n",
    "                      f\"medication records have StartDate after StopDate\")\n",
    "                \n",
    "            temporal_metrics['medication_sequence'] = {\n",
    "                'check': 'StartDate_before_StopDate',\n",
    "                'valid_percentage': 1 - invalid_pct,\n",
    "                'invalid_count': invalid_count,\n",
    "                'total_checked': total_both_dates\n",
    "            }\n",
    "    \n",
    "    # 3. Check referral sequences for patients (relevant for pathway analysis)\n",
    "    if 'referral' in data_dict and 'CompletedDate' in data_dict['referral'].columns:\n",
    "        ref_df = data_dict['referral']\n",
    "        # Group by patient and sort by date\n",
    "        patient_ref_counts = ref_df.groupby('Patient_ID')['CompletedDate'].count()\n",
    "        multiple_refs = (patient_ref_counts > 1).sum()\n",
    "        multiple_refs_pct = multiple_refs / len(patient_ref_counts)\n",
    "        \n",
    "        print(f\"Referral sequences: {multiple_refs_pct:.2%} ({multiple_refs:,}/{len(patient_ref_counts):,}) \" +\n",
    "              f\"patients have multiple referrals\")\n",
    "              \n",
    "        temporal_metrics['referral_sequence'] = {\n",
    "            'check': 'multiple_referrals',\n",
    "            'patients_with_multiple_refs': multiple_refs,\n",
    "            'percentage': multiple_refs_pct\n",
    "        }\n",
    "    \n",
    "    # 4. Visualize date distributions\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Collect date ranges for key tables\n",
    "    key_tables = ['encounter', 'lab', 'medication', 'referral']\n",
    "    date_ranges = []\n",
    "    \n",
    "    for table in key_tables:\n",
    "        if table not in temporal_metrics:\n",
    "            continue\n",
    "            \n",
    "        for col, metrics in temporal_metrics[table].items():\n",
    "            if 'min_date' in metrics and 'max_date' in metrics:\n",
    "                date_ranges.append({\n",
    "                    'table': table,\n",
    "                    'column': col,\n",
    "                    'min_date': metrics['min_date'],\n",
    "                    'max_date': metrics['max_date']\n",
    "                })\n",
    "    \n",
    "    # Create date range plot\n",
    "    if date_ranges:\n",
    "        df_ranges = pd.DataFrame(date_ranges)\n",
    "        df_ranges['label'] = df_ranges['table'] + '.' + df_ranges['column']\n",
    "        \n",
    "        # Sort by min_date\n",
    "        df_ranges = df_ranges.sort_values('min_date')\n",
    "        \n",
    "        # Plot\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        for i, row in df_ranges.iterrows():\n",
    "            plt.plot([row['min_date'], row['max_date']], [i, i], 'o-', linewidth=2, markersize=8)\n",
    "            plt.text(row['min_date'], i+0.1, row['min_date'].strftime('%Y-%m-%d'), fontsize=9)\n",
    "            plt.text(row['max_date'], i+0.1, row['max_date'].strftime('%Y-%m-%d'), fontsize=9)\n",
    "            \n",
    "        plt.yticks(range(len(df_ranges)), df_ranges['label'])\n",
    "        plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "        plt.title('Date Ranges by Table and Column')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(config.OUTPUT_PATH / 'date_ranges.png')\n",
    "        plt.close()\n",
    "    \n",
    "    return temporal_metrics\n",
    "\n",
    "def analyze_patient_population(data_dict):\n",
    "    \"\"\"\n",
    "    Analyze the patient population demographics and coverage.\n",
    "    \n",
    "    This function:\n",
    "    1. Analyzes core demographic distributions (age, sex)\n",
    "    2. Checks data coverage across key tables for patient cohort\n",
    "    3. Identifies potential inclusion/exclusion issues\n",
    "    \n",
    "    Understanding the patient population is essential for:\n",
    "    - Assessing potential selection bias (Haneuse & Daniels, 2016)\n",
    "    - Ensuring adequate representation across key strata (Deeny & Steventon, 2015)\n",
    "    - Establishing the generalizability of findings (Hersh et al., 2013)\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data_dict : dict\n",
    "        Dictionary of dataframes with table names as keys\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary of population metrics\n",
    "    \"\"\"\n",
    "    print_section_header(\"Patient Population Analysis\")\n",
    "    \n",
    "    population_metrics = {}\n",
    "    \n",
    "    # Exit if patient table is missing\n",
    "    if 'patient' not in data_dict:\n",
    "        print(\"ERROR: Patient table missing, cannot analyze population\")\n",
    "        return population_metrics\n",
    "        \n",
    "    patient_df = data_dict['patient']\n",
    "\n",
    "    if 'Sex' in patient_df.columns:\n",
    "        # Normalize sex values to standardized format\n",
    "        sex_mapping = {\n",
    "            'F': 'Female', 'FEMALE': 'Female', 'Female': 'Female', \n",
    "            'M': 'Male', 'MALE': 'Male', 'Male': 'Male',\n",
    "            'U': 'Unknown', 'Unknown': 'Unknown', \n",
    "            'Undifferentiated': 'Other'\n",
    "        }\n",
    "        \n",
    "        # Apply mapping (preserve original for reference)\n",
    "        patient_df['Sex_normalized'] = patient_df['Sex'].map(sex_mapping).fillna('Unknown')\n",
    "        \n",
    "        # Get normalized distribution\n",
    "        sex_counts = patient_df['Sex_normalized'].value_counts()\n",
    "        sex_pct = sex_counts / len(patient_df) * 100\n",
    "        \n",
    "        print(\"\\nNormalized sex distribution:\")\n",
    "        for sex, count in sex_counts.items():\n",
    "            print(f\"  {sex}: {count:,} ({sex_pct[sex]:.1f}%)\")\n",
    "            \n",
    "        # Store in metrics\n",
    "        population_metrics['sex_normalized'] = {\n",
    "            'counts': sex_counts.to_dict(),\n",
    "            'percentage': sex_pct.to_dict()\n",
    "        }\n",
    "        \n",
    "        # Create visualization with normalized values\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        ax = sns.barplot(x=sex_counts.index, y=sex_counts.values)\n",
    "        plt.title('Patient Sex Distribution (Normalized)', fontsize=14)\n",
    "        plt.xlabel('Sex', fontsize=12)\n",
    "        plt.ylabel('Number of Patients', fontsize=12)\n",
    "        \n",
    "        # Add count and percentage labels\n",
    "        for i, p in enumerate(ax.patches):\n",
    "            height = p.get_height()\n",
    "            percentage = sex_pct.iloc[i]\n",
    "            ax.text(p.get_x() + p.get_width()/2., height + height*0.02,\n",
    "                   f'{int(height):,}\\n({percentage:.1f}%)', \n",
    "                   ha=\"center\", va=\"bottom\", fontsize=9)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(config.OUTPUT_PATH / 'sex_distribution_normalized.png')\n",
    "        plt.close()\n",
    "        \n",
    "    \n",
    "    # 1. Basic demographic analysis\n",
    "    print_subsection_header(\"Demographic Distribution\")\n",
    "    \n",
    "    # Calculate age from birth year\n",
    "    if 'BirthYear' in patient_df.columns:\n",
    "        # Check if birth year is valid (not future, not unreasonably old)\n",
    "        current_year = config.CURRENT_YEAR\n",
    "        # Filter out clearly invalid birth years\n",
    "        invalid_birth_mask = (patient_df['BirthYear'] > current_year) | (patient_df['BirthYear'] < 1900)\n",
    "        if invalid_birth_mask.any():\n",
    "            print(f\"WARNING: Found {invalid_birth_mask.sum()} patients with invalid birth years. Setting to NaN.\")\n",
    "            patient_df.loc[invalid_birth_mask, 'BirthYear'] = np.nan\n",
    "        \n",
    "        # Check if DeceasedYear column exists in demographic data\n",
    "        has_deceased_info = ('patient_demographic' in data_dict and \n",
    "                            'DeceasedYear' in data_dict['patient_demographic'].columns)\n",
    "    \n",
    "        # Base age calculation using current year\n",
    "        patient_df['Age'] = current_year - patient_df['BirthYear']\n",
    "        \n",
    "        if has_deceased_info:\n",
    "            # Get only the necessary columns from demographic data to avoid duplicate columns in merge\n",
    "            demo_df = data_dict['patient_demographic'][['Patient_ID', 'DeceasedYear']].copy()\n",
    "            \n",
    "            # Remove duplicates if any exist in demographic data\n",
    "            if demo_df['Patient_ID'].duplicated().any():\n",
    "                print(f\"WARNING: Found {demo_df['Patient_ID'].duplicated().sum()} duplicate Patient_IDs in demographic data.\")\n",
    "                # Keep the first occurrence of each Patient_ID\n",
    "                demo_df = demo_df.drop_duplicates('Patient_ID')\n",
    "            \n",
    "            # Merge with demographic data to get deceased year\n",
    "            patient_df = patient_df.merge(demo_df, on='Patient_ID', how='left')\n",
    "            \n",
    "            # Validate DeceasedYear values\n",
    "            # - Must be not null\n",
    "            # - Must be a reasonable year (not future, not before birth year)\n",
    "            # - Must be after birth year\n",
    "            valid_deceased_mask = (\n",
    "                patient_df['DeceasedYear'].notna() & \n",
    "                (patient_df['DeceasedYear'] > 0) &\n",
    "                (patient_df['DeceasedYear'] <= current_year) &\n",
    "                (patient_df['DeceasedYear'] >= patient_df['BirthYear'])\n",
    "            )\n",
    "            \n",
    "            # Create reference year column (either death year or current year)\n",
    "            patient_df['reference_year'] = current_year  # Default to current year\n",
    "            \n",
    "            # Only update reference year for valid deceased records\n",
    "            if valid_deceased_mask.any():\n",
    "                patient_df.loc[valid_deceased_mask, 'reference_year'] = patient_df.loc[valid_deceased_mask, 'DeceasedYear']\n",
    "                \n",
    "                # Flag invalid deceased years\n",
    "                invalid_deceased = patient_df['DeceasedYear'].notna() & ~valid_deceased_mask\n",
    "                if invalid_deceased.any():\n",
    "                    print(f\"WARNING: Found {invalid_deceased.sum()} patients with invalid death years. \"\n",
    "                        f\"Using current year for age calculation instead.\")\n",
    "            \n",
    "            # Calculate corrected age using either death year or current year\n",
    "            patient_df['Age'] = patient_df['reference_year'] - patient_df['BirthYear']\n",
    "            \n",
    "            # Report on deceased patients\n",
    "            deceased_count = valid_deceased_mask.sum()\n",
    "            print(f\"Deceased patients with valid death year: {deceased_count:,} \"\n",
    "                f\"({deceased_count/len(patient_df)*100:.2f}%)\")\n",
    "        else:\n",
    "            # Standard age calculation based on current year\n",
    "            patient_df['Age'] = current_year - patient_df['BirthYear']\n",
    "        \n",
    "        # Cap implausible ages to avoid outliers affecting statistics\n",
    "        # Handle maximum age cap (e.g., 110 years)\n",
    "        max_age_cap = 110\n",
    "        too_old_mask = patient_df['Age'] > max_age_cap\n",
    "        if too_old_mask.any():\n",
    "            print(f\"WARNING: Found {too_old_mask.sum()} patients with ages > {max_age_cap}. Capping at {max_age_cap}.\")\n",
    "            patient_df.loc[too_old_mask, 'Age'] = max_age_cap\n",
    "        \n",
    "        # Handle negative ages (data error)\n",
    "        negative_age_mask = patient_df['Age'] < 0\n",
    "        if negative_age_mask.any():\n",
    "            print(f\"WARNING: Found {negative_age_mask.sum()} patients with negative ages. Setting to NaN.\")\n",
    "            patient_df.loc[negative_age_mask, 'Age'] = np.nan\n",
    "            \n",
    "        # Age statistics (ignoring NaN values)\n",
    "        age_mean = patient_df['Age'].mean()\n",
    "        age_median = patient_df['Age'].median()\n",
    "        age_min = patient_df['Age'].min()\n",
    "        age_max = patient_df['Age'].max()\n",
    "        \n",
    "        print(f\"Age statistics (as of {config.CURRENT_YEAR}):\")\n",
    "        print(f\"  Mean: {age_mean:.1f} years\")\n",
    "        print(f\"  Median: {age_median:.1f} years\")\n",
    "        print(f\"  Range: {age_min} to {age_max} years\")\n",
    "        \n",
    "        # Age distribution with standard age groups\n",
    "        # Option 1: Standard age groups (pediatric, adult, senior divisions)\n",
    "        age_bins = [0, 18, 35, 50, 65, 80, max_age_cap]\n",
    "        age_labels = ['<18', '18-34', '35-49', '50-64', '65-79', '80+']\n",
    "        \n",
    "        # For easier customization, you could use one of these alternative binning schemes:\n",
    "        # Option 2: Decades for more granular view\n",
    "        # age_bins = [0, 10, 20, 30, 40, 50, 60, 70, 80, 90, max_age_cap]\n",
    "        # age_labels = ['0-9', '10-19', '20-29', '30-39', '40-49', '50-59', '60-69', '70-79', '80-89', '90+']\n",
    "        \n",
    "        # Option 3: More detailed pediatric and geriatric groups\n",
    "        # age_bins = [0, 2, 5, 12, 18, 35, 50, 65, 75, 85, max_age_cap]\n",
    "        # age_labels = ['0-1', '2-4', '5-11', '12-17', '18-34', '35-49', '50-64', '65-74', '75-84', '85+']\n",
    "        \n",
    "        # Create age groups, handling NaN values\n",
    "        patient_df['Age_Group'] = pd.cut(patient_df['Age'], bins=age_bins, labels=age_labels)\n",
    "        \n",
    "        # Calculate distribution, excluding NaN values\n",
    "        valid_age_mask = patient_df['Age_Group'].notna()\n",
    "        if (~valid_age_mask).any():\n",
    "            print(f\"WARNING: {(~valid_age_mask).sum()} patients have missing age data and are excluded from age distribution.\")\n",
    "        \n",
    "        # Calculate distribution based on valid ages only\n",
    "        age_dist = patient_df.loc[valid_age_mask, 'Age_Group'].value_counts().sort_index()\n",
    "        age_pct = age_dist / valid_age_mask.sum() * 100\n",
    "        \n",
    "        # Display age distribution\n",
    "        age_table = pd.DataFrame({\n",
    "            'Age Group': age_dist.index,\n",
    "            'Count': age_dist.values,\n",
    "            'Percentage': age_pct.values\n",
    "        })\n",
    "        \n",
    "        print(\"\\nAge distribution:\")\n",
    "        display(age_table)\n",
    "        \n",
    "        # Store in metrics\n",
    "        population_metrics['age'] = {\n",
    "            'mean': age_mean,\n",
    "            'median': age_median,\n",
    "            'min': age_min,\n",
    "            'max': age_max,\n",
    "            'distribution': age_dist.to_dict(),\n",
    "            'percentage': age_pct.to_dict(),\n",
    "            'excluded_count': (~valid_age_mask).sum() if (~valid_age_mask).any() else 0\n",
    "        }\n",
    "        \n",
    "        # Plot age distribution\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        ax = sns.barplot(x=age_dist.index, y=age_dist.values)\n",
    "        plt.title('Patient Age Distribution', fontsize=14)\n",
    "        plt.xlabel('Age Group', fontsize=12)\n",
    "        plt.ylabel('Number of Patients', fontsize=12)\n",
    "        \n",
    "        # Add count and percentage labels\n",
    "        for i, p in enumerate(ax.patches):\n",
    "            height = p.get_height()\n",
    "            percentage = age_pct.iloc[i]\n",
    "            ax.text(p.get_x() + p.get_width()/2., height + height*0.02,\n",
    "                f'{int(height):,}\\n({percentage:.1f}%)', \n",
    "                ha=\"center\", va=\"bottom\", fontsize=9)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(config.OUTPUT_PATH / 'age_distribution.png')\n",
    "        plt.close()\n",
    "\n",
    "        # Add a note if there were data quality issues\n",
    "        quality_issues = invalid_birth_mask.sum() + (\n",
    "            negative_age_mask.sum() if 'negative_age_mask' in locals() else 0\n",
    "        )\n",
    "        if quality_issues > 0:\n",
    "            print(f\"\\nNOTE: Found {quality_issues} patients with age data quality issues.\")\n",
    "            print(\"      See warnings above for details.\")\n",
    "            \n",
    "            # Add quality metrics\n",
    "            population_metrics['age']['data_quality_issues'] = {\n",
    "                'invalid_birth_year': invalid_birth_mask.sum(),\n",
    "                'negative_age': negative_age_mask.sum() if 'negative_age_mask' in locals() else 0,\n",
    "                'too_old': too_old_mask.sum() if 'too_old_mask' in locals() else 0\n",
    "            }\n",
    "    else:\n",
    "        print(\"WARNING: 'BirthYear' column not found, age calculations skipped\")\n",
    "    \n",
    "    # Sex distribution\n",
    "    if 'Sex' in patient_df.columns:\n",
    "        sex_counts = patient_df['Sex'].value_counts()\n",
    "        sex_pct = sex_counts / len(patient_df) * 100\n",
    "        \n",
    "        print(\"\\nSex distribution:\")\n",
    "        for sex, count in sex_counts.items():\n",
    "            print(f\"  {sex}: {count:,} ({sex_pct[sex]:.1f}%)\")\n",
    "            \n",
    "        # Store in metrics\n",
    "        population_metrics['sex'] = {\n",
    "            'counts': sex_counts.to_dict(),\n",
    "            'percentage': sex_pct.to_dict()\n",
    "        }\n",
    "        \n",
    "        # Plot sex distribution\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        ax = sns.barplot(x=sex_counts.index, y=sex_counts.values)\n",
    "        plt.title('Patient Sex Distribution', fontsize=14)\n",
    "        plt.xlabel('Sex', fontsize=12)\n",
    "        plt.ylabel('Number of Patients', fontsize=12)\n",
    "        \n",
    "        # Add count and percentage labels\n",
    "        for i, p in enumerate(ax.patches):\n",
    "            height = p.get_height()\n",
    "            percentage = sex_pct.iloc[i]\n",
    "            ax.text(p.get_x() + p.get_width()/2., height + height*0.02,\n",
    "                   f'{int(height):,}\\n({percentage:.1f}%)', \n",
    "                   ha=\"center\", va=\"bottom\", fontsize=9)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(config.OUTPUT_PATH / 'sex_distribution.png')\n",
    "        plt.close()\n",
    "    \n",
    "    # 2. Data coverage across tables\n",
    "    print_subsection_header(\"Patient Data Coverage\")\n",
    "    \n",
    "    # Get patient ID sets for each table\n",
    "    coverage = {}\n",
    "    all_patients = set(patient_df['Patient_ID'])\n",
    "    total_patients = len(all_patients)\n",
    "    \n",
    "    for table, df in data_dict.items():\n",
    "        if table == 'patient':\n",
    "            continue\n",
    "            \n",
    "        if 'Patient_ID' in df.columns:\n",
    "            table_patients = set(df['Patient_ID'].unique())\n",
    "            overlap = table_patients.intersection(all_patients)\n",
    "            \n",
    "            coverage_pct = len(overlap) / total_patients\n",
    "            coverage[table] = {\n",
    "                'patients': len(overlap),\n",
    "                'percentage': coverage_pct\n",
    "            }\n",
    "            \n",
    "            print(f\"{table}: {coverage_pct:.2%} ({len(overlap):,}/{total_patients:,} patients)\")\n",
    "    \n",
    "    # Create intersection visualization\n",
    "    if coverage:\n",
    "        # Sort tables by coverage\n",
    "        sorted_tables = sorted(coverage.keys(), key=lambda x: coverage[x]['percentage'], reverse=True)\n",
    "        \n",
    "        # Create bar chart of coverage\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        coverage_vals = [coverage[t]['percentage'] for t in sorted_tables]\n",
    "        bars = plt.barh(sorted_tables, coverage_vals)\n",
    "        \n",
    "        # Add percentage labels\n",
    "        for i, bar in enumerate(bars):\n",
    "            width = bar.get_width()\n",
    "            label = f\"{width:.1%}\"\n",
    "            plt.text(max(0.05, width - 0.1), bar.get_y() + bar.get_height()/2, \n",
    "                    label, ha='center', va='center', color='white', fontweight='bold')\n",
    "        \n",
    "        plt.xlabel('Percentage of Patients with Data')\n",
    "        plt.title('Patient Coverage by Data Table')\n",
    "        plt.xlim(0, 1.0)\n",
    "        plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(config.OUTPUT_PATH / 'patient_coverage.png')\n",
    "        plt.close()\n",
    "    \n",
    "    # Store in metrics\n",
    "    population_metrics['coverage'] = coverage\n",
    "    \n",
    "    # 3. Eligibility analysis based on protocol criteria\n",
    "    print_subsection_header(\"Study Eligibility Analysis\")\n",
    "    \n",
    "    # Age eligibility (adults ≥18)\n",
    "    if 'Age' in patient_df.columns:\n",
    "        age_eligible = patient_df['Age'] >= config.MIN_AGE\n",
    "        age_eligible_count = age_eligible.sum()\n",
    "        age_eligible_pct = age_eligible_count / len(patient_df)\n",
    "        \n",
    "        print(f\"Age eligible (≥{config.MIN_AGE}): {age_eligible_pct:.2%} ({age_eligible_count:,}/{len(patient_df):,} patients)\")\n",
    "    \n",
    "    # Encounter eligibility (≥2 encounters)\n",
    "    if 'encounter' in data_dict and 'Patient_ID' in data_dict['encounter'].columns:\n",
    "        encounter_counts = data_dict['encounter']['Patient_ID'].value_counts()\n",
    "        encounter_eligible = encounter_counts[encounter_counts >= config.MIN_ENCOUNTERS]\n",
    "        encounter_eligible_count = len(encounter_eligible)\n",
    "        encounter_eligible_pct = encounter_eligible_count / len(patient_df)\n",
    "        \n",
    "        print(f\"Encounter eligible (≥{config.MIN_ENCOUNTERS} encounters): \" +\n",
    "              f\"{encounter_eligible_pct:.2%} ({encounter_eligible_count:,}/{len(patient_df):,} patients)\")\n",
    "        \n",
    "        # Encounter statistics\n",
    "        enc_mean = encounter_counts.mean()\n",
    "        enc_median = encounter_counts.median()\n",
    "        enc_p90 = encounter_counts.quantile(0.9)\n",
    "        \n",
    "        print(f\"Encounter statistics:\")\n",
    "        print(f\"  Mean: {enc_mean:.1f} encounters per patient\")\n",
    "        print(f\"  Median: {enc_median:.0f} encounters per patient\")\n",
    "        print(f\"  90th percentile: {enc_p90:.0f} encounters per patient\")\n",
    "        \n",
    "        # Store in metrics\n",
    "        population_metrics['encounters'] = {\n",
    "            'mean': enc_mean,\n",
    "            'median': enc_median,\n",
    "            'p90': enc_p90,\n",
    "            'eligible_count': encounter_eligible_count,\n",
    "            'eligible_percentage': encounter_eligible_pct\n",
    "        }\n",
    "        \n",
    "        # Create histogram of encounter counts\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        # Log transform for better visualization\n",
    "        log_counts = np.log10(encounter_counts + 1)  # +1 to handle zeros\n",
    "        plt.hist(log_counts, bins=50)\n",
    "        plt.title('Distribution of Encounters per Patient (Log Scale)', fontsize=14)\n",
    "        plt.xlabel('log10(Encounters + 1)', fontsize=12)\n",
    "        plt.ylabel('Number of Patients', fontsize=12)\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(config.OUTPUT_PATH / 'encounter_distribution.png')\n",
    "        plt.close()\n",
    "    \n",
    "    # 4. Combined eligibility criteria\n",
    "    if 'Age' in patient_df.columns and 'encounter' in data_dict:\n",
    "        # Get patient IDs with sufficient encounters\n",
    "        encounter_counts = data_dict['encounter']['Patient_ID'].value_counts()\n",
    "        encounter_eligible_ids = set(encounter_counts[encounter_counts >= config.MIN_ENCOUNTERS].index)\n",
    "        \n",
    "        # Combine with age eligibility\n",
    "        age_eligible_ids = set(patient_df.loc[patient_df['Age'] >= config.MIN_AGE, 'Patient_ID'])\n",
    "        \n",
    "        # Intersection\n",
    "        eligible_ids = age_eligible_ids.intersection(encounter_eligible_ids)\n",
    "        eligible_count = len(eligible_ids)\n",
    "        eligible_pct = eligible_count / len(patient_df)\n",
    "        \n",
    "        print(f\"\\nCombined eligibility (age ≥{config.MIN_AGE} AND ≥{config.MIN_ENCOUNTERS} encounters): \" +\n",
    "              f\"{eligible_pct:.2%} ({eligible_count:,}/{len(patient_df):,} patients)\")\n",
    "              \n",
    "        # Store in metrics\n",
    "        population_metrics['combined_eligibility'] = {\n",
    "            'eligible_count': eligible_count,\n",
    "            'eligible_percentage': eligible_pct,\n",
    "            'age_criteria': f\"≥{config.MIN_AGE}\",\n",
    "            'encounter_criteria': f\"≥{config.MIN_ENCOUNTERS}\"\n",
    "        }\n",
    "    \n",
    "    return population_metrics\n",
    "\n",
    "\n",
    "# --------------------------- Data Validation Functions -------------------------- #\n",
    "\n",
    "def validate_data_relationships(data_dict):\n",
    "    \"\"\"\n",
    "    Validate foreign key relationships between datasets to ensure referential integrity.\n",
    "    \n",
    "    This function checks how well foreign keys in dependent tables (e.g., encounters, labs)\n",
    "    match primary keys in reference tables (e.g., patients). High integrity is crucial for\n",
    "    reliable analysis, as broken references can lead to data loss during joins.\n",
    "    \n",
    "    The function implements recommendations from:\n",
    "    - Kahn et al. (2016) \"A Harmonized Data Quality Assessment Terminology and Framework...\"\n",
    "    - Weiskopf & Weng (2013) \"Methods and dimensions of electronic health record data quality...\"\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data_dict : dict\n",
    "        Dictionary of dataframes with table names as keys\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary of relationship metrics between tables\n",
    "    \"\"\"\n",
    "    print_section_header(\"Data Relationship Validation\")\n",
    "    \n",
    "    relationships = {}\n",
    "    \n",
    "    # Define key relationships to check\n",
    "    key_relationships = [\n",
    "        # dependent_table, reference_table, foreign_key, primary_key\n",
    "        ('encounter', 'patient', 'Patient_ID', 'Patient_ID'),\n",
    "        ('encounter_diagnosis', 'encounter', 'Encounter_ID', 'Encounter_ID'),\n",
    "        ('encounter_diagnosis', 'patient', 'Patient_ID', 'Patient_ID'),\n",
    "        ('lab', 'patient', 'Patient_ID', 'Patient_ID'),\n",
    "        ('lab', 'encounter', 'Encounter_ID', 'Encounter_ID'),\n",
    "        ('medication', 'patient', 'Patient_ID', 'Patient_ID'),\n",
    "        ('referral', 'patient', 'Patient_ID', 'Patient_ID'),\n",
    "        ('health_condition', 'patient', 'Patient_ID', 'Patient_ID')\n",
    "    ]\n",
    "    \n",
    "    for dep_table, ref_table, fk, pk in key_relationships:\n",
    "        # Skip if either table is missing\n",
    "        if dep_table not in data_dict or ref_table not in data_dict:\n",
    "            print(f\"Skipping relationship check: {dep_table}.{fk} -> {ref_table}.{pk} (table missing)\")\n",
    "            continue\n",
    "            \n",
    "        # Skip if columns don't exist\n",
    "        if fk not in data_dict[dep_table].columns or pk not in data_dict[ref_table].columns:\n",
    "            print(f\"Skipping relationship check: {dep_table}.{fk} -> {ref_table}.{pk} (column missing)\")\n",
    "            continue\n",
    "            \n",
    "        # Get unique keys from both tables\n",
    "        dep_keys = set(data_dict[dep_table][fk].dropna().unique())\n",
    "        ref_keys = set(data_dict[ref_table][pk].dropna().unique())\n",
    "        \n",
    "        # Calculate metrics\n",
    "        matching_keys = dep_keys.intersection(ref_keys)\n",
    "        orphaned_keys = dep_keys - ref_keys\n",
    "        \n",
    "        # As percentages\n",
    "        total_dep_keys = len(dep_keys)\n",
    "        match_pct = len(matching_keys) / total_dep_keys if total_dep_keys > 0 else 0\n",
    "        orphan_pct = len(orphaned_keys) / total_dep_keys if total_dep_keys > 0 else 0\n",
    "        \n",
    "        # Store metrics\n",
    "        rel_key = f\"{dep_table}.{fk} -> {ref_table}.{pk}\"\n",
    "        relationships[rel_key] = {\n",
    "            'dependent_table': dep_table,\n",
    "            'reference_table': ref_table,\n",
    "            'foreign_key': fk,\n",
    "            'primary_key': pk,\n",
    "            'total_unique_keys': total_dep_keys,\n",
    "            'matching_keys': len(matching_keys),\n",
    "            'orphaned_keys': len(orphaned_keys),\n",
    "            'match_percentage': match_pct,\n",
    "            'orphan_percentage': orphan_pct\n",
    "        }\n",
    "        \n",
    "        # Print summary\n",
    "        print(f\"Relationship: {rel_key}\")\n",
    "        print(f\"  Match rate: {match_pct:.2%} ({len(matching_keys):,}/{total_dep_keys:,} keys)\")\n",
    "        if orphan_pct > 0:\n",
    "            print(f\"  Orphaned records: {orphan_pct:.2%} ({len(orphaned_keys):,} keys)\")\n",
    "            # Show sample of orphaned keys (useful for debugging)\n",
    "            if len(orphaned_keys) <= 5:\n",
    "                print(f\"  Sample orphaned keys: {list(orphaned_keys)}\")\n",
    "            else:\n",
    "                print(f\"  Sample orphaned keys: {list(orphaned_keys)[:5]} ...\")\n",
    "        print()\n",
    "        \n",
    "    # Create summary table for visualization\n",
    "    if relationships:\n",
    "        rel_df = pd.DataFrame([\n",
    "            {\n",
    "                'Relationship': k,\n",
    "                'Match Rate': v['match_percentage'],\n",
    "                'Orphaned Rate': v['orphan_percentage'],\n",
    "                'Total Keys': v['total_unique_keys']\n",
    "            }\n",
    "            for k, v in relationships.items()\n",
    "        ])\n",
    "        \n",
    "        # Sort by match rate\n",
    "        rel_df = rel_df.sort_values('Match Rate')\n",
    "        \n",
    "        # Plot relationship metrics\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        bars = plt.barh(rel_df['Relationship'], rel_df['Match Rate'])\n",
    "        \n",
    "        # Add percentage labels\n",
    "        for i, bar in enumerate(bars):\n",
    "            width = bar.get_width()\n",
    "            label = f\"{width:.1%}\"\n",
    "            plt.text(max(0.05, width - 0.1), bar.get_y() + bar.get_height()/2, \n",
    "                    label, ha='center', va='center', color='white', fontweight='bold')\n",
    "        \n",
    "        plt.xlabel('Match Rate (% of dependent keys found in reference table)')\n",
    "        plt.title('Data Relationship Integrity')\n",
    "        plt.xlim(0, 1.0)\n",
    "        plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(config.OUTPUT_PATH / 'relationship_integrity.png')\n",
    "        plt.close()\n",
    "        \n",
    "    return relationships\n",
    "\n",
    "def validate_temporal_consistency(data_dict):\n",
    "    \"\"\"\n",
    "    Validate temporal consistency in date columns across datasets.\n",
    "    \n",
    "    This function checks for:\n",
    "    1. Chronological consistency (e.g., start dates before end dates)\n",
    "    2. Date ranges within reasonable study period\n",
    "    3. Temporal alignment between related events\n",
    "    \n",
    "    Temporal consistency is essential for accurate pathway analysis, especially for\n",
    "    establishing the correct sequence of NYD status, lab tests, referrals, and diagnoses.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data_dict : dict\n",
    "        Dictionary of dataframes with table names as keys\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary of temporal consistency metrics\n",
    "    \"\"\"\n",
    "    print_section_header(\"Temporal Consistency Validation\")\n",
    "    \n",
    "    temporal_metrics = {}\n",
    "    \n",
    "    # 1. Check date ranges in each table\n",
    "    print_subsection_header(\"Date ranges by table\")\n",
    "    \n",
    "    for table_name, df in data_dict.items():\n",
    "        date_cols = [col for col in df.columns if pd.api.types.is_datetime64_dtype(df[col])]\n",
    "        if not date_cols:\n",
    "            continue\n",
    "            \n",
    "        table_metrics = {}\n",
    "        print(f\"Table: {table_name}\")\n",
    "        \n",
    "        for col in date_cols:\n",
    "            # Skip if all null\n",
    "            if df[col].isna().all():\n",
    "                continue\n",
    "                \n",
    "            min_date = df[col].min()\n",
    "            max_date = df[col].max()\n",
    "            null_count = df[col].isna().sum()\n",
    "            null_pct = null_count / len(df)\n",
    "            \n",
    "            # Check for future dates (beyond current study year)\n",
    "            future_date_threshold = pd.Timestamp(f\"{config.CURRENT_YEAR+1}-01-01\")\n",
    "            future_dates = df[col] >= future_date_threshold\n",
    "            future_count = future_dates.sum()\n",
    "            future_pct = future_count / df[col].notna().sum() if df[col].notna().any() else 0\n",
    "            \n",
    "            # Check for implausible past dates (before 1900)\n",
    "            past_date_threshold = pd.Timestamp(\"1900-01-01\")\n",
    "            past_dates = df[col] < past_date_threshold\n",
    "            past_count = past_dates.sum()\n",
    "            past_pct = past_count / df[col].notna().sum() if df[col].notna().any() else 0\n",
    "            \n",
    "            print(f\"  {col}: {min_date} to {max_date} (Null: {null_pct:.2%})\")\n",
    "            if future_pct > 0:\n",
    "                print(f\"    WARNING: {future_pct:.2%} ({future_count:,}) future dates beyond {config.CURRENT_YEAR}\")\n",
    "            if past_pct > 0:\n",
    "                print(f\"    WARNING: {past_pct:.2%} ({past_count:,}) implausibly old dates before 1900\")\n",
    "                \n",
    "            table_metrics[col] = {\n",
    "                'min_date': min_date,\n",
    "                'max_date': max_date,\n",
    "                'null_percentage': null_pct,\n",
    "                'future_date_percentage': future_pct,\n",
    "                'past_date_percentage': past_pct\n",
    "            }\n",
    "            \n",
    "        temporal_metrics[table_name] = table_metrics\n",
    "        \n",
    "    # 2. Check for specific date sequence consistency\n",
    "    print_subsection_header(\"Date sequence validation\")\n",
    "    \n",
    "    # Medication: StartDate before StopDate\n",
    "    if 'medication' in data_dict and 'StartDate' in data_dict['medication'].columns and 'StopDate' in data_dict['medication'].columns:\n",
    "        med_df = data_dict['medication']\n",
    "        # Only check rows with both dates non-null\n",
    "        both_dates = med_df['StartDate'].notna() & med_df['StopDate'].notna()\n",
    "        total_both_dates = both_dates.sum()\n",
    "        \n",
    "        if total_both_dates > 0:\n",
    "            invalid_sequence = (med_df['StartDate'] > med_df['StopDate']) & both_dates\n",
    "            invalid_count = invalid_sequence.sum()\n",
    "            invalid_pct = invalid_count / total_both_dates\n",
    "            \n",
    "            print(f\"Medication - StartDate before StopDate: {(1-invalid_pct):.2%} valid\")\n",
    "            if invalid_pct > 0:\n",
    "                print(f\"  WARNING: {invalid_pct:.2%} ({invalid_count:,}/{total_both_dates:,}) \" +\n",
    "                      f\"medication records have StartDate after StopDate\")\n",
    "                \n",
    "            temporal_metrics['medication_sequence'] = {\n",
    "                'check': 'StartDate_before_StopDate',\n",
    "                'valid_percentage': 1 - invalid_pct,\n",
    "                'invalid_count': invalid_count,\n",
    "                'total_checked': total_both_dates\n",
    "            }\n",
    "    \n",
    "    # 3. Check referral sequences for patients (relevant for pathway analysis)\n",
    "    if 'referral' in data_dict and 'CompletedDate' in data_dict['referral'].columns:\n",
    "        ref_df = data_dict['referral']\n",
    "        # Group by patient and sort by date\n",
    "        patient_ref_counts = ref_df.groupby('Patient_ID')['CompletedDate'].count()\n",
    "        multiple_refs = (patient_ref_counts > 1).sum()\n",
    "        multiple_refs_pct = multiple_refs / len(patient_ref_counts)\n",
    "        \n",
    "        print(f\"Referral sequences: {multiple_refs_pct:.2%} ({multiple_refs:,}/{len(patient_ref_counts):,}) \" +\n",
    "              f\"patients have multiple referrals\")\n",
    "              \n",
    "        temporal_metrics['referral_sequence'] = {\n",
    "            'check': 'multiple_referrals',\n",
    "            'patients_with_multiple_refs': multiple_refs,\n",
    "            'percentage': multiple_refs_pct\n",
    "        }\n",
    "    \n",
    "    # 4. Visualize date distributions\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Collect date ranges for key tables\n",
    "    key_tables = ['encounter', 'lab', 'medication', 'referral']\n",
    "    date_ranges = []\n",
    "    \n",
    "    for table in key_tables:\n",
    "        if table not in temporal_metrics:\n",
    "            continue\n",
    "            \n",
    "        for col, metrics in temporal_metrics[table].items():\n",
    "            if 'min_date' in metrics and 'max_date' in metrics:\n",
    "                date_ranges.append({\n",
    "                    'table': table,\n",
    "                    'column': col,\n",
    "                    'min_date': metrics['min_date'],\n",
    "                    'max_date': metrics['max_date']\n",
    "                })\n",
    "    \n",
    "    # Create date range plot\n",
    "    if date_ranges:\n",
    "        df_ranges = pd.DataFrame(date_ranges)\n",
    "        df_ranges['label'] = df_ranges['table'] + '.' + df_ranges['column']\n",
    "        \n",
    "        # Sort by min_date\n",
    "        df_ranges = df_ranges.sort_values('min_date')\n",
    "        \n",
    "        # Plot\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        for i, row in df_ranges.iterrows():\n",
    "            plt.plot([row['min_date'], row['max_date']], [i, i], 'o-', linewidth=2, markersize=8)\n",
    "            plt.text(row['min_date'], i+0.1, row['min_date'].strftime('%Y-%m-%d'), fontsize=9)\n",
    "            plt.text(row['max_date'], i+0.1, row['max_date'].strftime('%Y-%m-%d'), fontsize=9)\n",
    "            \n",
    "        plt.yticks(range(len(df_ranges)), df_ranges['label'])\n",
    "        plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "        plt.title('Date Ranges by Table and Column')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(config.OUTPUT_PATH / 'date_ranges.png')\n",
    "        plt.close()\n",
    "    \n",
    "    return temporal_metrics\n",
    "\n",
    "def analyze_patient_population(data_dict):\n",
    "    \"\"\"\n",
    "    Analyze the patient population demographics and coverage.\n",
    "    \n",
    "    This function:\n",
    "    1. Analyzes core demographic distributions (age, sex)\n",
    "    2. Checks data coverage across key tables for patient cohort\n",
    "    3. Identifies potential inclusion/exclusion issues\n",
    "    \n",
    "    Understanding the patient population is essential for:\n",
    "    - Assessing potential selection bias (Haneuse & Daniels, 2016)\n",
    "    - Ensuring adequate representation across key strata (Deeny & Steventon, 2015)\n",
    "    - Establishing the generalizability of findings (Hersh et al., 2013)\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data_dict : dict\n",
    "        Dictionary of dataframes with table names as keys\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary of population metrics\n",
    "    \"\"\"\n",
    "    print_section_header(\"Patient Population Analysis\")\n",
    "    \n",
    "    population_metrics = {}\n",
    "    \n",
    "    # Exit if patient table is missing\n",
    "    if 'patient' not in data_dict:\n",
    "        print(\"ERROR: Patient table missing, cannot analyze population\")\n",
    "        return population_metrics\n",
    "        \n",
    "    patient_df = data_dict['patient']\n",
    "\n",
    "    if 'Sex' in patient_df.columns:\n",
    "        # Normalize sex values to standardized format\n",
    "        sex_mapping = {\n",
    "            'F': 'Female', 'FEMALE': 'Female', 'Female': 'Female', \n",
    "            'M': 'Male', 'MALE': 'Male', 'Male': 'Male',\n",
    "            'U': 'Unknown', 'Unknown': 'Unknown', \n",
    "            'Undifferentiated': 'Other'\n",
    "        }\n",
    "        \n",
    "        # Apply mapping (preserve original for reference)\n",
    "        patient_df['Sex_normalized'] = patient_df['Sex'].map(sex_mapping).fillna('Unknown')\n",
    "        \n",
    "        # Get normalized distribution\n",
    "        sex_counts = patient_df['Sex_normalized'].value_counts()\n",
    "        sex_pct = sex_counts / len(patient_df) * 100\n",
    "        \n",
    "        print(\"\\nNormalized sex distribution:\")\n",
    "        for sex, count in sex_counts.items():\n",
    "            print(f\"  {sex}: {count:,} ({sex_pct[sex]:.1f}%)\")\n",
    "            \n",
    "        # Store in metrics\n",
    "        population_metrics['sex_normalized'] = {\n",
    "            'counts': sex_counts.to_dict(),\n",
    "            'percentage': sex_pct.to_dict()\n",
    "        }\n",
    "        \n",
    "        # Create visualization with normalized values\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        ax = sns.barplot(x=sex_counts.index, y=sex_counts.values)\n",
    "        plt.title('Patient Sex Distribution (Normalized)', fontsize=14)\n",
    "        plt.xlabel('Sex', fontsize=12)\n",
    "        plt.ylabel('Number of Patients', fontsize=12)\n",
    "        \n",
    "        # Add count and percentage labels\n",
    "        for i, p in enumerate(ax.patches):\n",
    "            height = p.get_height()\n",
    "            percentage = sex_pct.iloc[i]\n",
    "            ax.text(p.get_x() + p.get_width()/2., height + height*0.02,\n",
    "                   f'{int(height):,}\\n({percentage:.1f}%)', \n",
    "                   ha=\"center\", va=\"bottom\", fontsize=9)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(config.OUTPUT_PATH / 'sex_distribution_normalized.png')\n",
    "        plt.close()\n",
    "        \n",
    "    \n",
    "    # 1. Basic demographic analysis\n",
    "    print_subsection_header(\"Demographic Distribution\")\n",
    "    \n",
    "    # Calculate age from birth year\n",
    "    if 'BirthYear' in patient_df.columns:\n",
    "        # Check if DeceasedYear column exists in demographic data\n",
    "        has_deceased_info = 'patient_demographic' in data_dict and 'DeceasedYear' in data_dict['patient_demographic'].columns\n",
    " \n",
    "        patient_df['Age'] = config.CURRENT_YEAR - patient_df['BirthYear']\n",
    "        if has_deceased_info:\n",
    "            # Merge with demographic data to get deceased year\n",
    "            demo_df = data_dict['patient_demographic'][['Patient_ID', 'DeceasedYear']]\n",
    "            patient_df = patient_df.merge(demo_df, on='Patient_ID', how='left')\n",
    "            \n",
    "            # Calculate age considering death year when available\n",
    "            patient_df['reference_year'] = config.CURRENT_YEAR  # Default to current year\n",
    "            deceased_mask = patient_df['DeceasedYear'].notna() & (patient_df['DeceasedYear'] > 0)\n",
    "            if deceased_mask.any():\n",
    "                patient_df.loc[deceased_mask, 'reference_year'] = patient_df.loc[deceased_mask, 'DeceasedYear']\n",
    "            \n",
    "            patient_df['Age'] = patient_df['reference_year'] - patient_df['BirthYear']\n",
    "            \n",
    "            # Report on deceased patients\n",
    "            deceased_count = deceased_mask.sum()\n",
    "            print(f\"Deceased patients with valid death year: {deceased_count:,} ({deceased_count/len(patient_df)*100:.2f}%)\")\n",
    "        else:\n",
    "            # Standard age calculation based on current year\n",
    "            patient_df['Age'] = config.CURRENT_YEAR - patient_df['BirthYear']\n",
    "            \n",
    "        # Age statistics\n",
    "        age_mean = patient_df['Age'].mean()\n",
    "        age_median = patient_df['Age'].median()\n",
    "        age_min = patient_df['Age'].min()\n",
    "        age_max = patient_df['Age'].max()\n",
    "        \n",
    "        print(f\"Age statistics (as of {config.CURRENT_YEAR}):\")\n",
    "        print(f\"  Mean: {age_mean:.1f} years\")\n",
    "        print(f\"  Median: {age_median:.1f} years\")\n",
    "        print(f\"  Range: {age_min} to {age_max} years\")\n",
    "        \n",
    "        # Age distribution\n",
    "        age_bins = [0, 18, 35, 50, 65, 80, 120]\n",
    "        age_labels = ['<18', '18-34', '35-49', '50-64', '65-79', '80+']\n",
    "        \n",
    "        patient_df['Age_Group'] = pd.cut(patient_df['Age'], bins=age_bins, labels=age_labels)\n",
    "        age_dist = patient_df['Age_Group'].value_counts().sort_index()\n",
    "        age_pct = age_dist / len(patient_df) * 100\n",
    "        \n",
    "        # Display age distribution\n",
    "        age_table = pd.DataFrame({\n",
    "            'Age Group': age_dist.index,\n",
    "            'Count': age_dist.values,\n",
    "            'Percentage': age_pct.values\n",
    "        })\n",
    "        \n",
    "        print(\"\\nAge distribution:\")\n",
    "        display(age_table)\n",
    "        \n",
    "        # Store in metrics\n",
    "        population_metrics['age'] = {\n",
    "            'mean': age_mean,\n",
    "            'median': age_median,\n",
    "            'min': age_min,\n",
    "            'max': age_max,\n",
    "            'distribution': age_dist.to_dict(),\n",
    "            'percentage': age_pct.to_dict()\n",
    "        }\n",
    "        \n",
    "        # Plot age distribution\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        ax = sns.barplot(x=age_dist.index, y=age_dist.values)\n",
    "        plt.title('Patient Age Distribution', fontsize=14)\n",
    "        plt.xlabel('Age Group', fontsize=12)\n",
    "        plt.ylabel('Number of Patients', fontsize=12)\n",
    "        \n",
    "        # Add count and percentage labels\n",
    "        for i, p in enumerate(ax.patches):\n",
    "            height = p.get_height()\n",
    "            percentage = age_pct.iloc[i]\n",
    "            ax.text(p.get_x() + p.get_width()/2., height + height*0.02,\n",
    "                   f'{int(height):,}\\n({percentage:.1f}%)', \n",
    "                   ha=\"center\", va=\"bottom\", fontsize=9)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(config.OUTPUT_PATH / 'age_distribution.png')\n",
    "        plt.close()\n",
    "    \n",
    "    # Sex distribution\n",
    "    if 'Sex' in patient_df.columns:\n",
    "        sex_counts = patient_df['Sex'].value_counts()\n",
    "        sex_pct = sex_counts / len(patient_df) * 100\n",
    "        \n",
    "        print(\"\\nSex distribution:\")\n",
    "        for sex, count in sex_counts.items():\n",
    "            print(f\"  {sex}: {count:,} ({sex_pct[sex]:.1f}%)\")\n",
    "            \n",
    "        # Store in metrics\n",
    "        population_metrics['sex'] = {\n",
    "            'counts': sex_counts.to_dict(),\n",
    "            'percentage': sex_pct.to_dict()\n",
    "        }\n",
    "        \n",
    "        # Plot sex distribution\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        ax = sns.barplot(x=sex_counts.index, y=sex_counts.values)\n",
    "        plt.title('Patient Sex Distribution', fontsize=14)\n",
    "        plt.xlabel('Sex', fontsize=12)\n",
    "        plt.ylabel('Number of Patients', fontsize=12)\n",
    "        \n",
    "        # Add count and percentage labels\n",
    "        for i, p in enumerate(ax.patches):\n",
    "            height = p.get_height()\n",
    "            percentage = sex_pct.iloc[i]\n",
    "            ax.text(p.get_x() + p.get_width()/2., height + height*0.02,\n",
    "                   f'{int(height):,}\\n({percentage:.1f}%)', \n",
    "                   ha=\"center\", va=\"bottom\", fontsize=9)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(config.OUTPUT_PATH / 'sex_distribution.png')\n",
    "        plt.close()\n",
    "    \n",
    "    # 2. Data coverage across tables\n",
    "    print_subsection_header(\"Patient Data Coverage\")\n",
    "    \n",
    "    # Get patient ID sets for each table\n",
    "    coverage = {}\n",
    "    all_patients = set(patient_df['Patient_ID'])\n",
    "    total_patients = len(all_patients)\n",
    "    \n",
    "    for table, df in data_dict.items():\n",
    "        if table == 'patient':\n",
    "            continue\n",
    "            \n",
    "        if 'Patient_ID' in df.columns:\n",
    "            table_patients = set(df['Patient_ID'].unique())\n",
    "            overlap = table_patients.intersection(all_patients)\n",
    "            \n",
    "            coverage_pct = len(overlap) / total_patients\n",
    "            coverage[table] = {\n",
    "                'patients': len(overlap),\n",
    "                'percentage': coverage_pct\n",
    "            }\n",
    "            \n",
    "            print(f\"{table}: {coverage_pct:.2%} ({len(overlap):,}/{total_patients:,} patients)\")\n",
    "    \n",
    "    # Create intersection visualization\n",
    "    if coverage:\n",
    "        # Sort tables by coverage\n",
    "        sorted_tables = sorted(coverage.keys(), key=lambda x: coverage[x]['percentage'], reverse=True)\n",
    "        \n",
    "        # Create bar chart of coverage\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        coverage_vals = [coverage[t]['percentage'] for t in sorted_tables]\n",
    "        bars = plt.barh(sorted_tables, coverage_vals)\n",
    "        \n",
    "        # Add percentage labels\n",
    "        for i, bar in enumerate(bars):\n",
    "            width = bar.get_width()\n",
    "            label = f\"{width:.1%}\"\n",
    "            plt.text(max(0.05, width - 0.1), bar.get_y() + bar.get_height()/2, \n",
    "                    label, ha='center', va='center', color='white', fontweight='bold')\n",
    "        \n",
    "        plt.xlabel('Percentage of Patients with Data')\n",
    "        plt.title('Patient Coverage by Data Table')\n",
    "        plt.xlim(0, 1.0)\n",
    "        plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(config.OUTPUT_PATH / 'patient_coverage.png')\n",
    "        plt.close()\n",
    "    \n",
    "    # Store in metrics\n",
    "    population_metrics['coverage'] = coverage\n",
    "    \n",
    "    # 3. Eligibility analysis based on protocol criteria\n",
    "    print_subsection_header(\"Study Eligibility Analysis\")\n",
    "    \n",
    "    # Age eligibility (adults ≥18)\n",
    "    if 'Age' in patient_df.columns:\n",
    "        age_eligible = patient_df['Age'] >= config.MIN_AGE\n",
    "        age_eligible_count = age_eligible.sum()\n",
    "        age_eligible_pct = age_eligible_count / len(patient_df)\n",
    "        \n",
    "        print(f\"Age eligible (≥{config.MIN_AGE}): {age_eligible_pct:.2%} ({age_eligible_count:,}/{len(patient_df):,} patients)\")\n",
    "    \n",
    "    # Encounter eligibility (≥2 encounters)\n",
    "    if 'encounter' in data_dict and 'Patient_ID' in data_dict['encounter'].columns:\n",
    "        encounter_counts = data_dict['encounter']['Patient_ID'].value_counts()\n",
    "        encounter_eligible = encounter_counts[encounter_counts >= config.MIN_ENCOUNTERS]\n",
    "        encounter_eligible_count = len(encounter_eligible)\n",
    "        encounter_eligible_pct = encounter_eligible_count / len(patient_df)\n",
    "        \n",
    "        print(f\"Encounter eligible (≥{config.MIN_ENCOUNTERS} encounters): \" +\n",
    "              f\"{encounter_eligible_pct:.2%} ({encounter_eligible_count:,}/{len(patient_df):,} patients)\")\n",
    "        \n",
    "        # Encounter statistics\n",
    "        enc_mean = encounter_counts.mean()\n",
    "        enc_median = encounter_counts.median()\n",
    "        enc_p90 = encounter_counts.quantile(0.9)\n",
    "        \n",
    "        print(f\"Encounter statistics:\")\n",
    "        print(f\"  Mean: {enc_mean:.1f} encounters per patient\")\n",
    "        print(f\"  Median: {enc_median:.0f} encounters per patient\")\n",
    "        print(f\"  90th percentile: {enc_p90:.0f} encounters per patient\")\n",
    "        \n",
    "        # Store in metrics\n",
    "        population_metrics['encounters'] = {\n",
    "            'mean': enc_mean,\n",
    "            'median': enc_median,\n",
    "            'p90': enc_p90,\n",
    "            'eligible_count': encounter_eligible_count,\n",
    "            'eligible_percentage': encounter_eligible_pct\n",
    "        }\n",
    "        \n",
    "        # Create histogram of encounter counts\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        # Log transform for better visualization\n",
    "        log_counts = np.log10(encounter_counts + 1)  # +1 to handle zeros\n",
    "        plt.hist(log_counts, bins=50)\n",
    "        plt.title('Distribution of Encounters per Patient (Log Scale)', fontsize=14)\n",
    "        plt.xlabel('log10(Encounters + 1)', fontsize=12)\n",
    "        plt.ylabel('Number of Patients', fontsize=12)\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(config.OUTPUT_PATH / 'encounter_distribution.png')\n",
    "        plt.close()\n",
    "    \n",
    "    # 4. Combined eligibility criteria\n",
    "    if 'Age' in patient_df.columns and 'encounter' in data_dict:\n",
    "        # Get patient IDs with sufficient encounters\n",
    "        encounter_counts = data_dict['encounter']['Patient_ID'].value_counts()\n",
    "        encounter_eligible_ids = set(encounter_counts[encounter_counts >= config.MIN_ENCOUNTERS].index)\n",
    "        \n",
    "        # Combine with age eligibility\n",
    "        age_eligible_ids = set(patient_df.loc[patient_df['Age'] >= config.MIN_AGE, 'Patient_ID'])\n",
    "        \n",
    "        # Intersection\n",
    "        eligible_ids = age_eligible_ids.intersection(encounter_eligible_ids)\n",
    "        eligible_count = len(eligible_ids)\n",
    "        eligible_pct = eligible_count / len(patient_df)\n",
    "        \n",
    "        print(f\"\\nCombined eligibility (age ≥{config.MIN_AGE} AND ≥{config.MIN_ENCOUNTERS} encounters): \" +\n",
    "              f\"{eligible_pct:.2%} ({eligible_count:,}/{len(patient_df):,} patients)\")\n",
    "              \n",
    "        # Store in metrics\n",
    "        population_metrics['combined_eligibility'] = {\n",
    "            'eligible_count': eligible_count,\n",
    "            'eligible_percentage': eligible_pct,\n",
    "            'age_criteria': f\"≥{config.MIN_AGE}\",\n",
    "            'encounter_criteria': f\"≥{config.MIN_ENCOUNTERS}\"\n",
    "        }\n",
    "    \n",
    "    return population_metrics\n",
    "\n",
    "def link_labs_to_encounters_by_time(lab_df, encounter_df, window_days=14):\n",
    "    \"\"\"Link lab records to encounters based on temporal proximity.\"\"\"\n",
    "    print(\"Implementing time-based lab-encounter linkage...\")\n",
    "    \n",
    "    # Only process labs with missing Encounter_ID but valid dates\n",
    "    labs_to_link = lab_df[\n",
    "        (lab_df['Encounter_ID'].isna()) & \n",
    "        (lab_df['PerformedDate'].notna())\n",
    "    ].copy()\n",
    "    \n",
    "    if len(labs_to_link) == 0:\n",
    "        return lab_df\n",
    "    \n",
    "    print(f\"Attempting to link {len(labs_to_link):,} labs to encounters\")\n",
    "    \n",
    "    # Create columns for linkage data\n",
    "    result = lab_df.copy()\n",
    "    result['Linked_Encounter_ID'] = None\n",
    "    result['Days_To_Encounter'] = None\n",
    "    result['Linkage_Confidence'] = None\n",
    "    \n",
    "    # Process in chunks for efficiency\n",
    "    chunk_size = 10000\n",
    "    chunks = [labs_to_link.iloc[i:i+chunk_size] for i in range(0, len(labs_to_link), chunk_size)]\n",
    "    \n",
    "    linked_count = 0\n",
    "    for chunk_idx, chunk in enumerate(chunks):\n",
    "        print(f\"Processing chunk {chunk_idx+1}/{len(chunks)}...\")\n",
    "        \n",
    "        for lab_idx, lab in chunk.iterrows():\n",
    "            # Get all encounters for this patient\n",
    "            patient_encounters = encounter_df[\n",
    "                (encounter_df['Patient_ID'] == lab['Patient_ID']) &\n",
    "                (encounter_df['EncounterDate'].notna())\n",
    "            ]\n",
    "            \n",
    "            if len(patient_encounters) == 0:\n",
    "                continue\n",
    "                \n",
    "            # Calculate time differences\n",
    "            patient_encounters['days_diff'] = abs(\n",
    "                (patient_encounters['EncounterDate'] - lab['PerformedDate']).dt.days\n",
    "            )\n",
    "            \n",
    "            # Find best match within window\n",
    "            valid_matches = patient_encounters[patient_encounters['days_diff'] <= window_days]\n",
    "            \n",
    "            if len(valid_matches) == 0:\n",
    "                continue\n",
    "                \n",
    "            # Sort by days_diff to get closest encounter\n",
    "            valid_matches = valid_matches.sort_values('days_diff')\n",
    "            best_match = valid_matches.iloc[0]\n",
    "            \n",
    "            # Calculate confidence score (1.0 = same day, decreases with distance)\n",
    "            confidence = 1.0 - (best_match['days_diff'] / (window_days * 2))\n",
    "            \n",
    "            # Store the linkage data\n",
    "            result.loc[lab_idx, 'Linked_Encounter_ID'] = best_match['Encounter_ID']\n",
    "            result.loc[lab_idx, 'Days_To_Encounter'] = best_match['days_diff']\n",
    "            result.loc[lab_idx, 'Linkage_Confidence'] = confidence\n",
    "            \n",
    "            linked_count += 1\n",
    "    \n",
    "    # Create effective ID column for downstream analysis\n",
    "    result['Effective_Encounter_ID'] = result['Encounter_ID']\n",
    "    mask = result['Effective_Encounter_ID'].isna() & result['Linked_Encounter_ID'].notna()\n",
    "    result.loc[mask, 'Effective_Encounter_ID'] = result.loc[mask, 'Linked_Encounter_ID']\n",
    "    \n",
    "    print(f\"Successfully linked {linked_count:,} labs to encounters by temporal proximity\")\n",
    "    print(f\"Average confidence score: {result['Linkage_Confidence'].mean():.2f}\")\n",
    "    print(f\"Total labs with encounter association: {result['Effective_Encounter_ID'].notna().sum():,} \"\n",
    "          f\"({result['Effective_Encounter_ID'].notna().sum()/len(result)*100:.2f}%)\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def analyze_coding_patterns(data_dict):\n",
    "    \"\"\"\n",
    "    Analyze diagnostic coding patterns relevant for SSD identification.\n",
    "    \n",
    "    This function examines:\n",
    "    1. Distribution of ICD-9/ICD-10 codes\n",
    "    2. Frequency of key diagnostic codes\n",
    "    3. Preliminary identification of potential NYD codes\n",
    "    \n",
    "    Understanding coding patterns is critical for:\n",
    "    - Proper identification of NYD status (Vital & Health Statistics, 1987)\n",
    "    - Accurate detection of SSD criteria based on diagnostic codes\n",
    "    - Assessment of coding variability across providers\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data_dict : dict\n",
    "        Dictionary of dataframes with table names as keys\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary of coding pattern metrics\n",
    "    \"\"\"\n",
    "    print_section_header(\"Diagnostic Coding Pattern Analysis\")\n",
    "    \n",
    "    coding_metrics = {}\n",
    "    \n",
    "    # Skip if encounter_diagnosis or health_condition tables are missing\n",
    "    if 'encounter_diagnosis' not in data_dict or 'health_condition' not in data_dict:\n",
    "        print(\"WARNING: Missing diagnosis tables, skipping coding analysis\")\n",
    "        return coding_metrics\n",
    "    \n",
    "    # 1. Analyze ICD code types and patterns in encounter diagnoses\n",
    "    print_subsection_header(\"Encounter Diagnosis Coding Patterns\")\n",
    "    \n",
    "    ed_df = data_dict['encounter_diagnosis']\n",
    "    \n",
    "    # Check code type distribution\n",
    "    if 'DiagnosisCodeType_calc' in ed_df.columns:\n",
    "        code_types = ed_df['DiagnosisCodeType_calc'].value_counts()\n",
    "        code_pct = code_types / len(ed_df) * 100\n",
    "        \n",
    "        print(\"Diagnosis code types:\")\n",
    "        for code_type, count in code_types.items():\n",
    "            print(f\"  {code_type}: {count:,} ({code_pct[code_type]:.1f}%)\")\n",
    "            \n",
    "        # Store in metrics\n",
    "        coding_metrics['code_types'] = {\n",
    "            'counts': code_types.to_dict(),\n",
    "            'percentage': code_pct.to_dict()\n",
    "        }\n",
    "    \n",
    "    # 2. Check for known NYD (Not Yet Diagnosed) patterns\n",
    "    if 'DiagnosisCode_calc' in ed_df.columns:\n",
    "        print_subsection_header(\"Preliminary NYD Code Analysis\")\n",
    "        \n",
    "        # Define NYD code patterns based on research\n",
    "        # nyd_patterns = [\n",
    "        #     r'^799\\.9',    # Other unknown and unspecified cause\n",
    "        #     r'^V71\\.',     # Observation without finding - all V71 subcodes\n",
    "        #     r'^R69',       # Illness, unspecified (ICD-10)\n",
    "        #     r'^Z03\\.',     # Medical observation (ICD-10)\n",
    "        # ]\n",
    "        nyd_patterns = [\n",
    "            r'799',       # General symptoms (includes 799.9, which is \"Other unknown cause\")\n",
    "            r'^V71',      # Observation without finding (without requiring the dot)\n",
    "            r'^R69',      # Illness, unspecified (ICD-10)\n",
    "            r'^Z03',      # Medical observation (ICD-10, without requiring the dot)\n",
    "            r'^780\\.9',   # Other general symptoms (including \"unspecified\")\n",
    "            r'^V65\\.5'    # Person with feared condition where no diagnosis was made\n",
    "        ]\n",
    "        \n",
    "        # Check for each pattern\n",
    "        nyd_counts = {}\n",
    "        for pattern in nyd_patterns:\n",
    "            matches = ed_df['DiagnosisCode_calc'].astype(str).str.contains(pattern, na=False)\n",
    "            count = matches.sum()\n",
    "            patient_count = ed_df.loc[matches, 'Patient_ID'].nunique()\n",
    "            \n",
    "            nyd_counts[pattern] = {\n",
    "                'code_count': count,\n",
    "                'patient_count': patient_count,\n",
    "                'percentage': count / len(ed_df) * 100 if len(ed_df) > 0 else 0\n",
    "            }\n",
    "            \n",
    "            print(f\"NYD pattern '{pattern}': {count:,} codes ({nyd_counts[pattern]['percentage']:.2f}%) \" +\n",
    "                  f\"in {patient_count:,} patients\")\n",
    "        \n",
    "        # Store in metrics\n",
    "        coding_metrics['nyd_patterns'] = nyd_counts\n",
    "        \n",
    "        # Count most common code roots (first 3 characters)\n",
    "        ed_df['code_root'] = ed_df['DiagnosisCode_calc'].astype(str).str.extract(r'([A-Za-z0-9]{1,3})')\n",
    "        root_counts = ed_df['code_root'].value_counts().head(20)\n",
    "        \n",
    "        print(\"\\nMost common diagnostic code roots (first 3 characters):\")\n",
    "        for root, count in root_counts.items():\n",
    "            print(f\"  {root}: {count:,} ({count/len(ed_df)*100:.2f}%)\")\n",
    "        \n",
    "        # Store in metrics\n",
    "        coding_metrics['common_roots'] = root_counts.to_dict()\n",
    "    \n",
    "    \n",
    "    print(\"\\nChecking for potential NYD indicators in diagnostic code content...\")\n",
    "    # Look for 799 codes specifically (which includes 799.9 - Other unknown causes)\n",
    "    code_799 = ed_df['DiagnosisCode_calc'].astype(str).str.contains('^799', regex=True, na=False)\n",
    "    code_799_count = code_799.sum() \n",
    "    code_799_patient_count = ed_df.loc[code_799, 'Patient_ID'].nunique()\n",
    "\n",
    "    print(f\"Code 799 (symptoms/signs): {code_799_count:,} codes ({code_799_count/len(ed_df)*100:.2f}%) in {code_799_patient_count:,} patients\")\n",
    "\n",
    "    # Look for V71 (observation without diagnosis)\n",
    "    code_v71 = ed_df['DiagnosisCode_calc'].astype(str).str.contains('^V71', regex=True, na=False)\n",
    "    code_v71_count = code_v71.sum()\n",
    "    code_v71_patient_count = ed_df.loc[code_v71, 'Patient_ID'].nunique()\n",
    "\n",
    "    print(f\"Code V71 (observation without diagnosis): {code_v71_count:,} codes ({code_v71_count/len(ed_df)*100:.2f}%) in {code_v71_patient_count:,} patients\")\n",
    "    \n",
    "\n",
    "    # 3. Check for text patterns indicating NYD\n",
    "    if 'DiagnosisText_calc' in ed_df.columns:\n",
    "        # Define NYD text patterns\n",
    "        nyd_text_patterns = [\n",
    "            r'\\bNYD\\b', \n",
    "            r'\\bnot yet diagnosed\\b', \n",
    "            r'\\bdiagnosis deferred\\b',\n",
    "            r'\\bunknown etiology\\b', \n",
    "            r'\\brule out\\b', \n",
    "            r'\\bunexplained\\b',\n",
    "            r'\\bundiagnosed\\b',\n",
    "            r'\\bundetermined\\b',\n",
    "            r'\\bsymptoms\\b',\n",
    "            r'\\bsymptom\\b NOT OTHERWISE SPECIFIED',\n",
    "            r'without definitive diagnosis',\n",
    "            r'no clear',\n",
    "            r'no specific',\n",
    "        ]\n",
    "        \n",
    "        # Check for each text pattern\n",
    "        text_counts = {}\n",
    "        for pattern in nyd_text_patterns:\n",
    "            matches = ed_df['DiagnosisText_calc'].astype(str).str.contains(pattern, case=False, regex=True, na=False)\n",
    "            count = matches.sum()\n",
    "            patient_count = ed_df.loc[matches, 'Patient_ID'].nunique()\n",
    "            \n",
    "            text_counts[pattern] = {\n",
    "                'code_count': count,\n",
    "                'patient_count': patient_count,\n",
    "                'percentage': count / len(ed_df) * 100 if len(ed_df) > 0 else 0\n",
    "            }\n",
    "            \n",
    "            print(f\"NYD text pattern '{pattern}': {count:,} entries ({text_counts[pattern]['percentage']:.2f}%) \" +\n",
    "                  f\"in {patient_count:,} patients\")\n",
    "        \n",
    "        # Store in metrics\n",
    "        coding_metrics['nyd_text_patterns'] = text_counts\n",
    "    \n",
    "    # 4. Preliminary analysis of potential symptom codes (780-789)\n",
    "    if 'DiagnosisCode_calc' in ed_df.columns:\n",
    "        print_subsection_header(\"Symptom Code Analysis\")\n",
    "        \n",
    "        # Check for ICD-9 symptom codes (780-789 range)\n",
    "        symptom_pattern = r'^78[0-9]'\n",
    "        symptom_matches = ed_df['DiagnosisCode_calc'].astype(str).str.contains(symptom_pattern, regex=True, na=False)\n",
    "        symptom_count = symptom_matches.sum()\n",
    "        symptom_patient_count = ed_df.loc[symptom_matches, 'Patient_ID'].nunique()\n",
    "        \n",
    "        symptom_pct = symptom_count / len(ed_df) * 100 if len(ed_df) > 0 else 0\n",
    "        patient_pct = symptom_patient_count / ed_df['Patient_ID'].nunique() * 100\n",
    "        \n",
    "        print(f\"ICD-9 Symptom codes (780-789): {symptom_count:,} codes ({symptom_pct:.2f}%) \" +\n",
    "              f\"in {symptom_patient_count:,} patients ({patient_pct:.2f}%)\")\n",
    "              \n",
    "        # Get top symptom codes\n",
    "        if symptom_count > 0:\n",
    "            symptom_codes = ed_df.loc[symptom_matches, 'DiagnosisCode_calc'].value_counts().head(10)\n",
    "            print(\"\\nTop symptom codes:\")\n",
    "            for code, count in symptom_codes.items():\n",
    "                print(f\"  {code}: {count:,}\")\n",
    "\n",
    "            print(\"\\nNote: ICD-9 codes 780-789 represent 'Symptoms, Signs, and Ill-defined Conditions' and are\")\n",
    "            print(\"particularly relevant for SSD research as they often indicate medically unexplained symptoms.\")\n",
    "            print(f\"The presence of these codes in {patient_pct:.1f}% of patients suggests a large pool of potential\")\n",
    "            print(\"cases with somatic symptoms that could be evaluated for SSD criteria.\")\n",
    "                \n",
    "            # Store in metrics\n",
    "            coding_metrics['symptom_codes'] = {\n",
    "                'total_count': symptom_count,\n",
    "                'patient_count': symptom_patient_count,\n",
    "                'percentage': symptom_pct,\n",
    "                'patient_percentage': patient_pct,\n",
    "                'top_codes': symptom_codes.to_dict()\n",
    "            }\n",
    "    \n",
    "    # 5. Check for body-system distribution of symptom codes\n",
    "    print_subsection_header(\"Body System Distribution\")\n",
    "    \n",
    "    # Define body systems based on ICD-9 ranges\n",
    "    body_systems = {\n",
    "        'general': ['^780', '^R50', '^R53'],  # Fever, fatigue, malaise\n",
    "        'gi': ['^787', '^789', '^K5', '^K6', '^R1'], # Digestive symptoms\n",
    "        'neuro': ['^784', '^346', '^307.81', '^G43', '^G44', '^R51'], # Headache, dizziness\n",
    "        'cardio': ['^785', '^I10', '^R0'], # Chest pain, palpitations\n",
    "        'respiratory': ['^786', '^R0[67]'], # Shortness of breath\n",
    "        'musculo': ['^729', '^M79', '^M25', '^M54'], # Pain, joint, back\n",
    "        'skin': ['^782', '^L2', '^L3'], # Rash, skin sensations\n",
    "        'other': ['^788', '^R3'] # Urinary, etc.\n",
    "    }\n",
    "    \n",
    "    # Count codes by body system\n",
    "    system_counts = {}\n",
    "    \n",
    "    for system, patterns in body_systems.items():\n",
    "        # Combine patterns\n",
    "        system_pattern = '|'.join(patterns)\n",
    "        matches = ed_df['DiagnosisCode_calc'].astype(str).str.contains(system_pattern, regex=True, na=False)\n",
    "        count = matches.sum()\n",
    "        patient_count = ed_df.loc[matches, 'Patient_ID'].nunique()\n",
    "        \n",
    "        system_counts[system] = {\n",
    "            'code_count': count,\n",
    "            'patient_count': patient_count,\n",
    "            'percentage': count / len(ed_df) * 100 if len(ed_df) > 0 else 0\n",
    "        }\n",
    "        \n",
    "        print(f\"Body system '{system}': {count:,} codes ({system_counts[system]['percentage']:.2f}%) \" +\n",
    "              f\"in {patient_count:,} patients\")\n",
    "    \n",
    "    # Calculate multi-system counts\n",
    "    if len(system_counts) > 0:\n",
    "        # Get patients with symptoms in each system\n",
    "        system_patients = {}\n",
    "        for system, patterns in body_systems.items():\n",
    "            system_pattern = '|'.join(patterns)\n",
    "            matches = ed_df['DiagnosisCode_calc'].astype(str).str.contains(system_pattern, regex=True, na=False)\n",
    "            system_patients[system] = set(ed_df.loc[matches, 'Patient_ID'].unique())\n",
    "        \n",
    "        # Count patients with symptoms in multiple systems\n",
    "        patient_system_count = {}\n",
    "        all_patients = set(ed_df['Patient_ID'].unique())\n",
    "        \n",
    "        for patient_id in all_patients:\n",
    "            systems = [system for system, patients in system_patients.items() if patient_id in patients]\n",
    "            patient_system_count[patient_id] = len(systems)\n",
    "        \n",
    "        # Summarize\n",
    "        system_count_df = pd.Series(patient_system_count).value_counts().sort_index()\n",
    "        system_count_pct = system_count_df / len(all_patients) * 100\n",
    "        \n",
    "        print(\"\\nPatients by number of body systems with symptoms:\")\n",
    "        for num_systems, count in system_count_df.items():\n",
    "            print(f\"  {num_systems} systems: {count:,} patients ({system_count_pct[num_systems]:.2f}%)\")\n",
    "\n",
    "        print(\"\\nNote: This analysis shows how many patients have symptom codes across different body systems.\")\n",
    "        print(\"  - 0 systems: Patients with no symptom codes in any defined body system\")\n",
    "        print(\"  - 1 system: Patients with symptoms in exactly one body system (e.g., only GI)\")\n",
    "        print(\"  - 2+ systems: Patients with symptoms in multiple body systems - a key DSM-5 criterion for SSD\")\n",
    "        print(f\"  => {system_count_df.loc[lambda x: x.index >= 2].sum():,} patients ({system_count_df.loc[lambda x: x.index >= 2].sum()/len(all_patients)*100:.2f}%) have symptoms in 2+ body systems\")\n",
    "        \n",
    "\n",
    "        # Store in metrics\n",
    "        coding_metrics['multi_system'] = {\n",
    "            'counts': system_count_df.to_dict(),\n",
    "            'percentage': system_count_pct.to_dict()\n",
    "        }\n",
    "        \n",
    "        # Create visualization\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        ax = sns.barplot(x=system_count_df.index, y=system_count_df.values)\n",
    "        plt.title('Patients by Number of Body Systems with Symptoms', fontsize=14)\n",
    "        plt.xlabel('Number of Body Systems', fontsize=12)\n",
    "        plt.ylabel('Number of Patients', fontsize=12)\n",
    "        \n",
    "        # Add count and percentage labels\n",
    "        for i, p in enumerate(ax.patches):\n",
    "            height = p.get_height()\n",
    "            percentage = system_count_pct.iloc[i]\n",
    "            ax.text(p.get_x() + p.get_width()/2., height + height*0.02,\n",
    "                   f'{int(height):,}\\n({percentage:.1f}%)', \n",
    "                   ha=\"center\", va=\"bottom\", fontsize=9)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(config.OUTPUT_PATH / 'body_system_distribution.png')\n",
    "        plt.close()\n",
    "    \n",
    "    return coding_metrics\n",
    "\n",
    "\n",
    "def analyze_lab_data(data_dict):\n",
    "    \"\"\"\n",
    "    Analyze lab data structure and completeness for negative cascade detection.\n",
    "    \n",
    "    This function examines:\n",
    "    1. Lab test type distribution\n",
    "    2. Normal range data availability\n",
    "    3. Completeness of test results\n",
    "    4. Patient-level lab testing patterns\n",
    "    \n",
    "    Lab data analysis is critical for:\n",
    "    - Identifying the \"negative lab cascade\" central to SSD research\n",
    "    - Assessing data quality for normal/abnormal determination\n",
    "    - Establishing baseline lab testing patterns\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data_dict : dict\n",
    "        Dictionary of dataframes with table names as keys\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary of lab data metrics\n",
    "    \"\"\"\n",
    "    print_section_header(\"Lab Data Analysis\")\n",
    "    \n",
    "    lab_metrics = {}\n",
    "    \n",
    "    # Skip if lab table is missing\n",
    "    if 'lab' not in data_dict:\n",
    "        print(\"WARNING: Lab table missing, skipping analysis\")\n",
    "        return lab_metrics\n",
    "    \n",
    "    lab_df = data_dict['lab']\n",
    "    \n",
    "    # 1. Basic lab count metrics\n",
    "    print_subsection_header(\"Lab Test Overview\")\n",
    "    \n",
    "    total_labs = len(lab_df)\n",
    "    patient_count = lab_df['Patient_ID'].nunique()\n",
    "    average_labs_per_patient = total_labs / patient_count if patient_count > 0 else 0\n",
    "    \n",
    "    print(f\"Total lab tests: {total_labs:,}\")\n",
    "    print(f\"Patients with lab data: {patient_count:,}\")\n",
    "    print(f\"Average lab tests per patient: {average_labs_per_patient:.1f}\")\n",
    "    \n",
    "    # Store in metrics\n",
    "    lab_metrics['overview'] = {\n",
    "        'total_labs': total_labs,\n",
    "        'patient_count': patient_count,\n",
    "        'avg_per_patient': average_labs_per_patient\n",
    "    }\n",
    "    \n",
    "    # 2. Lab test type distribution\n",
    "    if 'Name_calc' in lab_df.columns:\n",
    "        # Get top lab tests\n",
    "        test_counts = lab_df['Name_calc'].value_counts().head(15)\n",
    "        test_pct = test_counts / len(lab_df) * 100\n",
    "        \n",
    "        print(\"\\nMost common lab tests:\")\n",
    "        for test, count in test_counts.items():\n",
    "            print(f\"  {test}: {count:,} ({test_pct[test]:.2f}%)\")\n",
    "            \n",
    "        # Store in metrics\n",
    "        lab_metrics['test_types'] = {\n",
    "            'counts': test_counts.to_dict(),\n",
    "            'percentage': test_pct.to_dict()\n",
    "        }\n",
    "    \n",
    "    # 3. Normal range data availability\n",
    "    print_subsection_header(\"Normal Range Data Availability\")\n",
    "    \n",
    "    if 'UpperNormal' in lab_df.columns and 'LowerNormal' in lab_df.columns:\n",
    "        # Check for presence of both normal range bounds\n",
    "        has_upper = lab_df['UpperNormal'].notna()\n",
    "        has_lower = lab_df['LowerNormal'].notna()\n",
    "        has_both = has_upper & has_lower\n",
    "        \n",
    "        both_count = has_both.sum()\n",
    "        both_pct = both_count / len(lab_df) * 100\n",
    "        \n",
    "        print(f\"Labs with both normal bounds: {both_count:,} ({both_pct:.2f}%)\")\n",
    "        \n",
    "        # Check by top test types\n",
    "        if 'Name_calc' in lab_df.columns:\n",
    "            test_normal_rates = {}\n",
    "            for test in test_counts.index[:10]:  # Top 10 tests\n",
    "                test_labs = lab_df['Name_calc'] == test\n",
    "                test_total = test_labs.sum()\n",
    "                test_with_bounds = (test_labs & has_both).sum()\n",
    "                test_rate = test_with_bounds / test_total * 100 if test_total > 0 else 0\n",
    "                \n",
    "                test_normal_rates[test] = {\n",
    "                    'total': test_total,\n",
    "                    'with_bounds': test_with_bounds,\n",
    "                    'percentage': test_rate\n",
    "                }\n",
    "                \n",
    "                print(f\"  {test}: {test_with_bounds:,}/{test_total:,} ({test_rate:.2f}%)\")\n",
    "                \n",
    "            # Store in metrics\n",
    "            lab_metrics['normal_range'] = {\n",
    "                'total_with_bounds': both_count,\n",
    "                'percentage': both_pct,\n",
    "                'by_test': test_normal_rates\n",
    "            }\n",
    "            \n",
    "            # Create visualization\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            tests = list(test_normal_rates.keys())\n",
    "            rates = [info['percentage'] for test, info in test_normal_rates.items()]\n",
    "            \n",
    "            # Sort by rate for better visualization\n",
    "            sorted_data = sorted(zip(tests, rates), key=lambda x: x[1], reverse=True)\n",
    "            tests = [t for t, r in sorted_data]\n",
    "            rates = [r for t, r in sorted_data]\n",
    "            \n",
    "            bars = plt.barh(tests, rates)\n",
    "            \n",
    "            # Add percentage labels\n",
    "            for i, bar in enumerate(bars):\n",
    "                width = bar.get_width()\n",
    "                label = f\"{width:.1f}%\"\n",
    "                plt.text(max(5, width - 10), bar.get_y() + bar.get_height()/2, \n",
    "                        label, ha='center', va='center', color='white', fontweight='bold')\n",
    "            \n",
    "            plt.xlabel('Percentage with Normal Range Bounds')\n",
    "            plt.title('Normal Range Data Availability by Lab Test Type')\n",
    "            plt.xlim(0, 100)\n",
    "            plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(config.OUTPUT_PATH / 'lab_normal_range_availability.png')\n",
    "            plt.close()\n",
    "    \n",
    "    # 4. Numeric result availability\n",
    "    print_subsection_header(\"Numeric Test Result Availability\")\n",
    "    \n",
    "    if 'TestResult_calc' in lab_df.columns:\n",
    "        # Check for numeric values\n",
    "        lab_df['TestResult_numeric'] = pd.to_numeric(lab_df['TestResult_calc'], errors='coerce')\n",
    "        has_numeric = lab_df['TestResult_numeric'].notna()\n",
    "        \n",
    "        numeric_count = has_numeric.sum()\n",
    "        numeric_pct = numeric_count / len(lab_df) * 100\n",
    "        \n",
    "        print(f\"Labs with numeric results: {numeric_count:,} ({numeric_pct:.2f}%)\")\n",
    "        \n",
    "        # Store in metrics\n",
    "        lab_metrics['numeric_results'] = {\n",
    "            'count': numeric_count,\n",
    "            'percentage': numeric_pct\n",
    "        }\n",
    "    \n",
    "    # 5. Patient-level lab testing patterns\n",
    "    print_subsection_header(\"Patient-Level Lab Testing Patterns\")\n",
    "    \n",
    "    # Count labs per patient\n",
    "    patient_lab_counts = lab_df.groupby('Patient_ID').size()\n",
    "    \n",
    "    # Calculate statistics\n",
    "    mean_labs = patient_lab_counts.mean()\n",
    "    median_labs = patient_lab_counts.median()\n",
    "    p90_labs = patient_lab_counts.quantile(0.9)\n",
    "    max_labs = patient_lab_counts.max()\n",
    "    \n",
    "    print(f\"Lab test statistics:\")\n",
    "    print(f\"  Mean: {mean_labs:.1f} tests per patient\")\n",
    "    print(f\"  Median: {median_labs:.0f} tests per patient\")\n",
    "    print(f\"  90th percentile: {p90_labs:.0f} tests per patient\")\n",
    "    print(f\"  Maximum: {max_labs:.0f} tests per patient\")\n",
    "    \n",
    "    # Store in metrics\n",
    "    lab_metrics['patient_labs'] = {\n",
    "        'mean': mean_labs,\n",
    "        'median': median_labs,\n",
    "        'p90': p90_labs,\n",
    "        'max': max_labs\n",
    "    }\n",
    "    \n",
    "    # Create histogram of lab counts\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    # Log transform for better visualization\n",
    "    log_counts = np.log10(patient_lab_counts + 1)  # +1 to handle zeros\n",
    "    plt.hist(log_counts, bins=50)\n",
    "    plt.title('Distribution of Lab Tests per Patient (Log Scale)', fontsize=14)\n",
    "    plt.xlabel('log10(Lab Tests + 1)', fontsize=12)\n",
    "    plt.ylabel('Number of Patients', fontsize=12)\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(config.OUTPUT_PATH / 'lab_test_distribution.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # 6. Preliminary normal lab cascade analysis\n",
    "    if 'TestResult_calc' in lab_df.columns and 'UpperNormal' in lab_df.columns and 'LowerNormal' in lab_df.columns:\n",
    "        print_subsection_header(\"Preliminary Normal Lab Analysis\")\n",
    "        \n",
    "        # Find labs with full normal range data\n",
    "        has_full_data = lab_df['TestResult_numeric'].notna() & lab_df['UpperNormal'].notna() & lab_df['LowerNormal'].notna()\n",
    "        \n",
    "        if has_full_data.any():\n",
    "            # Convert range boundaries to numeric\n",
    "            lab_df['upper_numeric'] = pd.to_numeric(lab_df['UpperNormal'], errors='coerce')\n",
    "            lab_df['lower_numeric'] = pd.to_numeric(lab_df['LowerNormal'], errors='coerce')\n",
    "            \n",
    "            # Get subset with full data\n",
    "            full_data = lab_df[has_full_data].copy()\n",
    "            \n",
    "            # Flag normal results\n",
    "            full_data['is_normal'] = (\n",
    "                (full_data['TestResult_numeric'] >= full_data['lower_numeric']) &\n",
    "                (full_data['TestResult_numeric'] <= full_data['upper_numeric'])\n",
    "            )\n",
    "            \n",
    "            # Count normal labs\n",
    "            normal_count = full_data['is_normal'].sum()\n",
    "            normal_pct = normal_count / len(full_data) * 100\n",
    "            \n",
    "            print(f\"Labs with full data for normal analysis: {len(full_data):,} ({len(full_data)/len(lab_df)*100:.2f}%)\")\n",
    "            print(f\"Normal lab results: {normal_count:,} ({normal_pct:.2f}%)\")\n",
    "            \n",
    "            # Count patients with multiple normal labs\n",
    "            patient_normal_counts = full_data.groupby('Patient_ID')['is_normal'].sum()\n",
    "            \n",
    "            # Thresholds for normal labs\n",
    "            for threshold in [3, 4, 5]:\n",
    "                patients_above = (patient_normal_counts >= threshold).sum()\n",
    "                pct_above = patients_above / len(patient_normal_counts) * 100\n",
    "                \n",
    "                print(f\"Patients with ≥{threshold} normal labs: {patients_above:,} ({pct_above:.2f}%)\")\n",
    "                \n",
    "            # Store in metrics\n",
    "            lab_metrics['normal_analysis'] = {\n",
    "                'normal_count': normal_count,\n",
    "                'normal_percentage': normal_pct,\n",
    "                'patient_thresholds': {\n",
    "                    f'ge_{threshold}': (patient_normal_counts >= threshold).sum()\n",
    "                    for threshold in [3, 4, 5]\n",
    "                }\n",
    "            }\n",
    "    \n",
    "    return lab_metrics\n",
    "\n",
    "\n",
    "def analyze_referral_patterns(data_dict):\n",
    "    \"\"\"\n",
    "    Analyze referral patterns with focus on psychiatry vs. other specialists.\n",
    "    \n",
    "    This function examines:\n",
    "    1. Referral type distribution\n",
    "    2. Preliminary psychiatry referral identification\n",
    "    3. Multi-specialty referral patterns\n",
    "    \n",
    "    Referral analysis is critical for:\n",
    "    - Identifying the specialist to psychiatry sequence in SSD pathway\n",
    "    - Quantifying \"doctor shopping\" behavior\n",
    "    - Understanding typical specialty consultation patterns\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data_dict : dict\n",
    "        Dictionary of dataframes with table names as keys\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary of referral pattern metrics\n",
    "    \"\"\"\n",
    "    print_section_header(\"Referral Pattern Analysis\")\n",
    "    \n",
    "    referral_metrics = {}\n",
    "    \n",
    "    # Skip if referral table is missing\n",
    "    if 'referral' not in data_dict:\n",
    "        print(\"WARNING: Referral table missing, skipping analysis\")\n",
    "        return referral_metrics\n",
    "    \n",
    "    ref_df = data_dict['referral']\n",
    "    \n",
    "    # 1. Basic referral metrics\n",
    "    print_subsection_header(\"Referral Overview\")\n",
    "    \n",
    "    total_refs = len(ref_df)\n",
    "    patient_count = ref_df['Patient_ID'].nunique()\n",
    "    average_refs_per_patient = total_refs / patient_count if patient_count > 0 else 0\n",
    "    \n",
    "    print(f\"Total referrals: {total_refs:,}\")\n",
    "    print(f\"Patients with referrals: {patient_count:,}\")\n",
    "    print(f\"Average referrals per patient: {average_refs_per_patient:.1f}\")\n",
    "    \n",
    "    # Store in metrics\n",
    "    referral_metrics['overview'] = {\n",
    "        'total_referrals': total_refs,\n",
    "        'patient_count': patient_count,\n",
    "        'avg_per_patient': average_refs_per_patient\n",
    "    }\n",
    "    \n",
    "    # 2. Referral type distribution\n",
    "    if 'Name_calc' in ref_df.columns:\n",
    "        # Get top referral types\n",
    "        ref_counts = ref_df['Name_calc'].value_counts().head(15)\n",
    "        ref_pct = ref_counts / len(ref_df) * 100\n",
    "        \n",
    "        print(\"\\nMost common referral types:\")\n",
    "        for ref_type, count in ref_counts.items():\n",
    "            print(f\"  {ref_type}: {count:,} ({ref_pct[ref_type]:.2f}%)\")\n",
    "            \n",
    "        # Store in metrics\n",
    "        referral_metrics['ref_types'] = {\n",
    "            'counts': ref_counts.to_dict(),\n",
    "            'percentage': ref_pct.to_dict()\n",
    "        }\n",
    "    \n",
    "    # 3. Identify psychiatric referrals\n",
    "    print_subsection_header(\"Psychiatric Referral Analysis\")\n",
    "    \n",
    "    if 'Name_calc' in ref_df.columns:\n",
    "        # Define psychiatry patterns based on validated terminology\n",
    "        psych_patterns = [\n",
    "            'psychiatr', 'mental health', 'psych', 'behavioral health', 'mood',\n",
    "            'mental', 'anxiety', 'depression', 'counseling', 'mh consult'\n",
    "        ]\n",
    "        psych_pattern = '|'.join([f\"\\\\b{p}\" for p in psych_patterns])\n",
    "        \n",
    "        # Flag psychiatric referrals\n",
    "        ref_df['to_psychiatrist'] = ref_df['Name_calc'].str.contains(\n",
    "            psych_pattern, case=False, regex=True, na=False)\n",
    "        \n",
    "        psych_count = ref_df['to_psychiatrist'].sum()\n",
    "        psych_pct = psych_count / len(ref_df) * 100\n",
    "        psych_patient_count = ref_df.loc[ref_df['to_psychiatrist'], 'Patient_ID'].nunique()\n",
    "        psych_patient_pct = psych_patient_count / patient_count * 100\n",
    "        \n",
    "        print(f\"Psychiatric referrals: {psych_count:,} ({psych_pct:.2f}%)\")\n",
    "        print(f\"Patients with psychiatric referrals: {psych_patient_count:,} ({psych_patient_pct:.2f}%)\")\n",
    "        \n",
    "        # Store in metrics\n",
    "        referral_metrics['psychiatry'] = {\n",
    "            'referral_count': psych_count,\n",
    "            'referral_percentage': psych_pct,\n",
    "            'patient_count': psych_patient_count,\n",
    "            'patient_percentage': psych_patient_pct\n",
    "        }\n",
    "    \n",
    "    # 4. Define and analyze body system specialists\n",
    "    print_subsection_header(\"Body System Specialist Analysis\")\n",
    "    \n",
    "    if 'Name_calc' in ref_df.columns:\n",
    "        # Define body system specialists based on validated terminology\n",
    "        body_systems = {\n",
    "            'cardio': ['cardiol', 'heart', 'cardiac', 'vascular', 'circulat', 'cardiolog', 'cardio'],\n",
    "            'gastro': ['gastro', 'gi', 'digestive', 'stomach', 'intestin', 'bowel', 'endo'],\n",
    "            'neuro': ['neuro', 'brain', 'headache', 'seizure', 'cognit', 'memory', 'nervous'],\n",
    "            'musculo': ['orthoped', 'rheumat', 'joint', 'pain', 'musculo', 'arthrit', 'back', 'spine', 'ortho'],\n",
    "            'respiratory': ['pulmon', 'lung', 'respirat', 'breath', 'asthma', 'copd', 'pulm', 'resp'],\n",
    "            'endo': ['endocrin', 'diabet', 'thyroid', 'hormone', 'metabol', 'endo'],\n",
    "            'derm': ['dermatol', 'skin', 'rash', 'lesion', 'derm'],\n",
    "            'gyn': ['gynecol', 'obstetric', 'women', 'pelvic', 'genital', 'urolog', 'gyn', 'repro']\n",
    "        }\n",
    "        \n",
    "        # Flag each body system\n",
    "        for system, keywords in body_systems.items():\n",
    "            system_pattern = '|'.join([f\"\\\\b{k}\" for k in keywords])\n",
    "            col_name = f'to_{system}'\n",
    "            ref_df[col_name] = ref_df['Name_calc'].str.contains(\n",
    "                system_pattern, case=False, regex=True, na=False)\n",
    "        \n",
    "        # Summarize body system referrals\n",
    "        system_metrics = {}\n",
    "        print(\"\\nBody system referral distribution:\")\n",
    "        for system in body_systems.keys():\n",
    "            col_name = f'to_{system}'\n",
    "            count = ref_df[col_name].sum()\n",
    "            pct = count / len(ref_df) * 100\n",
    "            patient_count = ref_df.loc[ref_df[col_name], 'Patient_ID'].nunique()\n",
    "            patient_pct = patient_count / ref_df['Patient_ID'].nunique() * 100\n",
    "            \n",
    "            system_metrics[system] = {\n",
    "                'referral_count': count,\n",
    "                'referral_percentage': pct,\n",
    "                'patient_count': patient_count,\n",
    "                'patient_percentage': patient_pct\n",
    "            }\n",
    "            \n",
    "            print(f\"  {system}: {count:,} referrals ({pct:.2f}%) in {patient_count:,} patients ({patient_pct:.2f}%)\")\n",
    "        \n",
    "        # Store in metrics\n",
    "        referral_metrics['body_systems'] = system_metrics\n",
    "        \n",
    "        # Create visualization\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        systems = list(system_metrics.keys())\n",
    "        counts = [info['referral_count'] for system, info in system_metrics.items()]\n",
    "        \n",
    "        # Sort by count for better visualization\n",
    "        sorted_data = sorted(zip(systems, counts), key=lambda x: x[1], reverse=True)\n",
    "        systems = [s for s, c in sorted_data]\n",
    "        counts = [c for s, c in sorted_data]\n",
    "        \n",
    "        ax = plt.bar(systems, counts)\n",
    "        \n",
    "        # Add count labels\n",
    "        for i, p in enumerate(ax):\n",
    "            height = p.get_height()\n",
    "            plt.text(p.get_x() + p.get_width()/2., height + height*0.02,\n",
    "                   f'{int(height):,}', \n",
    "                   ha=\"center\", va=\"bottom\", fontsize=9)\n",
    "        \n",
    "        plt.ylabel('Number of Referrals')\n",
    "        plt.title('Referrals by Body System')\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(config.OUTPUT_PATH / 'body_system_referrals.png')\n",
    "        plt.close()\n",
    "    \n",
    "    # 5. Multi-specialty referral patterns\n",
    "    print_subsection_header(\"Multi-Specialty Referral Patterns\")\n",
    "    \n",
    "    # Count referrals per patient\n",
    "    patient_ref_counts = ref_df.groupby('Patient_ID').size()\n",
    "    \n",
    "    # Calculate statistics\n",
    "    mean_refs = patient_ref_counts.mean()\n",
    "    median_refs = patient_ref_counts.median()\n",
    "    p90_refs = patient_ref_counts.quantile(0.9)\n",
    "    \n",
    "    print(f\"Referral statistics:\")\n",
    "    print(f\"  Mean: {mean_refs:.1f} referrals per patient\")\n",
    "    print(f\"  Median: {median_refs:.0f} referrals per patient\")\n",
    "    print(f\"  90th percentile: {p90_refs:.0f} referrals per patient\")\n",
    "    \n",
    "    # Analyze multi-specialty patterns\n",
    "    if 'to_psychiatrist' in ref_df.columns and any(f'to_{system}' in ref_df.columns for system in body_systems.keys()):\n",
    "        # Flag any non-psychiatric specialty\n",
    "        ref_df['to_any_body_system'] = False\n",
    "        for system in body_systems.keys():\n",
    "            col_name = f'to_{system}'\n",
    "            if col_name in ref_df.columns:\n",
    "                ref_df['to_any_body_system'] = ref_df['to_any_body_system'] | ref_df[col_name]\n",
    "        \n",
    "        # Get patient-level specialty flags\n",
    "        patient_specialties = ref_df.groupby('Patient_ID').agg({\n",
    "            'to_psychiatrist': 'any',\n",
    "            'to_any_body_system': 'any'\n",
    "        })\n",
    "        \n",
    "        # Calculate patterns\n",
    "        patient_specialties['psych_only'] = patient_specialties['to_psychiatrist'] & ~patient_specialties['to_any_body_system']\n",
    "        patient_specialties['body_only'] = ~patient_specialties['to_psychiatrist'] & patient_specialties['to_any_body_system']\n",
    "        patient_specialties['both'] = patient_specialties['to_psychiatrist'] & patient_specialties['to_any_body_system']\n",
    "        patient_specialties['neither'] = ~patient_specialties['to_psychiatrist'] & ~patient_specialties['to_any_body_system']\n",
    "        \n",
    "        # Summarize\n",
    "        pattern_counts = {\n",
    "            'psych_only': patient_specialties['psych_only'].sum(),\n",
    "            'body_only': patient_specialties['body_only'].sum(),\n",
    "            'both': patient_specialties['both'].sum(),\n",
    "            'neither': patient_specialties['neither'].sum()\n",
    "        }\n",
    "        \n",
    "        pattern_pct = {k: v / len(patient_specialties) * 100 for k, v in pattern_counts.items()}\n",
    "        \n",
    "        print(\"\\nPatient referral patterns:\")\n",
    "        print(f\"  Psychiatry only: {pattern_counts['psych_only']:,} patients ({pattern_pct['psych_only']:.2f}%)\")\n",
    "        print(f\"  Body system only: {pattern_counts['body_only']:,} patients ({pattern_pct['body_only']:.2f}%)\")\n",
    "        print(f\"  Both psychiatry and body system: {pattern_counts['both']:,} patients ({pattern_pct['both']:.2f}%)\")\n",
    "        print(f\"  Neither (other or unclassified referrals): {pattern_counts['neither']:,} patients ({pattern_pct['neither']:.2f}%)\")\n",
    "        \n",
    "        # Store in metrics\n",
    "        referral_metrics['patterns'] = {\n",
    "            'counts': pattern_counts,\n",
    "            'percentage': pattern_pct\n",
    "        }\n",
    "        \n",
    "        # Create visualization\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        labels = ['Psychiatry Only', 'Body System Only', 'Both', 'Neither/Other']\n",
    "        values = [pattern_counts[k] for k in ['psych_only', 'body_only', 'both', 'neither']]\n",
    "        \n",
    "        ax = plt.bar(labels, values)\n",
    "        \n",
    "        # Add count and percentage labels\n",
    "        for i, p in enumerate(ax):\n",
    "            height = p.get_height()\n",
    "            percentage = list(pattern_pct.values())[i]\n",
    "            plt.text(p.get_x() + p.get_width()/2., height + height*0.02,\n",
    "                   f'{int(height):,}\\n({percentage:.1f}%)', \n",
    "                   ha=\"center\", va=\"bottom\", fontsize=9)\n",
    "        \n",
    "        plt.ylabel('Number of Patients')\n",
    "        plt.title('Patient Referral Patterns')\n",
    "        plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(config.OUTPUT_PATH / 'referral_patterns.png')\n",
    "        plt.close()\n",
    "    \n",
    "    # 6. Doctor shopping analysis (multiple providers)\n",
    "    if 'referral' in data_dict and 'Provider_ID' in ref_df.columns:\n",
    "        print_subsection_header(\"Doctor Shopping Analysis\")\n",
    "        \n",
    "        # Count distinct providers per patient\n",
    "        provider_counts = ref_df.groupby('Patient_ID')['Provider_ID'].nunique()\n",
    "        \n",
    "        # Calculate statistics\n",
    "        mean_providers = provider_counts.mean()\n",
    "        median_providers = provider_counts.median()\n",
    "        p90_providers = provider_counts.quantile(0.9)\n",
    "        \n",
    "        print(f\"Provider statistics:\")\n",
    "        print(f\"  Mean: {mean_providers:.1f} distinct providers per patient\")\n",
    "        print(f\"  Median: {median_providers:.0f} distinct providers per patient\")\n",
    "        print(f\"  90th percentile: {p90_providers:.0f} distinct providers per patient\")\n",
    "        \n",
    "        # Define doctor shopping as ≥5 providers (from research protocol)\n",
    "        shopping_threshold = 5\n",
    "        shoppers = (provider_counts >= shopping_threshold).sum()\n",
    "        shoppers_pct = shoppers / len(provider_counts) * 100\n",
    "        \n",
    "        print(f\"Patients with ≥{shopping_threshold} different providers (potential doctor shopping): \" +\n",
    "              f\"{shoppers:,} ({shoppers_pct:.2f}%)\")\n",
    "        \n",
    "        # Store in metrics\n",
    "        referral_metrics['doctor_shopping'] = {\n",
    "            'mean_providers': mean_providers,\n",
    "            'median_providers': median_providers,\n",
    "            'p90_providers': p90_providers,\n",
    "            'shoppers_count': shoppers,\n",
    "            'shoppers_percentage': shoppers_pct,\n",
    "            'threshold': shopping_threshold\n",
    "        }\n",
    "        \n",
    "        # Create histogram of provider counts\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.hist(provider_counts, bins=range(0, 20), alpha=0.7)\n",
    "        plt.axvline(x=shopping_threshold, color='r', linestyle='--', linewidth=2, \n",
    "                   label=f'Shopping threshold (≥{shopping_threshold})')\n",
    "        plt.title('Distribution of Distinct Providers per Patient', fontsize=14)\n",
    "        plt.xlabel('Number of Distinct Providers', fontsize=12)\n",
    "        plt.ylabel('Number of Patients', fontsize=12)\n",
    "        plt.legend()\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(config.OUTPUT_PATH / 'provider_distribution.png')\n",
    "        plt.close()\n",
    "    \n",
    "    return referral_metrics\n",
    "def save_validation_results(data_quality, relationship_metrics, temporal_metrics,\n",
    "                         population_metrics, coding_metrics, lab_metrics, referral_metrics):\n",
    "    \"\"\"\n",
    "    Save all validation results to a structured JSON file for future reference.\n",
    "    \n",
    "    This function combines all metrics into a single, comprehensive report that can be:\n",
    "    1. Loaded in subsequent notebooks\n",
    "    2. Used for data quality monitoring over time\n",
    "    3. Included in supplementary materials for publications\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    Various metric dictionaries from validation functions\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    str\n",
    "        Path to saved report file\n",
    "    \"\"\"\n",
    "    def calculate_nyd_patients(coding_metrics):\n",
    "        \"\"\"Calculate total patients with any NYD code pattern.\"\"\"\n",
    "        if not coding_metrics or 'nyd_patterns' not in coding_metrics:\n",
    "            return 0\n",
    "            \n",
    "        # Get all patient counts from patterns\n",
    "        pattern_counts = [pattern.get('patient_count', 0) \n",
    "                        for pattern in coding_metrics['nyd_patterns'].values()]\n",
    "        \n",
    "        # Return the highest count (as a conservative estimate)\n",
    "        # This avoids double-counting while ensuring we don't miss patients\n",
    "        return max(pattern_counts, default=0)\n",
    "        \n",
    "    print_section_header(\"Saving Validation Results\")\n",
    "    \n",
    "     # Combine all metrics\n",
    "    validation_report = {\n",
    "        'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        'data_quality': data_quality,\n",
    "        'relationships': relationship_metrics,\n",
    "        'temporal': temporal_metrics,\n",
    "        'population': population_metrics,\n",
    "        'coding': coding_metrics,\n",
    "        'lab': lab_metrics,\n",
    "        'referral': referral_metrics\n",
    "    }\n",
    "    \n",
    "    # Save to file\n",
    "    report_path = config.OUTPUT_PATH / 'data_validation_report.json'\n",
    "    \n",
    "    with open(report_path, 'w') as f:\n",
    "        json.dump(validation_report, f, indent=2, default=str)  # default=str handles non-serializable objects\n",
    "    \n",
    "    print(f\"Saved validation report to {report_path}\")\n",
    "    \n",
    "    # Create summary for display\n",
    "    summary = {\n",
    "        'Tables Loaded': len(data_quality),\n",
    "        'Total Patients': population_metrics.get('overview', {}).get('total_patients', 'Unknown'),\n",
    "        'Data Relationship Issues': any(rel.get('orphan_percentage', 0) > 0.05 for rel in relationship_metrics.values()) if relationship_metrics else 'Unknown',\n",
    "        'Normal Lab Data Available': lab_metrics.get('normal_range', {}).get('percentage', 0) if lab_metrics else 'Unknown',\n",
    "        'Patients with NYD Codes': calculate_nyd_patients(coding_metrics),\n",
    "        'Psychiatry Referrals': referral_metrics.get('psychiatry', {}).get('patient_count', 0) if referral_metrics else 'Unknown'\n",
    "    }\n",
    "    \n",
    "    print(\"\\nValidation Summary:\")\n",
    "    for key, value in summary.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "    \n",
    "    return report_path\n",
    "def enhance_lab_classification(lab_df):\n",
    "    \"\"\"Multi-strategy approach to classify lab results as normal/abnormal.\"\"\"\n",
    "    print(\"Enhancing normal lab classification...\")\n",
    "    \n",
    "    result = lab_df.copy()\n",
    "    total_labs = len(result)\n",
    "    result['is_normal'] = pd.NA\n",
    "    \n",
    "    # 1. Explicit normal ranges where available\n",
    "    has_bounds = result['LowerNormal'].notna() & result['UpperNormal'].notna() & result['TestResult_calc'].notna()\n",
    "    \n",
    "    if has_bounds.any():\n",
    "        # Convert to numeric for comparison\n",
    "        lower_numeric = pd.to_numeric(result.loc[has_bounds, 'LowerNormal'], errors='coerce')\n",
    "        upper_numeric = pd.to_numeric(result.loc[has_bounds, 'UpperNormal'], errors='coerce')\n",
    "        result_numeric = pd.to_numeric(result.loc[has_bounds, 'TestResult_calc'], errors='coerce')\n",
    "        \n",
    "        # Identify normal results within bounds\n",
    "        valid_bounds = lower_numeric.notna() & upper_numeric.notna() & result_numeric.notna()\n",
    "        if valid_bounds.any():\n",
    "            normal_mask = valid_bounds & (result_numeric >= lower_numeric) & (result_numeric <= upper_numeric)\n",
    "            result.loc[has_bounds[has_bounds].index[normal_mask], 'is_normal'] = True\n",
    "            result.loc[has_bounds[has_bounds].index[~normal_mask & valid_bounds], 'is_normal'] = False\n",
    "        \n",
    "        processed_count = valid_bounds.sum()\n",
    "        print(f\"Method 1 (Explicit ranges): {processed_count:,} labs processed ({processed_count/total_labs*100:.2f}%)\")\n",
    "    \n",
    "    # 2. Standard reference intervals for common tests\n",
    "    common_tests = {\n",
    "        'TOTAL CHOLESTEROL': {'min': 0, 'max': 5.2, 'unit': 'mmol/L'},\n",
    "        'HDL': {'min': 1.0, 'max': 3.0, 'unit': 'mmol/L'},\n",
    "        'LDL': {'min': 0, 'max': 3.4, 'unit': 'mmol/L'},\n",
    "        'TRIGLYCERIDES': {'min': 0, 'max': 1.7, 'unit': 'mmol/L'},\n",
    "        'FASTING GLUCOSE': {'min': 3.9, 'max': 5.6, 'unit': 'mmol/L'},\n",
    "        'HBA1C': {'min': 0, 'max': 5.7, 'unit': '%'},\n",
    "        'TSH': {'min': 0.4, 'max': 4.0, 'unit': 'mIU/L'},\n",
    "        'ALT': {'min': 0, 'max': 40, 'unit': 'U/L'},\n",
    "        'AST': {'min': 0, 'max': 40, 'unit': 'U/L'},\n",
    "        'CREATININE': {'min': 50, 'max': 120, 'unit': 'umol/L'},\n",
    "        'HEMOGLOBIN': {'min': 120, 'max': 160, 'unit': 'g/L'},\n",
    "        'WBC': {'min': 4.0, 'max': 11.0, 'unit': '10^9/L'},\n",
    "        'POTASSIUM': {'min': 3.5, 'max': 5.0, 'unit': 'mmol/L'},\n",
    "        'SODIUM': {'min': 135, 'max': 145, 'unit': 'mmol/L'}\n",
    "    }\n",
    "    \n",
    "    # Convert TestResult_calc to numeric once\n",
    "    result['result_numeric'] = pd.to_numeric(result['TestResult_calc'], errors='coerce')\n",
    "    \n",
    "    # Process each common test\n",
    "    reference_count = 0\n",
    "    for test_name, reference in common_tests.items():\n",
    "        # Find pending labs for this test (result known but normal status unknown)\n",
    "        test_mask = (\n",
    "            result['Name_calc'].str.contains(test_name, case=False, regex=False, na=False) &\n",
    "            result['result_numeric'].notna() &\n",
    "            result['is_normal'].isna()\n",
    "        )\n",
    "        \n",
    "        if test_mask.any():\n",
    "            normal_mask = (\n",
    "                (result.loc[test_mask, 'result_numeric'] >= reference['min']) & \n",
    "                (result.loc[test_mask, 'result_numeric'] <= reference['max'])\n",
    "            )\n",
    "            result.loc[test_mask[test_mask].index[normal_mask], 'is_normal'] = True\n",
    "            result.loc[test_mask[test_mask].index[~normal_mask], 'is_normal'] = False\n",
    "            reference_count += test_mask.sum()\n",
    "    \n",
    "    print(f\"Method 2 (Reference intervals): {reference_count:,} labs processed ({reference_count/total_labs*100:.2f}%)\")\n",
    "    \n",
    "    # 3. Text pattern search for remaining labs\n",
    "    pending_mask = result['is_normal'].isna() & result['TestResult_calc'].notna()\n",
    "    text_count = 0\n",
    "    \n",
    "    if pending_mask.any():\n",
    "        # Normal indicators\n",
    "        normal_patterns = [\n",
    "            'normal', 'neg', 'negative', 'unremarkable', 'w/in normal', 'within normal', \n",
    "            'wnl', 'within reference', 'not detected', 'n/a'\n",
    "        ]\n",
    "        normal_pattern = '|'.join([f\"\\\\b{p}\" for p in normal_patterns])\n",
    "        \n",
    "        # Abnormal indicators\n",
    "        abnormal_patterns = [\n",
    "            'abnormal', 'pos', 'positive', 'high', 'low', 'elevated', 'depressed', \n",
    "            'outside', 'detected', 'present'\n",
    "        ]\n",
    "        abnormal_pattern = '|'.join([f\"\\\\b{p}\" for p in abnormal_patterns])\n",
    "        \n",
    "        # Apply normal patterns\n",
    "        normal_text = result.loc[pending_mask, 'TestResult_calc'].astype(str).str.contains(\n",
    "            normal_pattern, case=False, regex=True, na=False\n",
    "        )\n",
    "        result.loc[pending_mask[pending_mask].index[normal_text], 'is_normal'] = True\n",
    "        \n",
    "        # Apply abnormal patterns (where normal wasn't found)\n",
    "        still_pending = result['is_normal'].isna() & result['TestResult_calc'].notna()\n",
    "        if still_pending.any():\n",
    "            abnormal_text = result.loc[still_pending, 'TestResult_calc'].astype(str).str.contains(\n",
    "                abnormal_pattern, case=False, regex=True, na=False\n",
    "            )\n",
    "            result.loc[still_pending[still_pending].index[abnormal_text], 'is_normal'] = False\n",
    "        \n",
    "        text_count = (normal_text.sum() + abnormal_text.sum())\n",
    "    \n",
    "    print(f\"Method 3 (Text patterns): {text_count:,} labs processed ({text_count/total_labs*100:.2f}%)\")\n",
    "    \n",
    "    # Calculate overall coverage\n",
    "    classified_count = result['is_normal'].notna().sum()\n",
    "    coverage_pct = classified_count / total_labs * 100\n",
    "    normal_count = result['is_normal'].sum()\n",
    "    abnormal_count = (~result['is_normal'] & result['is_normal'].notna()).sum()\n",
    "    \n",
    "    print(f\"Overall: Classified {classified_count:,} labs ({coverage_pct:.2f}%)\")\n",
    "    print(f\"Normal: {normal_count:,} ({normal_count/classified_count*100:.2f}% of classified)\")\n",
    "    print(f\"Abnormal: {abnormal_count:,} ({abnormal_count/classified_count*100:.2f}% of classified)\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def enhance_referral_dates(referral_df):\n",
    "    \"\"\"Enhance referral dates using fallback strategies.\"\"\"\n",
    "    print(\"Implementing referral date enhancement...\")\n",
    "    \n",
    "    result = referral_df.copy()\n",
    "    total_refs = len(result)\n",
    "    \n",
    "    # Check completion date coverage\n",
    "    missing_completion = result['CompletedDate'].isna()\n",
    "    missing_count = missing_completion.sum()\n",
    "    missing_pct = missing_count / total_refs * 100\n",
    "    \n",
    "    print(f\"CompletedDate missing in {missing_count:,} referrals ({missing_pct:.2f}%)\")\n",
    "    \n",
    "    # Create effective date column with source tracking\n",
    "    result['EffectiveDate'] = result['CompletedDate']\n",
    "    result['DateSource'] = 'CompletedDate'\n",
    "    \n",
    "    # Use DateCreated as fallback when needed\n",
    "    if missing_count > 0:\n",
    "        result.loc[missing_completion, 'EffectiveDate'] = result.loc[missing_completion, 'DateCreated']\n",
    "        result.loc[missing_completion, 'DateSource'] = 'DateCreated'\n",
    "        \n",
    "        # Check coverage after fallback\n",
    "        remaining_missing = result['EffectiveDate'].isna().sum()\n",
    "        \n",
    "        print(f\"After fallback: {remaining_missing:,} referrals still missing dates ({remaining_missing/total_refs*100:.2f}%)\")\n",
    "        print(f\"Using DateCreated for {missing_count-remaining_missing:,} referrals\")\n",
    "    \n",
    "    # Flag referral status based on available dates\n",
    "    result['ReferralStatus'] = 'Unknown'\n",
    "    \n",
    "    # Completed referrals have CompletedDate\n",
    "    result.loc[result['CompletedDate'].notna(), 'ReferralStatus'] = 'Completed'\n",
    "    \n",
    "    # Pending referrals have DateCreated but no CompletedDate\n",
    "    result.loc[(result['CompletedDate'].isna()) & (result['DateCreated'].notna()), \n",
    "               'ReferralStatus'] = 'Pending'\n",
    "    \n",
    "    # Count by status\n",
    "    status_counts = result['ReferralStatus'].value_counts()\n",
    "    print(\"\\nReferral Status Distribution:\")\n",
    "    for status, count in status_counts.items():\n",
    "        print(f\"  {status}: {count:,} ({count/total_refs*100:.2f}%)\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def save_checkpoint_with_documentation(data_dict, notebook_number, description, changes=None):\n",
    "    \"\"\"Save checkpoint with clear documentation for future reference.\"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    # Create checkpoint directory\n",
    "    checkpoint_dir = config.INTERIM_PATH / f\"checkpoint_{notebook_number}_{timestamp}\"\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    \n",
    "    # Save each dataframe with appropriate format\n",
    "    saved_tables = {}\n",
    "    for name, df in data_dict.items():\n",
    "        try:\n",
    "            # Handle special case for lab table\n",
    "            if name == 'lab':\n",
    "                csv_path = checkpoint_dir / f\"{name}.csv\"\n",
    "                df.to_csv(csv_path, index=False)\n",
    "                saved_tables[name] = {\n",
    "                    'path': str(csv_path),\n",
    "                    'rows': len(df),\n",
    "                    'columns': len(df.columns),\n",
    "                    'format': 'csv'\n",
    "                }\n",
    "                print(f\"Saved {name} ({len(df):,} rows) as CSV\")\n",
    "            else:\n",
    "                # Try parquet first\n",
    "                try:\n",
    "                    parquet_path = checkpoint_dir / f\"{name}.parquet\"\n",
    "                    df.to_parquet(parquet_path, index=False)\n",
    "                    saved_tables[name] = {\n",
    "                        'path': str(parquet_path),\n",
    "                        'rows': len(df),\n",
    "                        'columns': len(df.columns),\n",
    "                        'format': 'parquet'\n",
    "                    }\n",
    "                    print(f\"Saved {name} ({len(df):,} rows) as parquet\")\n",
    "                except Exception:\n",
    "                    # Fall back to CSV\n",
    "                    csv_path = checkpoint_dir / f\"{name}.csv\"\n",
    "                    df.to_csv(csv_path, index=False)\n",
    "                    saved_tables[name] = {\n",
    "                        'path': str(csv_path),\n",
    "                        'rows': len(df),\n",
    "                        'columns': len(df.columns),\n",
    "                        'format': 'csv'\n",
    "                    }\n",
    "                    print(f\"Saved {name} ({len(df):,} rows) as CSV (parquet failed)\")\n",
    "        except Exception as e:\n",
    "            print(f\"ERROR saving {name}: {str(e)}\")\n",
    "    \n",
    "    # Create detailed README\n",
    "    readme_content = f\"\"\"# Notebook {notebook_number}: {description}\n",
    "\n",
    "## Summary\n",
    "This checkpoint contains data processed through notebook {notebook_number}.\n",
    "\n",
    "## Date\n",
    "{datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}\n",
    "\n",
    "## Tables\n",
    "{chr(10).join([f\"- **{name}**: {info['rows']:,} rows, {len(data_dict[name].columns)} columns ({info['format']})\" \n",
    "               for name, info in saved_tables.items()])}\n",
    "\n",
    "## Changes Made\n",
    "{chr(10).join([f\"- {change}\" for change in (changes or ['No specific changes documented.'])])}\n",
    "\n",
    "## Key Notes\n",
    "- Lab normal detection uses multiple methods (explicit ranges, reference intervals, text patterns)\n",
    "- Orphaned labs linked to encounters using temporal proximity\n",
    "- Referral dates use DateCreated as fallback when CompletedDate missing\n",
    "- NYD codes enhanced with both numeric and text-based identification\n",
    "\n",
    "## Next Steps\n",
    "Continue with Notebook {notebook_number + 1} for NYD identification refinement.\n",
    "\"\"\"\n",
    "    \n",
    "    readme_path = checkpoint_dir / \"README.md\"\n",
    "    with open(readme_path, 'w') as f:\n",
    "        f.write(readme_content)\n",
    "    \n",
    "    # Create metadata JSON\n",
    "    metadata = {\n",
    "        'notebook': notebook_number,\n",
    "        'description': description,\n",
    "        'timestamp': timestamp,\n",
    "        'tables': saved_tables,\n",
    "        'changes': changes or [],\n",
    "        'next_notebook': f\"{notebook_number + 1:02d}_NYD_Identification.ipynb\"\n",
    "    }\n",
    "    \n",
    "    metadata_path = checkpoint_dir / \"metadata.json\"\n",
    "    with open(metadata_path, 'w') as f:\n",
    "        json.dump(metadata, f, indent=2, default=str)\n",
    "    \n",
    "    print(f\"\\nCheckpoint saved at: {checkpoint_dir}\")\n",
    "    print(f\"README created: {readme_path}\")\n",
    "    \n",
    "    return checkpoint_dir\n",
    "\n",
    "def link_labs_to_encounters_by_time_optimized(lab_df, encounter_df, window_days=14):\n",
    "    \"\"\"\n",
    "    Highly optimized version of lab-encounter linkage using vectorized operations.\n",
    "    Processes data in larger chunks with efficient patient-based indexing.\n",
    "    \"\"\"\n",
    "    print(\"Implementing optimized time-based lab-encounter linkage...\")\n",
    "    \n",
    "    # Create efficient copy with only necessary columns\n",
    "    result = lab_df.copy()\n",
    "    result['Linked_Encounter_ID'] = None\n",
    "    result['Days_To_Encounter'] = None\n",
    "    result['Linkage_Confidence'] = None\n",
    "    \n",
    "    # Only process labs with missing Encounter_ID but valid dates\n",
    "    labs_to_link = lab_df[\n",
    "        lab_df['PerformedDate'].notna()\n",
    "    ].copy()\n",
    "    \n",
    "    print(f\"Preparing to link {len(labs_to_link):,} labs to encounters\")\n",
    "    \n",
    "    # Create patient index for encounters (do this ONCE)\n",
    "    print(\"Indexing encounters by patient (one-time operation)...\")\n",
    "    valid_encounters = encounter_df[encounter_df['EncounterDate'].notna()].copy()\n",
    "    \n",
    "    # Pre-sort encounters by date for each patient (more efficient lookups)\n",
    "    patient_encounter_dict = {}\n",
    "    for patient_id, group in valid_encounters.groupby('Patient_ID'):\n",
    "        # Pre-sort by date once per patient\n",
    "        patient_encounter_dict[patient_id] = group.sort_values('EncounterDate')\n",
    "    \n",
    "    # Use much larger chunks for better performance\n",
    "    chunk_size = 250000  # Increased from 10,000 to 250,000\n",
    "    chunks = np.array_split(labs_to_link, max(1, len(labs_to_link) // chunk_size))\n",
    "    total_chunks = len(chunks)\n",
    "    \n",
    "    print(f\"Processing {len(labs_to_link):,} labs in {total_chunks} optimized chunks...\")\n",
    "    \n",
    "    linked_count = 0\n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    for chunk_idx, chunk in enumerate(chunks):\n",
    "        chunk_start = datetime.now()\n",
    "        print(f\"Processing chunk {chunk_idx+1}/{total_chunks} ({len(chunk):,} labs)...\")\n",
    "        \n",
    "        # Process each patient's labs as a group (much more efficient)\n",
    "        for patient_id, patient_labs in chunk.groupby('Patient_ID'):\n",
    "            if patient_id not in patient_encounter_dict:\n",
    "                continue\n",
    "                \n",
    "            patient_encounters = patient_encounter_dict[patient_id]\n",
    "            if len(patient_encounters) == 0:\n",
    "                continue\n",
    "            \n",
    "            # Convert encounter dates to numpy array once per patient\n",
    "            encounter_dates = patient_encounters['EncounterDate'].values\n",
    "            encounter_ids = patient_encounters['Encounter_ID'].values\n",
    "            \n",
    "            # Process all labs for this patient with vectorized operations\n",
    "            for idx, lab in patient_labs.iterrows():\n",
    "                if pd.isna(lab['PerformedDate']):\n",
    "                    continue\n",
    "                    \n",
    "                # Calculate days difference using numpy (much faster)\n",
    "                lab_date = np.datetime64(lab['PerformedDate'])\n",
    "                days_diff = np.abs((encounter_dates - lab_date).astype('timedelta64[D]').astype(np.int64))\n",
    "                \n",
    "                # Find matches within window\n",
    "                valid_match_indices = np.where(days_diff <= window_days)[0]\n",
    "                if len(valid_match_indices) == 0:\n",
    "                    continue\n",
    "                \n",
    "                # Find index of minimum days difference\n",
    "                min_idx = valid_match_indices[np.argmin(days_diff[valid_match_indices])]\n",
    "                best_days_diff = days_diff[min_idx]\n",
    "                best_encounter_id = encounter_ids[min_idx]\n",
    "                \n",
    "                # Calculate confidence score (1.0 = same day)\n",
    "                confidence = 1.0 - (best_days_diff / (window_days * 2))\n",
    "                \n",
    "                # Store linkage data efficiently\n",
    "                result.loc[idx, 'Linked_Encounter_ID'] = best_encounter_id\n",
    "                result.loc[idx, 'Days_To_Encounter'] = best_days_diff\n",
    "                result.loc[idx, 'Linkage_Confidence'] = confidence\n",
    "                \n",
    "                linked_count += 1\n",
    "        \n",
    "        chunk_time = (datetime.now() - chunk_start).total_seconds()\n",
    "        labs_per_second = len(chunk) / max(1, chunk_time)\n",
    "        remaining_chunks = total_chunks - (chunk_idx + 1)\n",
    "        est_remaining_time = remaining_chunks * chunk_time / 60  # minutes\n",
    "        \n",
    "        print(f\"  Chunk {chunk_idx+1} processed in {chunk_time:.1f}s ({labs_per_second:.1f} labs/second)\")\n",
    "        print(f\"  Progress: {linked_count:,} labs linked, ~{est_remaining_time:.1f} minutes remaining\")\n",
    "    \n",
    "    # Create effective ID column for downstream analysis\n",
    "    result['Effective_Encounter_ID'] = result['Encounter_ID']\n",
    "    mask = result['Effective_Encounter_ID'].isna() & result['Linked_Encounter_ID'].notna()\n",
    "    result.loc[mask, 'Effective_Encounter_ID'] = result.loc[mask, 'Linked_Encounter_ID']\n",
    "    \n",
    "    total_time = (datetime.now() - start_time).total_seconds() / 60  # minutes\n",
    "    print(f\"Successfully linked {linked_count:,} labs in {total_time:.1f} minutes\")\n",
    "    print(f\"Total labs with encounter association: {result['Effective_Encounter_ID'].notna().sum():,} \"\n",
    "          f\"({result['Effective_Encounter_ID'].notna().sum()/len(result)*100:.2f}%)\")\n",
    "    \n",
    "    return result\n",
    "def enhance_lab_classification_optimized(lab_df):\n",
    "    \"\"\"\n",
    "    Optimized implementation of lab normal/abnormal classification\n",
    "    using vectorized operations for better performance.\n",
    "    \"\"\"\n",
    "    print(\"Enhancing lab classification with optimized approach...\")\n",
    "    \n",
    "    result = lab_df.copy()\n",
    "    total_labs = len(result)\n",
    "    \n",
    "    # Initialize as NA - will fill with True/False\n",
    "    result['is_normal'] = pd.NA\n",
    "    \n",
    "    # Convert TestResult_calc to numeric once (more efficient)\n",
    "    result['result_numeric'] = pd.to_numeric(result['TestResult_calc'], errors='coerce')\n",
    "    \n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    # 1. APPROACH 1: Explicit normal ranges\n",
    "    has_bounds = ~result['LowerNormal'].isna() & ~result['UpperNormal'].isna() & ~result['result_numeric'].isna()\n",
    "    \n",
    "    if has_bounds.any():\n",
    "        print(f\"Processing {has_bounds.sum():,} labs with explicit normal ranges...\")\n",
    "        \n",
    "        # Vectorized conversion (once per field)\n",
    "        lower_numeric = pd.to_numeric(result.loc[has_bounds, 'LowerNormal'], errors='coerce')\n",
    "        upper_numeric = pd.to_numeric(result.loc[has_bounds, 'UpperNormal'], errors='coerce')\n",
    "        \n",
    "        # Check valid bounds and determine normal/abnormal (vectorized)\n",
    "        valid_bounds = ~lower_numeric.isna() & ~upper_numeric.isna()\n",
    "        bounds_indices = has_bounds[has_bounds].index[valid_bounds]\n",
    "        \n",
    "        # Vectorized comparison\n",
    "        result.loc[bounds_indices, 'is_normal'] = (\n",
    "            (result.loc[bounds_indices, 'result_numeric'] >= lower_numeric[valid_bounds]) & \n",
    "            (result.loc[bounds_indices, 'result_numeric'] <= upper_numeric[valid_bounds])\n",
    "        )\n",
    "        \n",
    "        method1_count = valid_bounds.sum()\n",
    "        print(f\"Method 1: Processed {method1_count:,} labs ({method1_count/total_labs*100:.2f}%)\")\n",
    "    \n",
    "    # 2. APPROACH 2: Reference ranges for common tests\n",
    "    common_tests = {\n",
    "        'TOTAL CHOLESTEROL': {'min': 0, 'max': 5.2, 'unit': 'mmol/L'},\n",
    "        'HDL': {'min': 1.0, 'max': 3.0, 'unit': 'mmol/L'},\n",
    "        'LDL': {'min': 0, 'max': 3.4, 'unit': 'mmol/L'},\n",
    "        'TRIGLYCERIDES': {'min': 0, 'max': 1.7, 'unit': 'mmol/L'},\n",
    "        'FASTING GLUCOSE': {'min': 3.9, 'max': 5.6, 'unit': 'mmol/L'},\n",
    "        'HBA1C': {'min': 0, 'max': 5.7, 'unit': '%'},\n",
    "        'TSH': {'min': 0.4, 'max': 4.0, 'unit': 'mIU/L'},\n",
    "        'ALT': {'min': 0, 'max': 40, 'unit': 'U/L'},\n",
    "        'AST': {'min': 0, 'max': 40, 'unit': 'U/L'},\n",
    "        'CREATININE': {'min': 50, 'max': 120, 'unit': 'umol/L'},\n",
    "        'HEMOGLOBIN': {'min': 120, 'max': 160, 'unit': 'g/L'},\n",
    "        'WBC': {'min': 4.0, 'max': 11.0, 'unit': '10^9/L'},\n",
    "        'POTASSIUM': {'min': 3.5, 'max': 5.0, 'unit': 'mmol/L'},\n",
    "        'SODIUM': {'min': 135, 'max': 145, 'unit': 'mmol/L'}\n",
    "    }\n",
    "    \n",
    "    method2_count = 0\n",
    "    # Process all test types at once using a more efficient approach\n",
    "    for test_name, reference in common_tests.items():\n",
    "        # Find pending labs for this test (using case-insensitive string operations)\n",
    "        missing_normal = result['is_normal'].isna()\n",
    "        test_mask = (\n",
    "            result['Name_calc'].str.contains(test_name, case=False, regex=False, na=False) &\n",
    "            ~result['result_numeric'].isna() &\n",
    "            missing_normal\n",
    "        )\n",
    "        \n",
    "        if test_mask.any():\n",
    "            mask_count = test_mask.sum()\n",
    "            method2_count += mask_count\n",
    "            \n",
    "            # Vectorized normal check\n",
    "            result.loc[test_mask, 'is_normal'] = (\n",
    "                (result.loc[test_mask, 'result_numeric'] >= reference['min']) & \n",
    "                (result.loc[test_mask, 'result_numeric'] <= reference['max'])\n",
    "            )\n",
    "    \n",
    "    print(f\"Method 2: Processed {method2_count:,} labs ({method2_count/total_labs*100:.2f}%)\")\n",
    "    \n",
    "    # 3. APPROACH 3: Text pattern search\n",
    "    still_pending = result['is_normal'].isna() & ~result['TestResult_calc'].isna()\n",
    "    method3_count = 0\n",
    "    \n",
    "    if still_pending.any():\n",
    "        # Improved text pattern analysis with exact match phrases (better performance)\n",
    "        # Convert TestResult_calc to string once (for all text operations)\n",
    "        test_result_str = result.loc[still_pending, 'TestResult_calc'].astype(str)\n",
    "        \n",
    "        # Normal patterns\n",
    "        normal_patterns = [\n",
    "            'normal', 'neg', 'negative', 'unremarkable', 'w/in normal', 'within normal', \n",
    "            'wnl', 'within reference', 'not detected', 'n/a'\n",
    "        ]\n",
    "        \n",
    "        # Apply all normal patterns at once (more efficient)\n",
    "        normal_mask = np.zeros(len(test_result_str), dtype=bool)\n",
    "        for pattern in normal_patterns:\n",
    "            pattern_match = test_result_str.str.contains(\n",
    "                f\"\\\\b{pattern}\\\\b\", case=False, regex=True, na=False\n",
    "            )\n",
    "            normal_mask = normal_mask | pattern_match.values\n",
    "        \n",
    "        # Set normal flags\n",
    "        result.loc[still_pending[still_pending].index[normal_mask], 'is_normal'] = True\n",
    "        method3_count += normal_mask.sum()\n",
    "        \n",
    "        # Update pending labs\n",
    "        still_pending = result['is_normal'].isna() & ~result['TestResult_calc'].isna()\n",
    "        \n",
    "        # Apply abnormal patterns to remaining labs\n",
    "        if still_pending.any():\n",
    "            test_result_str = result.loc[still_pending, 'TestResult_calc'].astype(str)\n",
    "            \n",
    "            # Abnormal patterns\n",
    "            abnormal_patterns = [\n",
    "                'abnormal', 'pos', 'positive', 'high', 'low', 'elevated', 'depressed', \n",
    "                'outside', 'detected', 'present'\n",
    "            ]\n",
    "            \n",
    "            # Apply all abnormal patterns at once\n",
    "            abnormal_mask = np.zeros(len(test_result_str), dtype=bool)\n",
    "            for pattern in abnormal_patterns:\n",
    "                pattern_match = test_result_str.str.contains(\n",
    "                    f\"\\\\b{pattern}\\\\b\", case=False, regex=True, na=False\n",
    "                )\n",
    "                abnormal_mask = abnormal_mask | pattern_match.values\n",
    "            \n",
    "            # Set abnormal flags\n",
    "            result.loc[still_pending[still_pending].index[abnormal_mask], 'is_normal'] = False\n",
    "            method3_count += abnormal_mask.sum()\n",
    "    \n",
    "    print(f\"Method 3: Processed {method3_count:,} labs ({method3_count/total_labs*100:.2f}%)\")\n",
    "    \n",
    "    # Calculate overall coverage\n",
    "    classified_count = result['is_normal'].notna().sum()\n",
    "    coverage_pct = classified_count / total_labs * 100\n",
    "    normal_count = (result['is_normal'] == True).sum()  # Explicitly check for True\n",
    "    abnormal_count = (result['is_normal'] == False).sum()  # Explicitly check for False\n",
    "    \n",
    "    total_time = (datetime.now() - start_time).total_seconds()\n",
    "    print(f\"Lab classification completed in {total_time:.1f} seconds\")\n",
    "    print(f\"Overall: Classified {classified_count:,} labs ({coverage_pct:.2f}%)\")\n",
    "    print(f\"Normal: {normal_count:,} ({normal_count/classified_count*100:.2f}% of classified)\")\n",
    "    print(f\"Abnormal: {abnormal_count:,} ({abnormal_count/classified_count*100:.2f}% of classified)\")\n",
    "    \n",
    "    return result\n",
    "def enhance_referral_dates_optimized(referral_df):\n",
    "    \"\"\"\n",
    "    Optimized referral date enhancement using vectorized operations\n",
    "    for better performance.\n",
    "    \"\"\"\n",
    "    print(\"Implementing referral date enhancement (optimized)...\")\n",
    "    \n",
    "    result = referral_df.copy()\n",
    "    total_refs = len(result)\n",
    "    \n",
    "    # Check completion date coverage\n",
    "    missing_completion = result['CompletedDate'].isna()\n",
    "    missing_count = missing_completion.sum()\n",
    "    missing_pct = missing_count / total_refs * 100\n",
    "    \n",
    "    print(f\"CompletedDate missing in {missing_count:,} referrals ({missing_pct:.2f}%)\")\n",
    "    \n",
    "    # Create effective date column and source tracking (vectorized)\n",
    "    result['EffectiveDate'] = result['CompletedDate']\n",
    "    result['DateSource'] = 'CompletedDate'\n",
    "    \n",
    "    # Use vectorized operations for fallback\n",
    "    if missing_count > 0:\n",
    "        # Apply DateCreated fallback where needed (single operation)\n",
    "        result.loc[missing_completion, 'EffectiveDate'] = result.loc[missing_completion, 'DateCreated']\n",
    "        result.loc[missing_completion, 'DateSource'] = 'DateCreated'\n",
    "        \n",
    "        # Check coverage after fallback\n",
    "        remaining_missing = result['EffectiveDate'].isna().sum()\n",
    "        \n",
    "        print(f\"After fallback: {remaining_missing:,} referrals still missing dates ({remaining_missing/total_refs*100:.2f}%)\")\n",
    "        print(f\"Using DateCreated for {missing_count-remaining_missing:,} referrals\")\n",
    "    \n",
    "    # Flag referral status (vectorized operations)\n",
    "    result['ReferralStatus'] = 'Unknown'\n",
    "    \n",
    "    # Completed referrals have CompletedDate (single operation)\n",
    "    result.loc[result['CompletedDate'].notna(), 'ReferralStatus'] = 'Completed'\n",
    "    \n",
    "    # Pending referrals have DateCreated but no CompletedDate (single operation)\n",
    "    pending_mask = (result['CompletedDate'].isna()) & (result['DateCreated'].notna())\n",
    "    result.loc[pending_mask, 'ReferralStatus'] = 'Pending'\n",
    "    \n",
    "    # Count by status\n",
    "    status_counts = result['ReferralStatus'].value_counts()\n",
    "    print(\"\\nReferral Status Distribution:\")\n",
    "    for status, count in status_counts.items():\n",
    "        print(f\"  {status}: {count:,} ({count/total_refs*100:.2f}%)\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "# ---------------------------- Main Execution ------------------------------ #\n",
    "# v1 - ORIGINAL \n",
    "# def main():\n",
    "#     \"\"\"Main execution function to run the full data loading and validation process.\"\"\"\n",
    "#     print_section_header(\"CPCSSN Care4Mind Dataset: Data Loading and Validation\")\n",
    "#     print(f\"Analysis date: {datetime.now().strftime('%Y-%m-%d')}\")\n",
    "   \n",
    "#     # Step 1: Load and perform initial data validation\n",
    "#     data, data_quality = load_and_validate_data()\n",
    "   \n",
    "#     # Step 2: Validate data relationships\n",
    "#     relationship_metrics = validate_data_relationships(data)\n",
    "   \n",
    "#     # Step 3: Validate temporal consistency\n",
    "#     temporal_metrics = validate_temporal_consistency(data)\n",
    "   \n",
    "#     # Step 4: Analyze patient population\n",
    "#     population_metrics = analyze_patient_population(data)\n",
    "   \n",
    "#     # Step 5: Analyze coding patterns\n",
    "#     coding_metrics = analyze_coding_patterns(data)\n",
    "   \n",
    "#     # Step 6: Analyze lab data\n",
    "#     lab_metrics = analyze_lab_data(data)\n",
    "   \n",
    "#     # Step 7: Analyze referral patterns\n",
    "#     referral_metrics = analyze_referral_patterns(data)\n",
    "   \n",
    "#     # Step 8: Save validation results\n",
    "#     validation_report_path = save_validation_results(\n",
    "#         data_quality, relationship_metrics, temporal_metrics,\n",
    "#         population_metrics, coding_metrics, lab_metrics, referral_metrics\n",
    "#     )\n",
    "   \n",
    "#     # Step 9: Save checkpoint for next notebook\n",
    "#     save_checkpoint(data, validation_report_path)\n",
    "   \n",
    "#     print_section_header(\"Data Validation Complete\")\n",
    "#     print(\"✓ Data loaded and validated\")\n",
    "#     print(\"✓ Quality metrics calculated\")\n",
    "#     print(\"✓ Visualizations generated\")\n",
    "#     print(\"✓ Checkpoint saved for next notebook\")\n",
    "   \n",
    "#     print(\"\\nProceed to Notebook 2: NYD Identification\")\n",
    "\n",
    "\n",
    "# V2 - ENHANCED\n",
    "\n",
    "# Updated main function with changes tracked\n",
    "def main():\n",
    "    \"\"\"Main execution with optimized data processing.\"\"\"\n",
    "    print_section_header(\"CPCSSN Care4Mind Dataset: Data Loading and Validation\")\n",
    "    print(f\"Analysis date: {datetime.now().strftime('%Y-%m-%d')}\")\n",
    "    \n",
    "    # Track changes for documentation\n",
    "    changes = []\n",
    "    \n",
    "    # Step 1: Load and validate data\n",
    "    data, data_quality = load_and_validate_data()\n",
    "    \n",
    "    # Step 2-5: Standard validation and analysis\n",
    "    relationship_metrics = validate_data_relationships(data)\n",
    "    temporal_metrics = validate_temporal_consistency(data)\n",
    "    population_metrics = analyze_patient_population(data)\n",
    "    coding_metrics = analyze_coding_patterns(data)\n",
    "    \n",
    "    # Step 6: Enhanced lab processing with optimized implementation\n",
    "    print(\"\\nApplying optimized lab processing...\")\n",
    "    \n",
    "    # Link orphaned labs to encounters using optimized function\n",
    "    original_labs = len(data['lab'])\n",
    "    data['lab'] = link_labs_to_encounters_by_time_optimized(data['lab'], data['encounter'])\n",
    "    changes.append(f\"Linked orphaned labs to encounters through temporal proximity (optimized)\")\n",
    "    \n",
    "    # Enhance normal lab classification using optimized function\n",
    "    data['lab'] = enhance_lab_classification_optimized(data['lab'])\n",
    "    changes.append(\"Expanded normal lab detection from 14% to ~45% using multiple methods (optimized)\")\n",
    "    \n",
    "    # Continue with regular lab analysis\n",
    "    lab_metrics = analyze_lab_data(data)\n",
    "    \n",
    "    # Step 7: Enhanced referral processing with optimized implementation\n",
    "    print(\"\\nApplying optimized referral processing...\")\n",
    "    data['referral'] = enhance_referral_dates_optimized(data['referral'])\n",
    "    changes.append(\"Implemented referral date fallbacks and status tracking (optimized)\")\n",
    "    \n",
    "    # Continue with regular referral analysis\n",
    "    referral_metrics = analyze_referral_patterns(data)\n",
    "    \n",
    "    # Step 8: Save validation with corrected NYD reporting\n",
    "    validation_report_path = save_validation_results(\n",
    "        data_quality, relationship_metrics, temporal_metrics, \n",
    "        population_metrics, coding_metrics, lab_metrics, referral_metrics\n",
    "    )\n",
    "    changes.append(\"Fixed NYD code reporting in validation summary\")\n",
    "    \n",
    "    # Step 9: Save comprehensive checkpoint\n",
    "    checkpoint_dir = save_checkpoint_with_documentation(\n",
    "        data,\n",
    "        notebook_number=1,\n",
    "        description=\"Data Loading and Validation with Optimized Processing\",\n",
    "        changes=changes\n",
    "    )\n",
    "    \n",
    "    print_section_header(\"Optimized Data Validation Complete\")\n",
    "    print(\"✓ Data loaded and validated with fixes\")\n",
    "    print(\"✓ NYD code reporting corrected\")\n",
    "    print(\"✓ Lab-encounter temporal linkage implemented (optimized)\")\n",
    "    print(\"✓ Normal lab detection significantly expanded (optimized)\")\n",
    "    print(\"✓ Referral date handling improved (optimized)\")\n",
    "    print(\"✓ Comprehensive documentation created\")\n",
    "    \n",
    "    print(f\"\\nProceed to Notebook 2: NYD_Identification.ipynb\")\n",
    "    print(f\"Load data from: {checkpoint_dir}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
