{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1: Causal Effect of Negative Lab Tests on Healthcare Utilization Mediated by SSD Severity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nSSD Causal Analysis Protocol\\nVersion: 1.0\\nDate: February 24, 2025\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 00_setup_and_protocol.ipynb\n",
    "\"\"\"\n",
    "SSD Causal Analysis Protocol\n",
    "Version: 1.0\n",
    "Date: February 24, 2025\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing pyyaml...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "#%% [markdown]\n",
    "# # 1. Environment Setup and Validation\n",
    "\n",
    "#%%\n",
    "# First, let's check and install required packages\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "def ensure_dependencies():\n",
    "    \"\"\"Install required packages if not present\"\"\"\n",
    "    required_packages = {\n",
    "        'pandas': 'pandas',\n",
    "        'numpy': 'numpy',\n",
    "        'matplotlib': 'matplotlib',\n",
    "        'seaborn': 'seaborn',\n",
    "        'pyyaml': 'pyyaml'\n",
    "    }\n",
    "    \n",
    "    for package, pip_name in required_packages.items():\n",
    "        try:\n",
    "            __import__(package)\n",
    "        except ImportError:\n",
    "            print(f\"Installing {package}...\")\n",
    "            subprocess.check_call([sys.executable, '-m', 'pip', 'install', pip_name])\n",
    "            print(f\"Done\")\n",
    "        \n",
    "\n",
    "\n",
    "ensure_dependencies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#%%\n",
    "# Core imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display, Markdown, HTML\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "# Set up basic configuration\n",
    "def setup_environment():\n",
    "    \"\"\"Configure the notebook environment\"\"\"\n",
    "    # Set random seed\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Configure pandas display\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.max_rows', 100)\n",
    "    \n",
    "    # Configure matplotlib\n",
    "    plt.style.use('default')  # Using default style instead of seaborn\n",
    "    \n",
    "    # Set up logging\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format='%(asctime)s - %(levelname)s - %(message)s'\n",
    "    )\n",
    "    \n",
    "    return logging.getLogger(__name__)\n",
    "\n",
    "logger = setup_environment()\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-24 02:44:01,041 - INFO - Created directory: ../data\n",
      "2025-02-24 02:44:01,041 - INFO - Created directory: ../results\n",
      "2025-02-24 02:44:01,041 - INFO - Created directory: ../figures\n",
      "2025-02-24 02:44:01,041 - INFO - Created directory: ../logs\n",
      "2025-02-24 02:44:01,074 - INFO - Loaded configuration from file\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#%%\n",
    "# Project structure setup\n",
    "def setup_project_structure():\n",
    "    \"\"\"Create necessary project directories\"\"\"\n",
    "    directories = [\n",
    "        '../data',\n",
    "        '../results',\n",
    "        '../figures',\n",
    "        '../logs'\n",
    "    ]\n",
    "    \n",
    "    for directory in directories:\n",
    "        Path(directory).mkdir(parents=True, exist_ok=True)\n",
    "        logger.info(f\"Created directory: {directory}\")\n",
    "\n",
    "setup_project_structure()\n",
    "\n",
    "#%%\n",
    "# Load and validate configuration\n",
    "def load_config() -> Dict:\n",
    "    \"\"\"\n",
    "    Load study configuration\n",
    "    \n",
    "    Returns:\n",
    "        Dict: Configuration settings\n",
    "    \"\"\"\n",
    "    # Default configuration if file doesn't exist\n",
    "    default_config = {\n",
    "        'data_paths': {\n",
    "            'raw_data': r'C:\\Users\\ProjectC4M\\Documents\\CPCSSN Datasets Care4Mind\\New Extraction Feb 2025\\extracted_data',\n",
    "            'prepared_data': '../100k_sample'\n",
    "        },\n",
    "        'study_parameters': {\n",
    "            'baseline_period': '2018-01-01',\n",
    "            'follow_up_period': '2020-12-31',\n",
    "            'min_age': 18,\n",
    "            'max_age': 85\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    config_path = Path('../config/config.yaml')\n",
    "    \n",
    "    try:\n",
    "        if config_path.exists():\n",
    "            with open(config_path) as f:\n",
    "                config = yaml.safe_load(f)\n",
    "            logger.info(\"Loaded configuration from file\")\n",
    "        else:\n",
    "            config = default_config\n",
    "            with open(config_path, 'w') as f:\n",
    "                yaml.dump(config, f)\n",
    "            logger.info(\"Created default configuration file\")\n",
    "            \n",
    "        return config\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Configuration error: {str(e)}\")\n",
    "        return default_config\n",
    "\n",
    "config = load_config()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "    # Causal Effect of Negative Lab Tests on Healthcare Utilization\n",
       "    \n",
       "    **Version:** 1.0  \n",
       "    **Date:** 2025-02-24  \n",
       "    **Study ID:** SSD-CPCSSN-2025-001\n",
       "    \n",
       "    ## Time Windows\n",
       "    \n",
       "**Baseline:** 2018-01-01 to 2018-06-30\n",
       "**Treatment:** 2018-07-01 to 2019-06-30\n",
       "**Outcome:** 2019-07-01 to 2020-06-30\n",
       "\n",
       "## Variables\n",
       "\n",
       "### Treatment: Negative Lab Cascade\n",
       "- **Type:** binary\n",
       "\n",
       "### Mediator: SSD Severity Score\n",
       "- **Type:** continuous (0-100)\n",
       "- **Components:**\n",
       "  * Symptom code frequency (ICD-9: 780-789)\n",
       "  * Visit patterns for unexplained symptoms\n",
       "  * Anxiety/depression indicators\n",
       "\n",
       "### Outcome: Healthcare Utilization\n",
       "- **Type:** count\n",
       "- **Metrics:**\n",
       "  * Total encounters\n",
       "  * ED visits\n",
       "  * Specialist referrals\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking files in: C:\\Users\\ProjectC4M\\Documents\\CPCSSN Datasets Care4Mind\\New Extraction Feb 2025\\SSD_Experiment1_Causal_Effect\\100k_sample\n",
      "Looking for file: C:\\Users\\ProjectC4M\\Documents\\CPCSSN Datasets Care4Mind\\New Extraction Feb 2025\\SSD_Experiment1_Causal_Effect\\100k_sample\\PatientDemographic_merged_prepared.csv\n",
      "Looking for file: C:\\Users\\ProjectC4M\\Documents\\CPCSSN Datasets Care4Mind\\New Extraction Feb 2025\\SSD_Experiment1_Causal_Effect\\100k_sample\\Lab_prepared.csv\n",
      "Looking for file: C:\\Users\\ProjectC4M\\Documents\\CPCSSN Datasets Care4Mind\\New Extraction Feb 2025\\SSD_Experiment1_Causal_Effect\\100k_sample\\Encounter_prepared.csv\n",
      "Looking for file: C:\\Users\\ProjectC4M\\Documents\\CPCSSN Datasets Care4Mind\\New Extraction Feb 2025\\SSD_Experiment1_Causal_Effect\\100k_sample\\EncounterDiagnosis_prepared.csv\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## Data Validation Results\n",
       "\n",
       "### PatientDemographic_merged_prepared.csv\n",
       "**Status:** Available\n",
       "\n",
       "- Size: 11.35 MB\n",
       "- Last Modified: 2025-02-20 19:36:06\n",
       "- Columns:\n",
       "  * PatientDemographic_ID\n",
       "  * Network_ID\n",
       "  * Site_ID\n",
       "  * Patient_ID\n",
       "  * Cycle_ID\n",
       "  * Occupation\n",
       "  * HighestEducation\n",
       "  * HousingStatus\n",
       "  * ResidencePostalCode\n",
       "  * PatientStatus_orig\n",
       "  * PatientStatus_calc\n",
       "  * Language\n",
       "  * Ethnicity\n",
       "  * DeceasedYear\n",
       "  * DateCreated\n",
       "  * BirthYear\n",
       "  * BirthMonth\n",
       "  * OptedOut\n",
       "  * OptOutDate\n",
       "  * Sex\n",
       "\n",
       "---\n",
       "### Lab_prepared.csv\n",
       "**Status:** Available\n",
       "\n",
       "- Size: 0.16 MB\n",
       "- Last Modified: 2025-02-20 18:43:49\n",
       "- Columns:\n",
       "  * Lab_ID\n",
       "  * Network_ID\n",
       "  * Site_ID\n",
       "  * Patient_ID\n",
       "  * Encounter_ID\n",
       "  * Cycle_ID\n",
       "  * PerformedDate\n",
       "  * Name_orig\n",
       "  * Name_calc\n",
       "  * CodeType_orig\n",
       "  * CodeType_calc\n",
       "  * Code_orig\n",
       "  * Code_calc\n",
       "  * TestResult_orig\n",
       "  * TestResult_calc\n",
       "  * UpperNormal\n",
       "  * LowerNormal\n",
       "  * NormalRange\n",
       "  * UnitOfMeasure_orig\n",
       "  * UnitOfMeasure_calc\n",
       "  * DateCreated\n",
       "\n",
       "---\n",
       "### Encounter_prepared.csv\n",
       "**Status:** Available\n",
       "\n",
       "- Size: 390.9 MB\n",
       "- Last Modified: 2025-02-20 18:43:33\n",
       "- Columns:\n",
       "  * Encounter_ID\n",
       "  * Network_ID\n",
       "  * Site_ID\n",
       "  * Patient_ID\n",
       "  * Provider_ID\n",
       "  * Cycle_ID\n",
       "  * EncounterDate\n",
       "  * Reason_orig\n",
       "  * Reason_calc\n",
       "  * EncounterType\n",
       "  * DateCreated\n",
       "\n",
       "---\n",
       "### EncounterDiagnosis_prepared.csv\n",
       "**Status:** Available\n",
       "\n",
       "- Size: 504.88 MB\n",
       "- Last Modified: 2025-02-20 18:43:45\n",
       "- Columns:\n",
       "  * EncounterDiagnosis_ID\n",
       "  * Network_ID\n",
       "  * Site_ID\n",
       "  * Patient_ID\n",
       "  * Encounter_ID\n",
       "  * Cycle_ID\n",
       "  * DiagnosisText_orig\n",
       "  * DiagnosisText_calc\n",
       "  * DiagnosisCodeType_orig\n",
       "  * DiagnosisCodeType_calc\n",
       "  * DiagnosisCode_orig\n",
       "  * DiagnosisCode_calc\n",
       "  * DateCreated\n",
       "\n",
       "---\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "## Power Analysis Results\n",
       "\n",
       "Required sample size: **235** patients\n",
       "\n",
       "### Parameters:\n",
       "- Alpha (Type I error rate): 0.05\n",
       "- Power: 0.8\n",
       "- Expected effect size: 0.2\n",
       "- Attrition adjustment: 20%\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-24 02:44:01,131 - INFO - Saved study documentation to ..\\results\\study_documentation_20250224_024401.yaml\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "## Next Steps\n",
       "\n",
       "1. Proceed to data preprocessing (`01_data_validation.ipynb`):\n",
       "   - Apply inclusion/exclusion criteria\n",
       "   - Handle missing data\n",
       "   - Create analysis dataset\n",
       "\n",
       "2. Feature engineering (`02_feature_engineering.ipynb`):\n",
       "   - Construct negative lab cascade indicator\n",
       "   - Build SSD severity score\n",
       "   - Calculate healthcare utilization metrics\n",
       "\n",
       "3. Causal analysis (`03_causal_analysis.ipynb`):\n",
       "   - Implement DoWhy mediation analysis\n",
       "   - Conduct sensitivity analyses\n",
       "   - Generate results\n",
       "\n",
       "Remember to commit this notebook and documentation to version control before proceeding.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#%% [markdown]\n",
    "# # 2. Study Protocol Documentation\n",
    "#%%\n",
    "# Study Protocol Documentation\n",
    "protocol = {\n",
    "    \"title\": \"Causal Effect of Negative Lab Tests on Healthcare Utilization\",\n",
    "    \"version\": \"1.0\",\n",
    "    \"date\": \"2025-02-24\",\n",
    "    \"study_id\": \"SSD-CPCSSN-2025-001\",\n",
    "    \n",
    "    \"temporal_windows\": {\n",
    "        \"baseline\": \"2018-01-01 to 2018-06-30\",\n",
    "        \"treatment\": \"2018-07-01 to 2019-06-30\",\n",
    "        \"outcome\": \"2019-07-01 to 2020-06-30\"\n",
    "    },\n",
    "    \n",
    "    \"variables\": {\n",
    "        \"treatment\": {\n",
    "            \"name\": \"Negative Lab Cascade\",\n",
    "            \"definition\": \"≥3 normal lab results in 12 months\",\n",
    "            \"type\": \"binary\",\n",
    "            \"source\": \"Lab_prepared.csv\"\n",
    "        },\n",
    "        \"mediator\": {\n",
    "            \"name\": \"SSD Severity Score\",\n",
    "            \"components\": [\n",
    "                \"Symptom code frequency (ICD-9: 780-789)\",\n",
    "                \"Visit patterns for unexplained symptoms\",\n",
    "                \"Anxiety/depression indicators\"\n",
    "            ],\n",
    "            \"type\": \"continuous (0-100)\"\n",
    "        },\n",
    "        \"outcome\": {\n",
    "            \"name\": \"Healthcare Utilization\",\n",
    "            \"metrics\": [\n",
    "                \"Total encounters\",\n",
    "                \"ED visits\",\n",
    "                \"Specialist referrals\"\n",
    "            ],\n",
    "            \"type\": \"count\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "#%%\n",
    "# Display protocol in formatted markdown\n",
    "def display_protocol(protocol: Dict):\n",
    "    \"\"\"\n",
    "    Create formatted display of study protocol\n",
    "    \"\"\"\n",
    "    md_text = f\"\"\"\n",
    "    # {protocol['title']}\n",
    "    \n",
    "    **Version:** {protocol['version']}  \n",
    "    **Date:** {protocol['date']}  \n",
    "    **Study ID:** {protocol['study_id']}\n",
    "    \n",
    "    ## Time Windows\n",
    "    \"\"\"\n",
    "    \n",
    "    for period, window in protocol['temporal_windows'].items():\n",
    "        md_text += f\"\\n**{period.title()}:** {window}\"\n",
    "    \n",
    "    md_text += \"\\n\\n## Variables\\n\"\n",
    "    \n",
    "    for var_type, details in protocol['variables'].items():\n",
    "        md_text += f\"\\n### {var_type.title()}: {details['name']}\\n\"\n",
    "        md_text += f\"- **Type:** {details['type']}\\n\"\n",
    "        \n",
    "        if 'components' in details:\n",
    "            md_text += \"- **Components:**\\n\"\n",
    "            for comp in details['components']:\n",
    "                md_text += f\"  * {comp}\\n\"\n",
    "        \n",
    "        if 'metrics' in details:\n",
    "            md_text += \"- **Metrics:**\\n\"\n",
    "            for metric in details['metrics']:\n",
    "                md_text += f\"  * {metric}\\n\"\n",
    "\n",
    "    display(Markdown(md_text))\n",
    "\n",
    "display_protocol(protocol)\n",
    "\n",
    "#%% [markdown]\n",
    "# # 3. Data Validation Check\n",
    "\n",
    "#%%\n",
    "def check_required_files():\n",
    "    \"\"\"\n",
    "    Verify existence and basic properties of required files\n",
    "    \"\"\"\n",
    "    required_files = [\n",
    "        'PatientDemographic_merged_prepared.csv',\n",
    "        'Lab_prepared.csv',\n",
    "        'Encounter_prepared.csv',\n",
    "        'EncounterDiagnosis_prepared.csv'\n",
    "    ]\n",
    "    \n",
    "    results = {}\n",
    "    data_path = Path(config['data_paths']['prepared_data'])\n",
    "\n",
    "    # First check if the directory exists\n",
    "    if not data_path.exists():\n",
    "        print(f\"Directory does not exist: {data_path}\")\n",
    "        return results\n",
    "        \n",
    "    print(f\"Checking files in: {data_path}\")\n",
    "    \n",
    "    for file in required_files:\n",
    "        try:\n",
    "            file_path = data_path / file\n",
    "            print(f\"Looking for file: {file_path}\")\n",
    "            \n",
    "            if file_path.exists():\n",
    "                # Read first few rows to check structure\n",
    "                df = pd.read_csv(file_path, nrows=5)\n",
    "                \n",
    "                results[file] = {\n",
    "                    'status': 'Available',\n",
    "                    'size_mb': round(file_path.stat().st_size / (1024 * 1024), 2),\n",
    "                    'columns': list(df.columns),\n",
    "                    'last_modified': datetime.fromtimestamp(\n",
    "                        file_path.stat().st_mtime\n",
    "                    ).strftime('%Y-%m-%d %H:%M:%S')\n",
    "                }\n",
    "            else:\n",
    "                results[file] = {'status': 'Missing'}\n",
    "                \n",
    "        except Exception as e:\n",
    "            results[file] = {'status': 'Error', 'message': str(e)}\n",
    "    \n",
    "    return results\n",
    "\n",
    "#%%\n",
    "# Run data validation check\n",
    "validation_results = check_required_files()\n",
    "\n",
    "# Display results in a formatted table\n",
    "def display_validation_results(results: Dict):\n",
    "    \"\"\"Create formatted display of validation results\"\"\"\n",
    "    md_text = \"## Data Validation Results\\n\\n\"\n",
    "    \n",
    "    for file, details in results.items():\n",
    "        md_text += f\"### {file}\\n\"\n",
    "        md_text += f\"**Status:** {details['status']}\\n\\n\"\n",
    "        \n",
    "        if details['status'] == 'Available':\n",
    "            md_text += f\"- Size: {details['size_mb']} MB\\n\"\n",
    "            md_text += f\"- Last Modified: {details['last_modified']}\\n\"\n",
    "            md_text += \"- Columns:\\n\"\n",
    "            for col in details['columns']:\n",
    "                md_text += f\"  * {col}\\n\"\n",
    "        elif details['status'] == 'Error':\n",
    "            md_text += f\"Error: {details['message']}\\n\"\n",
    "            \n",
    "        md_text += \"\\n---\\n\"\n",
    "    \n",
    "    display(Markdown(md_text))\n",
    "\n",
    "display_validation_results(validation_results)\n",
    "\n",
    "#%% [markdown]\n",
    "# # 4. Power Analysis\n",
    "\n",
    "#%%\n",
    "def calculate_sample_size():\n",
    "    \"\"\"\n",
    "    Calculate required sample size for causal mediation analysis\n",
    "    Based on Fritz & MacKinnon (2007)\n",
    "    \"\"\"\n",
    "    alpha = 0.05  # Type I error rate\n",
    "    power = 0.80  # Desired power\n",
    "    effect_size = 0.20  # Expected effect size\n",
    "    \n",
    "    # Sample size calculation for mediation\n",
    "    from scipy.stats import norm\n",
    "    \n",
    "    z_alpha = norm.ppf(1 - alpha/2)\n",
    "    z_beta = norm.ppf(power)\n",
    "    \n",
    "    n_raw = ((z_alpha + z_beta)**2) / effect_size**2\n",
    "    n_adjusted = int(n_raw * 1.2)  # Adding 20% for attrition\n",
    "    \n",
    "    results = {\n",
    "        'required_n': n_adjusted,\n",
    "        'parameters': {\n",
    "            'alpha': alpha,\n",
    "            'power': power,\n",
    "            'effect_size': effect_size,\n",
    "            'attrition_adjustment': '20%'\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "#%%\n",
    "# Run power analysis\n",
    "power_results = calculate_sample_size()\n",
    "\n",
    "# Display results\n",
    "power_md = f\"\"\"\n",
    "## Power Analysis Results\n",
    "\n",
    "Required sample size: **{power_results['required_n']}** patients\n",
    "\n",
    "### Parameters:\n",
    "- Alpha (Type I error rate): {power_results['parameters']['alpha']}\n",
    "- Power: {power_results['parameters']['power']}\n",
    "- Expected effect size: {power_results['parameters']['effect_size']}\n",
    "- Attrition adjustment: {power_results['parameters']['attrition_adjustment']}\n",
    "\"\"\"\n",
    "\n",
    "display(Markdown(power_md))\n",
    "\n",
    "#%% [markdown]\n",
    "# # 5. Save Protocol and Setup Log\n",
    "\n",
    "#%%\n",
    "def save_study_documentation():\n",
    "    \"\"\"\n",
    "    Save all study documentation and setup information\n",
    "    \"\"\"\n",
    "    import matplotlib\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    \n",
    "    # Create documentation dictionary\n",
    "    documentation = {\n",
    "        'protocol': protocol,\n",
    "        'power_analysis': power_results,\n",
    "        'data_validation': validation_results,\n",
    "        'environment': {\n",
    "            'python_version': sys.version,\n",
    "            'key_packages': {\n",
    "                'pandas': pd.__version__,\n",
    "                'numpy': np.__version__,\n",
    "                'matplotlib': matplotlib.__version__\n",
    "            },\n",
    "            'execution_date': timestamp\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Save as YAML\n",
    "    doc_path = Path('../results') / f'study_documentation_{timestamp}.yaml'\n",
    "    with open(doc_path, 'w') as f:\n",
    "        yaml.dump(documentation, f)\n",
    "    \n",
    "    logger.info(f\"Saved study documentation to {doc_path}\")\n",
    "    \n",
    "    return doc_path\n",
    "\n",
    "doc_path = save_study_documentation()\n",
    "\n",
    "#%% [markdown]\n",
    "# # 6. Next Steps\n",
    "\n",
    "#%%\n",
    "next_steps = \"\"\"\n",
    "## Next Steps\n",
    "\n",
    "1. Proceed to data preprocessing (`01_data_validation.ipynb`):\n",
    "   - Apply inclusion/exclusion criteria\n",
    "   - Handle missing data\n",
    "   - Create analysis dataset\n",
    "\n",
    "2. Feature engineering (`02_feature_engineering.ipynb`):\n",
    "   - Construct negative lab cascade indicator\n",
    "   - Build SSD severity score\n",
    "   - Calculate healthcare utilization metrics\n",
    "\n",
    "3. Causal analysis (`03_causal_analysis.ipynb`):\n",
    "   - Implement DoWhy mediation analysis\n",
    "   - Conduct sensitivity analyses\n",
    "   - Generate results\n",
    "\n",
    "Remember to commit this notebook and documentation to version control before proceeding.\n",
    "\"\"\"\n",
    "\n",
    "display(Markdown(next_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
