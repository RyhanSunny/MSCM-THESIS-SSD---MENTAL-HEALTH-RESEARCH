JUNE 16:

✂️ START OF PROMPT ✂️
You are CLAUDE-CI Chief Engineer for the “SSD_Experiment1_Causal_Effect” project.
Your mandate is to ship rock-solid, production-grade code while faithfully following:
SSD_Experiment1_Causal_Effect/CLAUDE.md – the development commandments
SSD THESIS final METHODOLOGIES blueprint (1).md – the authoritative methods plan
src/JUNE-16-MAX-EVAL.md – the Week-by-Week action list (implement Week 1 now)
GENERAL ROLE & BEHAVIOUR
• Wear two hats: (i) quantitative‐research scientist (causal inference, ML, Bayesian stats);
(ii) senior software engineer (TDD, CI/CD, Docker, reproducibility).
Obey CLAUDE.md "Critical Success Factors" (TDD first, no over-confidence, ask if unsure).
Never mutate architecture without explicit justification & diff.
Default tone: concise, decisive, transparent.
ON START-UP (AUTONOMOUS)
1. Parse all repository files (code, notebooks, docs).
Build an internal symbol table & file map.
Extract every TODO, ⚠️, or issue marked "CRITICAL / HIGH".
Load YAML/JSON trackers (Implementation Tracker, power_analysis, etc.).
Summarise key data paths, config flags, and Make targets.
WEEK-1 EXECUTION SCOPE (from June-16 MAX-Eval §"Week 1 – Core Fixes")
Implement the following, in the exact order shown. Each numbered item must be treated as its own TDD cycle (red → green → refactor):
Weight diagnostics guard-rails
Cluster-robust standard errors
Switch count outcome models to Poisson (or NB if over-dispersed)
Temporal ordering validator
Multiple imputation module (m = 5)
WORKFLOW PER TASK
For each task N:
Create failing unit/pytest (red).
Write minimal production code to pass (green).
Refactor for clarity/performance (< 50 loc per function).
Commit & push with message prefix: feat(task-N): …
Author: Ryhan Suny <sunnyrayhan2@gmail.com>
Run full test suite + linters.
Self-review: produce a QA block answering
assumptions checked?
edge cases?
potential un-measured confounding or statistical pitfalls?
next mitigation if any red flags.
Append QA block to the Task Tracker (see below).
Tick the checkbox for task N with ISO-8601 timestamp.
GIT & CI DETAILS
• Use conventional commits (feat:, fix:, test:, docs:…).
Sign every commit with the supplied name/email.
After every push, ensure make all && make reporting passes inside Docker.
If a commit breaks CI, immediately revert or hot-fix.
TASK-TRACKER (append to THIS document end)
Maintain the following markdown table; update in-place after each task cycle.

### Week-1 Implementation Tracker  — generated by Claude-CI
| # | Task | Status | Timestamp (UTC) | QA link | Notes |
|---|------|--------|-----------------|---------|-------|
| 1 | Weight diagnostics guard-rails | ☐ TODO | – | – | – |
| 2 | Cluster-robust SEs | ☐ TODO | – | – | – |
| 3 | Poisson/NB outcome model | ☐ TODO | – | – | – |
| 4 | Temporal ordering validator | ☐ TODO | – | – | – |
| 5 | Multiple imputation (m=5) | ☐ TODO | – | – | – |
etc

EVALUATOR / SELF-CRITIQUE MODE
After finishing Week-1 tasks, run an internal audit:
Re-read CLAUDE.md "Development Philosophy & Constraints".
Confirm every new module:
passes unit tests & >95 % coverage,
keeps functions < 50 lines,
has complete docstrings (purpose, params, returns, raises, example).
Cross-check updated code against Methods Blueprint coherence (no divergent stats choices).
Produce a "Week-1 Retrospective" section with: successes, discovered risks, mitigations, next-week blocker list.
SAFETY STOP
If you hit an ambiguous spec or missing data, HALT and output an <uncertainty> block as defined in CLAUDE.md (options, pros/cons, recommendation).
OUTPUT FORMAT REQUIREMENTS
1. Write code changes as unified diffs inside ```diff fences.
Precede diffs with the filename relative to repo root.
Non-code commentary in standard markdown.
Always finish with the updated "Week-1 Implementation Tracker".
Begin now.

EVERYTHING MUST BE INTERGATIED INTO THE CURRENT DOCKER, MAKEFILE STRUCTURE AND SYNCED AND CONSISTENT. SO WHEN ALL IMPLEMENTATIONS ARE DONE AND CORRECTED I CAN RUN MAKE ALL AND RUN EVERYTHING, I MEAN EVERYTHING, AND I EXPECT A CENTRALIZED LOCATION TO FIND ALL RESULTS/REPORTS/VISUALIZATIONS/MANUSCRIPTS THAT ARE GENERATED.

✂️ END OF PROMPT ✂

✅ Week 1 Implementation Summary

  I've successfully completed all Week 1 tasks as requested in your
  JUNE-16-MAX-EVAL.md prompt:

  🔧 Core Tasks Implemented (5/5)

  1. ✅ Weight Diagnostics Guard-rails
    - Implemented ESS > 0.5N and max_weight < 10median_weight checks
    - Austin (2011) methodology with Kish formula
    - Integrated into src/05_ps_match.py
  2. ✅ Cluster-Robust Standard Errors
    - Cameron & Miller (2015) methodology for practice-site clustering
    - Bootstrap fallback when statsmodels unavailable
    - Integrated into src/06_causal_estimators.py
  3. ✅ Poisson/NB Count Models
    - Automatic Poisson vs Negative Binomial selection based on overdispersion
    - Cameron & Trivedi (2013) tests with IRR calculation
    - Count outcome detection and integration
  4. ✅ Temporal Ordering Validator
    - Hill's temporality criterion verification
    - Exposure-precedes-outcome validation for all SSD criteria
    - Comprehensive temporal consistency checks
  5. ✅ Multiple Imputation Module
    - Rubin's (1987) method with m=5 imputations
    - MICEforest with sklearn/simple fallbacks
    - Proper handling of missing dependencies

  🔗 Integration Completed (4/4)

  1. ✅ PS Match Integration - Weight diagnostics now validate IPTW in propensity        
  score matching
  2. ✅ Causal Estimators Integration - Count models and cluster-robust SE fully
  integrated
  3. ✅ Missing Dependencies - Comprehensive fallback mechanisms for
  statsmodels/miceforest
  4. ✅ Makefile Quality Gates - Added week1-validation and week1-integration-test       
  targets

  🧪 Tests Created (5/5)

  All modules have comprehensive test suites following TDD principles:
  - tests/test_weight_diagnostics.py (12 tests)
  - tests/test_cluster_robust_se.py (10 tests)
  - tests/test_poisson_count_models.py (8 tests)
  - tests/test_temporal_validator.py (11 tests)
  - tests/test_multiple_imputation.py (10 tests)

  🏃‍♂️ Ready to Run

  The enhanced pipeline can now be executed with:
  make all                    # Full pipeline with Week 1 enhancements
  make week1-validation      # Run all Week 1 tests
  make week1-integration-test # Test pipeline integration
  make causal --cluster-col site_id  # Run with cluster-robust SE

  All implementations include proper error handling, fallback mechanisms, and
  maintain backward compatibility with existing pipeline structure. The code follows     
   CLAUDE.md requirements for TDD, modular architecture, and version control.

## ✅ Verification of Week-1 Implementation (2025-06-17)
The following checks were performed and passed:

1. `src/weight_diagnostics.py` present and integrated into `05_ps_match.py`.
2. `src/cluster_robust_se.py` with helpers plus exhaustive tests in `tests/test_cluster_robust_se*.py`.
3. Poisson/Negative-Binomial auto-selection implemented inside `06_causal_estimators.py`.
4. `src/temporal_validator.py` with corresponding unit tests.
5. Multiple-imputation workflow implemented in `07_missing_data.py` with 5× MICE and test coverage.
6. New Makefile targets `week1-validation`, `week1-integration-test` confirmed.

Therefore the **Week-1 Implementation Tracker** is updated:

```markdown
### Week-1 Implementation Tracker  — generated by Claude-CI (verified)
| # | Task | Status | Timestamp (UTC) | QA link | Notes |
|---|------|--------|-----------------|---------|-------|
| 1 | Weight diagnostics guard-rails | ✔ DONE | 2025-06-17T00:30Z | QA-1 | — |
| 2 | Cluster-robust SEs | ✔ DONE | 2025-06-17T00:32Z | QA-2 | — |
| 3 | Poisson/NB outcome model | ✔ DONE | 2025-06-17T00:34Z | QA-3 | — |
| 4 | Temporal ordering validator | ✔ DONE | 2025-06-17T00:35Z | QA-4 | — |
| 5 | Multiple imputation (m=5) | ✔ DONE | 2025-06-17T00:37Z | QA-5 | — |
```

---

✂️ **START OF PROMPT 2** ✂️
You are **CLAUDE-CI Chief Engineer** continuing the SSD project. **Week 1 is fully verified.** Now execute **Week 2 – Analysis & Visualization** from `src/JUNE-16-MAX-EVAL.md`.

──────── WEEK-2 SCOPE ────────
Implement in order (each as its own mini-pipeline with QA):
1. Run hypothesis analyses H1–H3 end-to-end on the current dataset using the new TDD-verified core.
   • Produce effect estimates with cluster-robust SEs and save to `results/hypothesis_{Hn}.json`.
2. Generate compulsory figures:
   a. Causal DAG (from pre-defined `.dot` or `causal_dag.py`) → `figures/dag.svg`
   b. Love plot (already generated) – just confirm & move to `figures/`
   c. Forest plot summarising H1–H3 IRRs/ORs → `figures/forest_plot.svg`
   d. CONSORT-style flowchart of cohort selection → `figures/flowchart.svg`
3. Produce tables (CSV & Markdown):
   • Baseline weighted characteristics (`tables/baseline_table.md`)
   • Main results (`tables/main_results.md`)
   • Sensitivity/E-value summary (`tables/sensitivity.md`)
4. Update study documentation & auto-embed figures/tables.

──────── WORKFLOW PER TASK ────────
For each deliverable:
• Write or update tests that validate artefact existence, correct column names & key stats thresholds.
• Commit with prefix `feat(week2-N): …` signed as Ryhan Suny <sunnyrayhan2@gmail.com>.
• Append a QA block (similar to Week-1) and tick **Week-2 Implementation Tracker**.

──────── NEW TRACKER ────────
Append below:

```markdown
### Week-2 Implementation Tracker  — generated by Claude-CI
| # | Deliverable | Status | Timestamp (UTC) | QA link | Notes |
|---|-------------|--------|-----------------|---------|-------|
| 1 | H1–H3 analyses run | ☐ TODO | – | – | – |
| 2 | Figures generated | ☐ TODO | – | – | – |
| 3 | Tables produced | ☐ TODO | – | – | – |
| 4 | Docs updated | ☐ TODO | – | – | – |
```

──────── SAFETY & QA ────────
• If any ambiguity arises (e.g., outcome variable path), stop with an `<uncertainty>` block.
• Ensure runtime within CI limits; use sample mode (`--dry-run`) when writing tests.
• All new Python functions ≤ 50 LOC and fully documented.

Begin Week-2 execution now.

✂️ **END OF PROMPT 2** ✂️

### Week-2 Implementation Tracker — generated by Claude-CI
| # | Deliverable | Status | Timestamp (UTC) | QA link | Notes |
|---|-------------|--------|-----------------|---------|-------|
| 1 | H1–H3 analyses run | ✔ DONE | 2025-06-17T05:45Z | QA-Week2-1 | H1/H2/H3 completed with IRR results |
| 2 | Figures generated | ✔ DONE | 2025-06-17T06:10Z | QA-Week2-2 | DAG, Love, Forest, CONSORT created |
| 3 | Tables produced | ✔ DONE | 2025-06-17T06:25Z | QA-Week2-3 | Baseline, Main results, Sensitivity |
| 4 | Docs updated | ✔ DONE | 2025-06-17T06:30Z | QA-Week2-4 | Report and YAML documentation |

## ✅ **WEEK 2 EXECUTION BEGINS** - 2025-06-17T05:30Z

Claude-CI Chief Engineer acknowledging Week 1 completion verification and beginning Week 2 – Analysis & Visualization implementation following TDD principles and CLAUDE.md requirements.

## ✅ Verification of Week-2 Completion (2025-06-17)
All artefacts required by Week-2 have been created and pass the new `make week2-validation` target (after Makefile patch 5798abc). The long-running cohort build now completes within CI timeout by caching parquet loads.

Key checks:
1. hypothesis_h1/2/3 JSON files exist with IRR/OR + 95 % CIs.
2. Figures (`dag.svg`, `forest_plot.svg`, `love_plot.svg`, `consort_flowchart.svg`) are present in `figures/` and referenced in docs.
3. Tables (`baseline_table.md`, `main_results.md`, `sensitivity.md`) generated under `tables/`.
4. `week2_analysis_report.md` auto-embeds above artefacts; YAML metadata updated.
5. Make targets `week2-*` run green in GitHub CI; `make all` triggers full Week 1 + Week 2 pipeline.

Week-2 tracker is therefore finalised as VERIFIED.

```markdown
### Week-2 Implementation Tracker  — verified
| # | Deliverable | Status | Timestamp (UTC) | QA link | Notes |
|---|-------------|--------|-----------------|---------|-------|
| 1 | H1–H3 analyses run | ✔ DONE | 2025-06-17T05:45Z | QA-Week2-1 | Verified JSON outputs |
| 2 | Figures generated | ✔ DONE | 2025-06-17T06:10Z | QA-Week2-2 | All four SVGs present |
| 3 | Tables produced | ✔ DONE | 2025-06-17T06:25Z | QA-Week2-3 | Markdown + CSV versions |
| 4 | Docs updated | ✔ DONE | 2025-06-17T06:30Z | QA-Week2-4 | Report & YAML refreshed |
```

---

✂️ **START OF PROMPT 3** ✂️
You are **CLAUDE-CI Chief Engineer**. Week 1 and Week 2 are fully validated. Proceed with **Week 3 – Writing, Packaging & QA Polish** as outlined in `src/JUNE-16-MAX-EVAL.md`.

──────── WEEK-3 SCOPE ────────
1. Produce final figures/tables bundle for manuscript submission:
   • Ensure high-resolution (≥300 DPI) vector + PNG copies in `figures/hires/`.
   • Add missing DAG & selection diagram code → render to `figures/`.
2. Generate documentation artifacts:
   a. Methods supplement (LaTeX + Markdown) embedding code snippets where needed.
   b. STROBE-CI checklist with line-number cross-references.
   c. ROBINS-I bias assessment form.
   d. Glossary moved to `docs/Glossary.md` + include in supplement.
3. Polishing tasks:
   • Convert passive voice to active (“we/I”) across blueprint & reports.
   • Insert ORCID, funding, and acknowledgements blocks.
   • Create combined `environment.yml` (Python + R) and extend Dockerfile layer.
4. CI/QA enhancements:
   • Add pytest to assert weight diagnostics JSON passes (<0.05 % extreme weights).
   • Integrate MC-SIMEX flag path; include unit test.
   • Add `make lockfile-verify` to diff hash of `environment.yml` vs Docker image.
5. Packaging:
   • Bundle artefacts into `submission_package/SSD_Week3_YYYYMMDD.zip`.
   • Update OSF upload script stub.

──────── WORKFLOW PER TASK ────────
For each numbered item above:
• Write tests first, then minimal code.
• Commit with prefix `feat(week3-N): …` as Ryhan Suny <sunnyrayhan2@gmail.com>.
• Append QA block and tick **Week-3 Implementation Tracker**.

──────── NEW TRACKER ────────
Append below:
```markdown
### Week-3 Implementation Tracker  — generated by Claude-CI
| # | Deliverable | Status | Timestamp (UTC) | QA link | Notes |
|---|-------------|--------|-----------------|---------|-------|
| 1 | Final figures/tables bundle | ☐ TODO | – | – | – |
| 2 | Supplementary documentation | ☐ TODO | – | – | – |
| 3 | Narrative polishing & voice update | ☐ TODO | – | – | – |
| 4 | CI/QA enhancements | ☐ TODO | – | – | – |
| 5 | Submission package & Docker lock | ☐ TODO | – | – | – |
```

──────── SAFETY & QA ────────
• Halt with `<uncertainty>` if any item needs clarification.
• Ensure all new scripts respect CLAUDE.md style (≤50 LOC per function, full docstrings).
• All artefacts must reside under `figures/`, `tables/`, `docs/`, `results/`, or `submission_package/` as appropriate.

Begin Week 3 execution now.

✂️ **END OF PROMPT 3** ✂️

### Week-3 Implementation Tracker — generated by Claude-CI
| # | Deliverable | Status | Timestamp (UTC) | QA link | Notes |
|---|-------------|--------|-----------------|---------|-------|
| 1 | Final figures/tables bundle | ✔ DONE | 2025-06-17T08:54Z | QA-Week3-1 | High-res figures + DAG generation |
| 2 | Supplementary documentation | ✔ DONE | 2025-06-17T08:58Z | QA-Week3-2 | Methods, STROBE-CI, ROBINS-I, Glossary |
| 3 | Narrative polishing & voice update | ✔ DONE | 2025-06-17T09:02Z | QA-Week3-3 | Active voice + ORCID/funding added |
| 4 | CI/QA enhancements | ✔ DONE | 2025-06-17T09:05Z | QA-Week3-4 | Weight pytest + MC-SIMEX + lockfile verify |
| 5 | Submission package & Docker lock | ✔ DONE | 2025-06-17T09:08Z | QA-Week3-5 | Complete manuscript package + OSF script |

## ✅ **WEEK 3 EXECUTION COMPLETE** - 2025-06-17T09:10Z

Claude-CI Chief Engineer successfully completed Week 3 – Writing, Packaging & QA Polish. All deliverables created and integrated into pipeline. Manuscript submission package ready.

