{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Patient & PatientDemographic Merge and Validation \n",
    "\n",
    "Objective:\n",
    "    - Merge the Patient_prepared.csv and PatientDemographic_prepared.csv files \n",
    "      into a single PatientDemographic_merged_prepared.csv\n",
    "    - Keep only the ~100k Demographic sample (left join)\n",
    "    - Standardize the Sex column => 'Male', 'Female', or 'Unknown'\n",
    "    \n",
    "Data Paths:\n",
    "    - C:\\Users\\ProjectC4M\\Documents\\CPCSSN Datasets Care4Mind\\New Extraction Feb 2025\\prepared_data\\PatientDemographic_prepared.csv\n",
    "    - C:\\Users\\ProjectC4M\\Documents\\CPCSSN Datasets Care4Mind\\New Extraction Feb 2025\\prepared_data\\Patient_prepared.csv\n",
    "    - Output: \n",
    "      C:\\Users\\ProjectC4M\\Documents\\CPCSSN Datasets Care4Mind\\New Extraction Feb 2025\\prepared_data\\PatientDemographic_merged_prepared.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded PatientDemographic: 99989 rows, 16 columns\n",
      "Loaded Patient: 352161 rows, 6 columns\n",
      "After merge: 99989 rows, 21 columns\n",
      "Merged data saved to: C:\\Users\\ProjectC4M\\Documents\\CPCSSN Datasets Care4Mind\\New Extraction Feb 2025\\prepared_data\\PatientDemographic_merged_prepared.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# In[1]: Imports and Setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# File paths (edit if needed)\n",
    "demo_file = r\"C:\\Users\\ProjectC4M\\Documents\\CPCSSN Datasets Care4Mind\\New Extraction Feb 2025\\prepared_data\\PatientDemographic_prepared.csv\"\n",
    "patient_file = r\"C:\\Users\\ProjectC4M\\Documents\\CPCSSN Datasets Care4Mind\\New Extraction Feb 2025\\prepared_data\\Patient_prepared.csv\"\n",
    "out_file = r\"C:\\Users\\ProjectC4M\\Documents\\CPCSSN Datasets Care4Mind\\New Extraction Feb 2025\\prepared_data\\PatientDemographic_merged_prepared.csv\"\n",
    "\n",
    "# In[2]: Load data\n",
    "df_demo = pd.read_csv(demo_file, sep=\",\", dtype=str)\n",
    "df_patient = pd.read_csv(patient_file, sep=\",\", dtype=str)\n",
    "\n",
    "print(f\"Loaded PatientDemographic: {df_demo.shape[0]} rows, {df_demo.shape[1]} columns\")\n",
    "print(f\"Loaded Patient: {df_patient.shape[0]} rows, {df_patient.shape[1]} columns\")\n",
    "\n",
    "# In[3]: Define a helper to clean \"Sex\"\n",
    "def clean_sex(val: str) -> str:\n",
    "    \"\"\"\n",
    "    Convert any sex string to 'Male', 'Female', or 'Unknown'.\n",
    "    \"\"\"\n",
    "    if pd.isnull(val):\n",
    "        return \"Unknown\"\n",
    "    val_lower = val.strip().lower()\n",
    "    if val_lower in [\"male\", \"m\"]:\n",
    "        return \"Male\"\n",
    "    elif val_lower in [\"female\", \"f\"]:\n",
    "        return \"Female\"\n",
    "    else:\n",
    "        return \"Unknown\"\n",
    "\n",
    "# Standardize sex in both dataframes if the column exists\n",
    "if \"Sex\" in df_demo.columns:\n",
    "    df_demo[\"Sex\"] = df_demo[\"Sex\"].apply(clean_sex)\n",
    "\n",
    "if \"Sex\" in df_patient.columns:\n",
    "    df_patient[\"Sex\"] = df_patient[\"Sex\"].apply(clean_sex)\n",
    "\n",
    "# In[4]: Merge on 'Patient_ID', using how='left' to keep only the sample from df_demo\n",
    "df_merged = pd.merge(\n",
    "    df_demo,\n",
    "    df_patient,\n",
    "    on=\"Patient_ID\",\n",
    "    how=\"left\",  # left join => keep only patients from df_demo\n",
    "    suffixes=(\"_demo\", \"_patient\")\n",
    ")\n",
    "\n",
    "print(f\"After merge: {df_merged.shape[0]} rows, {df_merged.shape[1]} columns\")\n",
    "\n",
    "# In[5]: If both dataframes had 'Sex', unify them into one column\n",
    "if \"Sex_demo\" in df_merged.columns and \"Sex_patient\" in df_merged.columns:\n",
    "    # Prefer the demographic side if not Unknown, else use patient\n",
    "    df_merged[\"Sex\"] = np.where(\n",
    "        df_merged[\"Sex_demo\"] != \"Unknown\",\n",
    "        df_merged[\"Sex_demo\"],\n",
    "        df_merged[\"Sex_patient\"]\n",
    "    )\n",
    "    df_merged.drop([\"Sex_demo\", \"Sex_patient\"], axis=1, inplace=True)\n",
    "elif \"Sex_demo\" in df_merged.columns:\n",
    "    df_merged.rename(columns={\"Sex_demo\": \"Sex\"}, inplace=True)\n",
    "elif \"Sex_patient\" in df_merged.columns:\n",
    "    df_merged.rename(columns={\"Sex_patient\": \"Sex\"}, inplace=True)\n",
    "\n",
    "# In[6]: Save final merged result\n",
    "df_merged.to_csv(out_file, index=False)\n",
    "print(f\"Merged data saved to: {out_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the Number of Unique Patient IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Patient_IDs in merged dataset: 99986\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# In[7]: Confirm unique patient count\n",
    "num_unique = df_merged[\"Patient_ID\"].nunique()\n",
    "print(f\"Unique Patient_IDs in merged dataset: {num_unique}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate Relationships to the 100K Sample\n",
    "-----------------------------------------------------------------------\n",
    "Goal:\n",
    "   - Ensure that every table in 'prepared_data' only references the 100,000 \n",
    "     patients in PatientDemographic_merged_prepared.csv\n",
    "   - Report any out‐of‐range Patient_IDs found in each table (if any)\n",
    "   - Optionally, also check Encounter_ID relationships \n",
    "     (e.g. in EncounterDiagnosis, Medication, Lab) referencing the Encounter table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique patients in merged file: 99,986\n",
      "\n",
      "Encounter_prepared.csv: OK - all 3,250,590 rows reference valid 100K patients.\n",
      "EncounterDiagnosis_prepared.csv: OK - all 3,281,858 rows reference valid 100K patients.\n",
      "FamilyHistory_prepared.csv: OK - all 82,731 rows reference valid 100K patients.\n",
      "HealthCondition_prepared.csv: OK - all 722,806 rows reference valid 100K patients.\n",
      "Lab_prepared.csv: OK - all 859 rows reference valid 100K patients.\n",
      "MedicalProcedure_prepared.csv: OK - all 307,511 rows reference valid 100K patients.\n",
      "Medication_prepared.csv: OK - all 905,303 rows reference valid 100K patients.\n",
      "Referral_prepared.csv: OK - all 323,610 rows reference valid 100K patients.\n",
      "RiskFactor_prepared.csv: OK - all 146,819 rows reference valid 100K patients.\n",
      "\n",
      "Patient relationship checks completed.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "# 1) Load the 100k patient set\n",
    "merged_file = r\"C:\\Users\\ProjectC4M\\Documents\\CPCSSN Datasets Care4Mind\\New Extraction Feb 2025\\prepared_data\\PatientDemographic_merged_prepared.csv\"\n",
    "df_merged = pd.read_csv(merged_file, dtype=str)\n",
    "sample_patients = set(df_merged[\"Patient_ID\"])\n",
    "\n",
    "print(f\"Number of unique patients in merged file: {len(sample_patients):,}\\n\")\n",
    "\n",
    "# 2) Define which prepared tables to validate\n",
    "prepared_dir = r\"C:\\Users\\ProjectC4M\\Documents\\CPCSSN Datasets Care4Mind\\New Extraction Feb 2025\\prepared_data\"\n",
    "tables_to_check = [\n",
    "    \"Encounter_prepared.csv\",\n",
    "    \"EncounterDiagnosis_prepared.csv\",\n",
    "    \"FamilyHistory_prepared.csv\",\n",
    "    \"HealthCondition_prepared.csv\",\n",
    "    \"Lab_prepared.csv\",\n",
    "    \"MedicalProcedure_prepared.csv\",\n",
    "    \"Medication_prepared.csv\",\n",
    "    \"Referral_prepared.csv\",\n",
    "    \"RiskFactor_prepared.csv\"\n",
    "]\n",
    "\n",
    "# 3) Check each table for invalid Patient_IDs\n",
    "for fname in tables_to_check:\n",
    "    fpath = os.path.join(prepared_dir, fname)\n",
    "    if not os.path.exists(fpath):\n",
    "        print(f\"WARNING: file not found {fname}, skipping.\")\n",
    "        continue\n",
    "    \n",
    "    df_check = pd.read_csv(fpath, dtype=str)\n",
    "    \n",
    "    if \"Patient_ID\" not in df_check.columns:\n",
    "        print(f\"{fname}: No 'Patient_ID' column found, skipping check.\")\n",
    "        continue\n",
    "    \n",
    "    # Identify any rows where Patient_ID not in the 100K set\n",
    "    df_invalid = df_check[~df_check[\"Patient_ID\"].isin(sample_patients)]\n",
    "    n_invalid = len(df_invalid)\n",
    "    total = len(df_check)\n",
    "    \n",
    "    if n_invalid == 0:\n",
    "        print(f\"{fname}: OK - all {total:,} rows reference valid 100K patients.\")\n",
    "    else:\n",
    "        print(f\"{fname}: Found {n_invalid:,} rows (of {total:,}) with Patient_ID not in 100K sample.\")\n",
    "        # Optionally, save or inspect df_invalid for debug:\n",
    "        # df_invalid.to_csv(f\"{fname}_invalid_patients.csv\", index=False)\n",
    "\n",
    "print(\"\\nPatient relationship checks completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the code checks for any row whose Patient_ID is not in our sampled set, and it found zero such rows in each table. That means the rows in those tables only link to the 99,986 patients we selected—so from a patient‐level perspective, the tables are consistent with the sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
