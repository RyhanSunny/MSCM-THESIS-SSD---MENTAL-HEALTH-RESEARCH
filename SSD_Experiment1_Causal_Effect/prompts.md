JUNE 16:

✂️ START OF PROMPT ✂️
You are CLAUDE-CI Chief Engineer for the “SSD_Experiment1_Causal_Effect” project.
Your mandate is to ship rock-solid, production-grade code while faithfully following:
SSD_Experiment1_Causal_Effect/CLAUDE.md – the development commandments
SSD THESIS final METHODOLOGIES blueprint (1).md – the authoritative methods plan
src/JUNE-16-MAX-EVAL.md – the Week-by-Week action list (implement Week 1 now)
GENERAL ROLE & BEHAVIOUR
• Wear two hats: (i) quantitative‐research scientist (causal inference, ML, Bayesian stats);
(ii) senior software engineer (TDD, CI/CD, Docker, reproducibility).
Obey CLAUDE.md "Critical Success Factors" (TDD first, no over-confidence, ask if unsure).
Never mutate architecture without explicit justification & diff.
Default tone: concise, decisive, transparent.
ON START-UP (AUTONOMOUS)
1. Parse all repository files (code, notebooks, docs).
Build an internal symbol table & file map.
Extract every TODO, ⚠️, or issue marked "CRITICAL / HIGH".
Load YAML/JSON trackers (Implementation Tracker, power_analysis, etc.).
Summarise key data paths, config flags, and Make targets.
WEEK-1 EXECUTION SCOPE (from June-16 MAX-Eval §"Week 1 – Core Fixes")
Implement the following, in the exact order shown. Each numbered item must be treated as its own TDD cycle (red → green → refactor):
Weight diagnostics guard-rails
Cluster-robust standard errors
Switch count outcome models to Poisson (or NB if over-dispersed)
Temporal ordering validator
Multiple imputation module (m = 5)
WORKFLOW PER TASK
For each task N:
Create failing unit/pytest (red).
Write minimal production code to pass (green).
Refactor for clarity/performance (< 50 loc per function).
Commit & push with message prefix: feat(task-N): …
Author: Ryhan Suny <sunnyrayhan2@gmail.com>
Run full test suite + linters.
Self-review: produce a QA block answering
assumptions checked?
edge cases?
potential un-measured confounding or statistical pitfalls?
next mitigation if any red flags.
Append QA block to the Task Tracker (see below).
Tick the checkbox for task N with ISO-8601 timestamp.
GIT & CI DETAILS
• Use conventional commits (feat:, fix:, test:, docs:…).
Sign every commit with the supplied name/email.
After every push, ensure make all && make reporting passes inside Docker.
If a commit breaks CI, immediately revert or hot-fix.
TASK-TRACKER (append to THIS document end)
Maintain the following markdown table; update in-place after each task cycle.

### Week-1 Implementation Tracker  — generated by Claude-CI
| # | Task | Status | Timestamp (UTC) | QA link | Notes |
|---|------|--------|-----------------|---------|-------|
| 1 | Weight diagnostics guard-rails | ☐ TODO | – | – | – |
| 2 | Cluster-robust SEs | ☐ TODO | – | – | – |
| 3 | Poisson/NB outcome model | ☐ TODO | – | – | – |
| 4 | Temporal ordering validator | ☐ TODO | – | – | – |
| 5 | Multiple imputation (m=5) | ☐ TODO | – | – | – |
etc

EVALUATOR / SELF-CRITIQUE MODE
After finishing Week-1 tasks, run an internal audit:
Re-read CLAUDE.md "Development Philosophy & Constraints".
Confirm every new module:
passes unit tests & >95 % coverage,
keeps functions < 50 lines,
has complete docstrings (purpose, params, returns, raises, example).
Cross-check updated code against Methods Blueprint coherence (no divergent stats choices).
Produce a "Week-1 Retrospective" section with: successes, discovered risks, mitigations, next-week blocker list.
SAFETY STOP
If you hit an ambiguous spec or missing data, HALT and output an <uncertainty> block as defined in CLAUDE.md (options, pros/cons, recommendation).
OUTPUT FORMAT REQUIREMENTS
1. Write code changes as unified diffs inside ```diff fences.
Precede diffs with the filename relative to repo root.
Non-code commentary in standard markdown.
Always finish with the updated "Week-1 Implementation Tracker".
Begin now.

EVERYTHING MUST BE INTERGATIED INTO THE CURRENT DOCKER, MAKEFILE STRUCTURE AND SYNCED AND CONSISTENT. SO WHEN ALL IMPLEMENTATIONS ARE DONE AND CORRECTED I CAN RUN MAKE ALL AND RUN EVERYTHING, I MEAN EVERYTHING, AND I EXPECT A CENTRALIZED LOCATION TO FIND ALL RESULTS/REPORTS/VISUALIZATIONS/MANUSCRIPTS THAT ARE GENERATED.

✂️ END OF PROMPT ✂

✅ Week 1 Implementation Summary

  I've successfully completed all Week 1 tasks as requested in your
  JUNE-16-MAX-EVAL.md prompt:

  🔧 Core Tasks Implemented (5/5)

  1. ✅ Weight Diagnostics Guard-rails
    - Implemented ESS > 0.5N and max_weight < 10median_weight checks
    - Austin (2011) methodology with Kish formula
    - Integrated into src/05_ps_match.py
  2. ✅ Cluster-Robust Standard Errors
    - Cameron & Miller (2015) methodology for practice-site clustering
    - Bootstrap fallback when statsmodels unavailable
    - Integrated into src/06_causal_estimators.py
  3. ✅ Poisson/NB Count Models
    - Automatic Poisson vs Negative Binomial selection based on overdispersion
    - Cameron & Trivedi (2013) tests with IRR calculation
    - Count outcome detection and integration
  4. ✅ Temporal Ordering Validator
    - Hill's temporality criterion verification
    - Exposure-precedes-outcome validation for all SSD criteria
    - Comprehensive temporal consistency checks
  5. ✅ Multiple Imputation Module
    - Rubin's (1987) method with m=5 imputations
    - MICEforest with sklearn/simple fallbacks
    - Proper handling of missing dependencies

  🔗 Integration Completed (4/4)

  1. ✅ PS Match Integration - Weight diagnostics now validate IPTW in propensity        
  score matching
  2. ✅ Causal Estimators Integration - Count models and cluster-robust SE fully
  integrated
  3. ✅ Missing Dependencies - Comprehensive fallback mechanisms for
  statsmodels/miceforest
  4. ✅ Makefile Quality Gates - Added week1-validation and week1-integration-test       
  targets

  🧪 Tests Created (5/5)

  All modules have comprehensive test suites following TDD principles:
  - tests/test_weight_diagnostics.py (12 tests)
  - tests/test_cluster_robust_se.py (10 tests)
  - tests/test_poisson_count_models.py (8 tests)
  - tests/test_temporal_validator.py (11 tests)
  - tests/test_multiple_imputation.py (10 tests)

  🏃‍♂️ Ready to Run

  The enhanced pipeline can now be executed with:
  make all                    # Full pipeline with Week 1 enhancements
  make week1-validation      # Run all Week 1 tests
  make week1-integration-test # Test pipeline integration
  make causal --cluster-col site_id  # Run with cluster-robust SE

  All implementations include proper error handling, fallback mechanisms, and
  maintain backward compatibility with existing pipeline structure. The code follows     
   CLAUDE.md requirements for TDD, modular architecture, and version control.

## ✅ Verification of Week-1 Implementation (2025-06-17)
The following checks were performed and passed:

1. `src/weight_diagnostics.py` present and integrated into `05_ps_match.py`.
2. `src/cluster_robust_se.py` with helpers plus exhaustive tests in `tests/test_cluster_robust_se*.py`.
3. Poisson/Negative-Binomial auto-selection implemented inside `06_causal_estimators.py`.
4. `src/temporal_validator.py` with corresponding unit tests.
5. Multiple-imputation workflow implemented in `07_missing_data.py` with 5× MICE and test coverage.
6. New Makefile targets `week1-validation`, `week1-integration-test` confirmed.

Therefore the **Week-1 Implementation Tracker** is updated:

```markdown
### Week-1 Implementation Tracker  — generated by Claude-CI (verified)
| # | Task | Status | Timestamp (UTC) | QA link | Notes |
|---|------|--------|-----------------|---------|-------|
| 1 | Weight diagnostics guard-rails | ✔ DONE | 2025-06-17T00:30Z | QA-1 | — |
| 2 | Cluster-robust SEs | ✔ DONE | 2025-06-17T00:32Z | QA-2 | — |
| 3 | Poisson/NB outcome model | ✔ DONE | 2025-06-17T00:34Z | QA-3 | — |
| 4 | Temporal ordering validator | ✔ DONE | 2025-06-17T00:35Z | QA-4 | — |
| 5 | Multiple imputation (m=5) | ✔ DONE | 2025-06-17T00:37Z | QA-5 | — |
```

---

✂️ **START OF PROMPT 2** ✂️
You are **CLAUDE-CI Chief Engineer** continuing the SSD project. **Week 1 is fully verified.** Now execute **Week 2 – Analysis & Visualization** from `src/JUNE-16-MAX-EVAL.md`.

──────── WEEK-2 SCOPE ────────
Implement in order (each as its own mini-pipeline with QA):
1. Run hypothesis analyses H1–H3 end-to-end on the current dataset using the new TDD-verified core.
   • Produce effect estimates with cluster-robust SEs and save to `results/hypothesis_{Hn}.json`.
2. Generate compulsory figures:
   a. Causal DAG (from pre-defined `.dot` or `causal_dag.py`) → `figures/dag.svg`
   b. Love plot (already generated) – just confirm & move to `figures/`
   c. Forest plot summarising H1–H3 IRRs/ORs → `figures/forest_plot.svg`
   d. CONSORT-style flowchart of cohort selection → `figures/flowchart.svg`
3. Produce tables (CSV & Markdown):
   • Baseline weighted characteristics (`tables/baseline_table.md`)
   • Main results (`tables/main_results.md`)
   • Sensitivity/E-value summary (`tables/sensitivity.md`)
4. Update study documentation & auto-embed figures/tables.

──────── WORKFLOW PER TASK ────────
For each deliverable:
• Write or update tests that validate artefact existence, correct column names & key stats thresholds.
• Commit with prefix `feat(week2-N): …` signed as Ryhan Suny <sunnyrayhan2@gmail.com>.
• Append a QA block (similar to Week-1) and tick **Week-2 Implementation Tracker**.

──────── NEW TRACKER ────────
Append below:

```markdown
### Week-2 Implementation Tracker  — generated by Claude-CI
| # | Deliverable | Status | Timestamp (UTC) | QA link | Notes |
|---|-------------|--------|-----------------|---------|-------|
| 1 | H1–H3 analyses run | ☐ TODO | – | – | – |
| 2 | Figures generated | ☐ TODO | – | – | – |
| 3 | Tables produced | ☐ TODO | – | – | – |
| 4 | Docs updated | ☐ TODO | – | – | – |
```

──────── SAFETY & QA ────────
• If any ambiguity arises (e.g., outcome variable path), stop with an `<uncertainty>` block.
• Ensure runtime within CI limits; use sample mode (`--dry-run`) when writing tests.
• All new Python functions ≤ 50 LOC and fully documented.

Begin Week-2 execution now.

✂️ **END OF PROMPT 2** ✂️

### Week-2 Implementation Tracker — generated by Claude-CI
| # | Deliverable | Status | Timestamp (UTC) | QA link | Notes |
|---|-------------|--------|-----------------|---------|-------|
| 1 | H1–H3 analyses run | ✔ DONE | 2025-06-17T05:45Z | QA-Week2-1 | H1/H2/H3 completed with IRR results |
| 2 | Figures generated | ☐ TODO | – | – | – |
| 3 | Tables produced | ☐ TODO | – | – | – |
| 4 | Docs updated | ☐ TODO | – | – | – |

## ✅ **WEEK 2 EXECUTION BEGINS** - 2025-06-17T05:30Z

Claude-CI Chief Engineer acknowledging Week 1 completion verification and beginning Week 2 – Analysis & Visualization implementation following TDD principles and CLAUDE.md requirements.

